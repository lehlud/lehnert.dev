[{"question":"<p>Gegeben sei folgendes Szenario: zwei F&#xE4;den werden auf einem\nMonoprozessorsystem mit der Strategie <q>First Come First Served</q>\nverwaltet. In <mark>jedem</mark> Faden wird die Anweisung\n<code>i++;</code> auf der gemeinsamen, globalen volatile Variablen i\nausgef&#xFC;hrt. Welche der folgenden Aussagen ist richtig?</p>\n","options":[{"comment":"<p>Ja, weil der Befehl <mark>immer</mark> ganz ausgef&#xFC;hrt wird, und weil\nes <mark>keine</mark> unvorhergesehenen Unterbrechungen gibt,\n<mark>muss</mark> man diese auch <mark>nicht</mark> verhindern oder\ndagegen vorbeugen.</p>\n","correct":true,"option":"<p>In einem Monoprozessorsystem ohne Verdr&#xE4;ngung ist keinerlei\nSynchronisation erforderlich.</p>\n"},{"comment":"<p>Nein, weil ein Interrupt keinen Einfluss haben <mark>muss</mark> auf\ndiese Operation.</p>\n","correct":false,"option":"<p>W&#xE4;hrend der Inkrementoperation m&#xFC;ssen Interrupts vor&#xFC;bergehend\nunterbunden werden.</p>\n"},{"option":"<p>Die Inkrementoperation <mark>muss</mark> mit einer CAS-Anweisung\nsynchronisiert werden.</p>\n","correct":false,"comment":"<p>Nein, wenn notwendig, w&#xE4;re es auch erlaubt es mit anderen mitteln zu\nsynchronisieren.</p>\n"},{"correct":false,"comment":"<p>Nein, das h&#xE4;ngt von der Recherarchitektur ab, und <mark>kann</mark>\naber <mark>muss</mark> <mark>nicht</mark> atomar &#xFC;bersetzt werden.</p>\n","option":"<p>Die Operation i++ ist auf einem Monoprozessorsystem\n<mark>immer</mark> atomar.</p>\n"}],"id":"SUE5G+rCmd7lduOaIArNFA","source":"2019-06","multiple":false},{"source":"2019-06","multiple":true,"options":[{"option":"<p>Die Sichtbarkeit globaler <code>static</code>-Variablen ist auf das\njeweilige Modul beschr&#xE4;nkt.</p>\n","correct":true,"comment":"<p>Ja, damit verhindert man auch Namenskonflikte zwischen Modulen.</p>\n"},{"comment":"<p>Ja, es <mark>kann</mark> auch direkt auf dem Stack gespeichert\nwerden.</p>\n","correct":true,"option":"<p>Funktionspointer werden <mark>nicht</mark> <mark>immer</mark> im\nText-Segment gespeichert.</p>\n"},{"comment":"<p>Ja-ish; diese k&#xF6;nnen <mark>nicht</mark> im Text-Segment liegen, weil\ndie dann <mark>nicht</mark> schreibbar w&#xE4;hren; diese k&#xF6;nnen\n<mark>nicht</mark> auf der Halde liegen, weil das zur laufzeit dynamisch\nverwaltet wird; diese k&#xF6;nnen <mark>nicht</mark> auf dem Stack liegen,\nweil die G&#xFC;ltigkeit unabh&#xE4;ngig vom Kontrollfluss und dem Aufrufbaum\nist.</p>\n","correct":null,"option":"<p>Globale schreibbare Variablen liegen im Daten-Segment.</p>\n"},{"option":"<p>Dynamisch allozierte Zeichenketten liegen im Text-Segment.</p>\n","correct":false,"comment":"<p>Nein, weil das Text Segment &#xFC;blicherweise <mark>nicht</mark> zur\nlaufzeit ver&#xE4;ndert wird.</p>\n"},{"comment":"<p>Nein, dynamische Speicherverwaltung, w&#xFC;rde wenn &#xFC;berhaupt die Halde\n(Heap) erweitern.</p>\n","correct":false,"option":"<p>Bei einem Aufruf von <code>malloc(3)</code> wird das Stack-Segment\ndynamisch erweitert.</p>\n"},{"option":"<p>Der Code von Funktionen wird zusammen mit den Variablen der Funktion\nim Stack-Segment abgelegt.</p>\n","comment":"<p>Nein, der Code von Funktionen liegt im Text Segment.</p>\n","correct":false},{"comment":"<p>Eigentlich ja, aber man <mark>kann</mark> dann diskutieren ob eine\nnicht-initialsierte <code>static</code> Variable, welche im BSS Segment\nliegt auch teil vom Daten-Segment ist oder nicht.</p>\n","correct":null,"option":"<p>Variablen der Speicherklasse <code>static</code> liegen im\nDaten-Segment.</p>\n"},{"correct":false,"comment":"<p>Nein, diese behalten den gleichen Wert unabh&#xE4;ngig vom\nFunktionsaufruf. Ihre Sichtbarkeit ist nur auf eine Funktion\nbeschr&#xE4;nkt.</p>\n","option":"<p>Lokale <code>static</code>-Variablen werden bei <mark>jedem</mark>\nBetreten der zugeh&#xF6;rigen Funktion neu initialisiert.</p>\n"}],"id":"BYArJQQJnvB7Vo0Ld7V05Q","question":"<p>Der Speicher eines UNIX-Prozesses ist in Text-, Daten- und\nStack-Segment untergliedert. Welche Aussagen bezogen auf C-Programme\nsind richtig?</p>\n"},{"options":[{"option":"<p>Das Betriebssystem erkennt die ung&#xFC;ltige Adresse bei der Weitergabe\ndes Befehls an die CPU (partielle Interpretation) und leitet eine\nAusnahmebehandlung ein.</p>\n","comment":"<p>Das Betriebsystem interpretiert die Befehle des Programms\n<mark>nicht</mark> selbst. Diese werden direkt von der CPU\ninterpretiert, welches sich in einem unpriviligiertem Modus befindet.\nF&#xFC;r privilegierte Befehle, <mark>muss</mark> man mit einem Systemaufruf\nsich an das Betriebsystem wenden.</p>\n","correct":false},{"correct":false,"comment":"<p>Zwar m&#xF6;glich, aber das ist <mark>nicht</mark> der Fall in C, wo\nFehlerbehandlung h&#xE4;ndisch gemacht wird.</p>\n","option":"<p>Der Compiler erkennt die problematische Code-Stelle und generiert\nCode, der zur Laufzeit bei dem Zugriff einen entsprechenden Fehler\nausl&#xF6;st.</p>\n"},{"option":"<p>Der Speicher schickt an die CPU einen Interrupt. Hierdurch wird das\nBetriebssystem angesprungen, das dem gerade laufenden Prozess das Signal\n<code>SIGSEGV</code> (Segmentation Violation) zustellt.</p>\n","comment":"<p>Der <q>Speicher</q> w&#xFC;rde in diesem Fall keinen Interrupt schicken,\nweil der Zugriff auf den ung&#xFC;ltigen Speicher bewusst und deterministisch\naufgetreten ist, und daher als ein <q>Trap</q> angesehen werden\nsollte.</p>\n","correct":false},{"comment":"<p>Ja; die CPU <mark>kann</mark> dann je nach Betriebsystem sich\nentscheiden diesen Trap weiter zu leiten an einen Prozess in Form eines\nSignals o.&#xC4;.</p>\n","correct":true,"option":"<p>Beim Zugriff <mark>muss</mark> die MMU, soweit vorhanden, die\nerforderliche Adressumsetzung vornehmen, erkennt die ung&#xFC;ltige Adresse\nund l&#xF6;st einen Trap aus.</p>\n"}],"id":"heTymodN/LToh6caXq5gdw","source":"2019-06","multiple":false,"question":"<p>Was passiert, wenn Sie in einem C-Programm versuchen &#xFC;ber einen\nZeiger auf ung&#xFC;ltigen Speicher zuzugreifen?</p>\n"},{"question":"<p>Welche der folgenden Aussagen zum Thema Synchronisation ist\nrichtig?</p>\n","id":"dPspFJ+12EQkQbZJA+XN6w","options":[{"option":"<p>Der Einsatz von nicht-blockierenden Synchronisationsmechanismen\n<mark>kann</mark> zu Verklemmungen (deadlocks) f&#xFC;hren.</p>\n","comment":"<p>Nein, bei einer Verklemmung m&#xFC;ssen mehre F&#xE4;den passiv aufeinander\nwarten, was bei nicht-blockierendeer Synchronisation <mark>nicht</mark>\npassieren kann.</p>\n","correct":false},{"correct":false,"comment":"<p>Nein, weil ein Anwendungsprozess <mark>keine</mark> Interrupts selbst\nsperren kann.</p>\n","option":"<p>Ein Anwendungsprozess <mark>muss</mark> bei der Verwendung von\nSemaphoren Interrupts sperren, um Probleme durch Nebenl&#xE4;ufigkeit zu\nverhindern.</p>\n"},{"option":"<p>Gibt ein Faden einen Mutex frei, den er selbst zuvor\n<mark>nicht</mark> angefordert hatte, stellt dies einen\nProgrammierfehler dar; eine Fehlerbehandlung sollte eingeleitet\nwerden.</p>\n","correct":true,"comment":"<p>Ja, weil ein Mutex <mark>immer</mark> von dem gleichem Faden\nfreigegeben werden sollte, wer es auch beansprucht hat (im Gegensatz zur\nbin&#xE4;ren Semaphore, wo diese Bedingung <mark>nicht</mark> gilt).</p>\n"},{"correct":false,"comment":"<p>Je nach Situation ist es <mark>nicht</mark> m&#xF6;glich (bspw. im Kern\nselbst, wo die Mechanismen Fehlen um <q>passiv</q>).</p>\n","option":"<p>Zur Synchronisation eines kritischen Abschnitts ist passives Warten\n<mark>immer</mark> besser geeignet als aktives Warten.</p>\n"}],"multiple":false,"source":"2019-06"},{"id":"0RTf4hQLx4a4+9hSprbXsA","question":"<p>Welche der folgenden Aussagen zu statischem bzw. dynamischem Binden\nist richtig?</p>\n","source":"2022-02","options":[{"option":"<p>Statisch gebundene Programmdateien sind kleiner als dynamisch\ngebundene, da mehrfach genutzte Funktionen in einer shared library\nabgelegt werden und <mark>nicht</mark> in die ausf&#xFC;hrbare Datei kopiert\nwerden</p>\n","correct":false,"comment":"<p>Die Beschreibung trifft auf dynamisch gebundene Programmdateien, weil\nBibliotheksfunktionen zur Laufzeit auf <code>.so</code> Dateien laden,\nim gegensatz zu statisch gebundenen Programmen, wo diese\n<mark>jedes</mark> mal zum Bindezeitpunkt in die ausf&#xFC;hrbare Datei\nkopiert werden.</p>\n"},{"correct":true,"option":"<p>Bei dynamischem Binden k&#xF6;nnen Fehlerkorrekturen in Bibliotheken\nleichter &#xFC;bernommen werden, da nur die Bibliothek selbst neu erzeugt\nwerden muss. Programme, die die Bibliothek verwenden, m&#xFC;ssen\n<mark>nicht</mark> neu kompiliert und gebunden werden.</p>\n","comment":"<p>Ja. Im Gegensatz dazu, m&#xFC;sste man bei einem statischen Bibliothek\n<mark>alle</mark> Programme nochmal neu, gegen die aktualisierte\nBibliothek bauen, damit diese die neuste Version benutzen.</p>\n"},{"comment":"<p>Nein, Adressen werden <mark>alle</mark> beim Binden aufgel&#xF6;st, und\nsind somit unabh&#xE4;ngig von der Ausf&#xFC;hrung &#x2013; <em>statisch</em> &#x2013;\nbekannt.</p>\n","correct":false,"option":"<p>Beim statischen Binden werden <mark>alle</mark> Adressen zum\nLadezeitpunkt aufgel&#xF6;st</p>\n"},{"correct":false,"option":"<p>Bei dynamischem Binden m&#xFC;ssen zum &#xDC;bersetzungszeitpunkt\n<mark>alle</mark> Adressbez&#xFC;ge vollst&#xE4;ndig aufgel&#xF6;st werden</p>\n","comment":"<p>Nein, Bibliotheksfunktionen welche aus <em>Shared Object</em> Dateien\ngeladen werden k&#xF6;nnen zur Laufzeit, m&#xFC;ssen <mark>nicht</mark> beim\n&#xDC;bersetzen bereits aufgel&#xF6;st geworden sein.</p>\n"}],"multiple":false},{"id":"PpOlsXQqPQNNm4Z6DbIkJA","question":"<p>Welche Antwort trifft f&#xFC;r die Eigenschaften eines\nUNIX/Linux-Dateideskriptor zu?</p>\n","source":"2022-02","multiple":false,"options":[{"comment":"<p>Nein, es ist zwar eine Ganzzahl, aber diese <mark>kann</mark>\n<mark>nicht</mark> beliebig hin und her gereicht werden, zumindest ohne\ndass das Betriebsystem entsprechend informiert wird (siehe\n<code>sendmsg(2)</code>).</p>\n","correct":false,"option":"<p>Ein Dateideskriptor ist eine Integerzahl, die &#xFC;ber gemeinsamen\nSpeicher an einen anderen Prozess &#xFC;bergeben werden kann, und von\nletzterem zum Zugriff auf eine ge&#xF6;ffnete Datei verwendet werden\nkann.</p>\n"},{"comment":"<p>Nein, es handelt sich <mark>nicht</mark> um einen Zeiger im\ngew&#xF6;hnlichen Sinne (eine Adresse auf eine Speicherstelle), auch wenn es\n&#xFC;blicherweise dazu benutzt wird um eine Prozess-Lokale Datei Tabelle zu\nAdressieren. Es stimmt aber, dass es dazu benutzt wird, einem\nSystemaufruf eine Datei anzudeuten, auf dem dieses arbeiten soll.</p>\n","correct":false,"option":"<p>Dateideskriptoren sind Zeiger auf Betriebssystemstrukturen, die von\nden Systemaufrufen ausgewertet werden, um auf Dateien zuzugreifen.</p>\n"},{"comment":"<p>Ja, ein Dateideskriptor <mark>muss</mark> <mark>nicht</mark> nur auf\n<q>gew&#xF6;hnlichen</q> Dateien arbeiten, sondern <mark>kann</mark>\nverschieden <q>Datei-&#xC4;hnlichen</q> Objekten (d.h. Datenstr&#xF6;men)\nabstrahieren. Wichtig ist auch der Punkt <q>prozesslokal</q>, weil die\nZahl nur eine Bedeutung hat, wenn das Betriebsystem dem Prozess diese\nZahl zuvor explizit vergeben hat.</p>\n","option":"<p>Ein Dateideskriptor ist eine prozesslokale Integerzahl, die der\nProzess zum Zugriff auf eine Datei, ein Ger&#xE4;t, einen Socket oder eine\nPipe benutzen kann.</p>\n","correct":true},{"comment":"<p>Nein, es ist m&#xF6;glich eine Datei Mehrfach zu &#xF6;ffnen, und dabei mehrere\nDateideskriptoren zu bekommen. Versuche</p>\n<pre><code>\nint main()\n{\n     int fd1 = open(&quot;/etc/passwd&quot;, O_RDONLY);\n     int fd2 = open(&quot;/etc/passwd&quot;, O_RDONLY);\n\n     printf(&quot;fd1: %d, fd2: %d\\n&quot;, fd1, fd2);\n}</code></pre>\n","correct":false,"option":"<p>Beim &#xD6;ffnen ein und derselben Datei erh&#xE4;lt ein Prozess jeweils die\ngleiche Integerzahl als Dateideskriptor zum Zugriff zur&#xFC;ck.</p>\n"}]},{"id":"HowH/yrrsx/cj8pC8awveA","question":"<p>Man unterschiedet zwei Kategorien von Ausnahmesituationen bei einer\nProgrammausf&#xFC;hrung: Traps und Interrupts. Welche der folgenden Aussagen\nsind zutreffend?</p>\n","source":"2022-02","multiple":true,"options":[{"comment":"<p>Ja, Beispielsweise bei einem ung&#xFC;ltigem Speicherzugriff.</p>\n","correct":true,"option":"<p>Ein Programm darf im Rahmen einer Trapbehandlung abgebrochen\nwerden.</p>\n"},{"comment":"<p>Nein, weil ein Interrupt nichts mit dem Programm zu tun hat, und\ndaher dieses <mark>nicht</mark> (direkt) abbrechen sollte.</p>\n","correct":false,"option":"<p>Ein durch einen Interrupt unterbrochenes Programm darf je nach der\nInterruptursache entweder abgebrochen oder fortgesetzt werden.</p>\n"},{"comment":"<p>Nein, bspw. wenn man versucht auf <mark>nicht</mark> lesbaren\nSpeicher versucht zuzugreifen, <mark>muss</mark> es abgebrochen werden,\nbevor auf den Speicher zuggegriffen wurde.</p>\n","option":"<p>Bei einem Trap wird der gerade in Bearbeitung befindliche\nMaschinenbefehl <mark>immer</mark> noch vollst&#xE4;ndig zu Ende bearbeitet,\nbevor mit der Trapbehandlung begonnen wird.</p>\n","correct":false},{"option":"<p>Die CPU sichert bei einem Interrupt einen Teil des\nProzessorzustands.</p>\n","correct":true,"comment":"<p>Ja, genau wie bei einer Signal-Behandlung unterbricht ein Interrupt\ndas <q>Hauptprogramm</q> vom Betriebsystem. Der Prozessorzustand\n<mark>muss</mark> daf&#xFC;r vermerkt worden sein, damit es danach wieder\nrestauriert werden kann.</p>\n"},{"comment":"<p>Ja, eine Rechnerarchitektur <mark>kann</mark> beim Teilen durch 0 ein\nTrap ausl&#xF6;sen.</p>\n","option":"<p>Die Ausf&#xFC;hrung einer Ganzzahl-Rechenoperation (z. B. Addition,\nDivision) <mark>kann</mark> zu einem Trap f&#xFC;hren.</p>\n","correct":true},{"comment":"<p>Nein, es ist dennoch m&#xF6;glich wenn beide auf die gleichen Ressourcen\nwarten, was im Betriebsystemkern m&#xF6;glich ist, vor allem wenn mehrere\nKerne mitspielen.</p>\n","option":"<p>Da Traps <mark>immer</mark> synchron auftreten, <mark>kann</mark> es\nim Rahmen ihrer Behandlung <mark>nicht</mark> zu Wettlaufsituationen mit\ndem unterbrochenen Programm kommen.</p>\n","correct":false},{"correct":false,"option":"<p>Wenn ein Interrupt ein schwerwiegendes Ereignis signalisiert, wird\ndas unterbrochene Programm im Rahmen der Interruptbearbeitung\n<mark>immer</mark> abgebrochen.</p>\n","comment":"<p>Nein, ein Interrupt sollte <mark>nie</mark> direkt zur Beendigung\neines Programms f&#xFC;ren.</p>\n"},{"comment":"<p>Nein, weil diese deterministisch <mark>immer</mark> dann auftreten,\nwenn ein Programm ein Systemaufruf absetzen will.</p>\n","correct":false,"option":"<p>Ein Systemaufruf im Anwendungsprogramm ist der Kategorie Interrupt\nzuzuordnen.</p>\n"}]},{"source":"2022-02","options":[{"comment":"<p>Nein, weil danach der Prozess <mark>nicht</mark> mehr <q>bereit</q>\nist (d.h. wieder eingelagert werden kann).</p>\n","correct":false,"option":"<p>Der Prozess ruft die Bibliotheksfunktion <code>exit(3)</code>\nauf.</p>\n"},{"correct":true,"option":"<p>Der Scheduler bewirkt, dass der Prozess durch einen anderen Prozess\nverdr&#xE4;ngt wird.</p>\n","comment":"<p>Ja, weil die einzige Ressource welche dem Prozess fehlt ist die CPU,\nwelche der Scheduler sp&#xE4;ter wieder <q>vergeben</q> kann, und damit der\nProzess auch die ganze Zeit bereit ist wieder weiter zu laufen.</p>\n"},{"option":"<p>Der Prozess greift lesend auf eine Datei zu und der entsprechende\nDatenblock ist noch <mark>nicht</mark> im Hauptspeicher vorhanden.</p>\n","correct":false,"comment":"<p>Nein, weil dann idr. der Prozess beendet wird mit einem Sigal wie\n<code>SIGSEVG</code>, und <mark>nicht</mark> mehr laufen darf.</p>\n"},{"comment":"<p>Nein, weil dann der Prozess blokiert wird, und <mark>nicht</mark>\nmehr laufen kann, bis an einer anderen Stelle eine entsprechende\nV-Operation ausgef&#xFC;hrt wird.</p>\n","option":"<p>Der Prozess ruft eine P-Operation auf einen Semaphor auf, welcher den\nWert 0 hat.</p>\n","correct":false}],"multiple":false,"id":"nR8Xpvc0tw6WR84nEoWuvg","question":"<p>In welcher der folgenden Situationen wird ein Prozess vom Zustand\nlaufend in den Zustand bereit &#xFC;bef&#xFC;hrt?</p>\n"},{"source":"2022-02","multiple":false,"options":[{"option":"<p>Ein Speicherbereich, der mit Hilfe der Funktion <code>free()</code>\nfreigegeben wurde, verbleibt im logischen Adressraum des zugeh&#xF6;rigen\nProzesses.</p>\n","correct":true,"comment":"<p>Ja. Der <strong>logische</strong> Adressraum A<sub>l</sub> = [n, m]\nist der gesamte Adressbereich ohne L&#xFC;cken, der einem Prozess zugeordnet\nwird. Dieser wird <mark>nicht</mark> verkleinert, wenn <code>free</code>\naufgerufen wird. Im Gegensatz dazu ist der virtuelle Adressraum\nA<sub>v</sub> jener, der nur partiell auf den Hauptspeicher abgebildet\nwird, bei dem also Adressen ung&#xFC;ltig sein k&#xF6;nnen. (vgl. SP1 B Vl. 2 S.\n12 ff., 27) (Bin mir hier <mark>nicht</mark> zu 100 % sicher, dass meine\nInterpretation korrekt ist)</p>\n"},{"comment":"<p>Nein, nach dem Ende des Programms wird der gesamte Adressbereich des\nProzesses freigegeben. Das ist m&#xF6;glich, weil das Betriebsystem den\nSpeicher f&#xFC;r jeden Prozess virtualisiert und damit auch in der Lage ist,\nihm diese Ressource zu entziehen.</p>\n","correct":false,"option":"<p>Mit <code>malloc()</code> angeforderter Speicher, welcher vor\nProgrammende <mark>nicht</mark> freigegeben wurde, <mark>kann</mark> vom\nBetriebssystem <mark>nicht</mark> mehr an andere Prozesse herausgegeben\nwerden und ist damit bis zum Neustart des Systems verloren.</p>\n"},{"option":"<p>Mit Hilfe des Systemaufrufes <code>malloc()</code> <mark>kann</mark>\nein Programm zus&#xE4;tzliche Speicherbl&#xF6;cke von sehr feink&#xF6;rniger Struktur\nvom Betriebssystem anfordern.</p>\n","correct":false,"comment":"<p>Nein, <code>malloc(3)</code> ist kein Systemaufruf, sondern eine\nBibliotheksfunktion. Au&#xDF;erdem fordert die Laufzeitumgebung\n(<em>libc</em>) den Speicher &#xFC;blicherweise grobgranular vom\nBetriebssystem an (<code>mmap(2)</code>, <code>brk(2)</code>) und\nverteilt diesen im Benutzerprozess.</p>\n"},{"comment":"<p>Nein, <code>malloc</code> <mark>kann</mark> als Teil des\nLaufzeitsystems den grobgranular vom Betriebssystem angeforderten\nSpeicher feingranular aufteilen und zur&#xFC;ckgeben.</p>\n","option":"<p>Da das Laufzeitsystem auf die Betriebssystemschnittstelle zur\nSpeicherverwaltung zur&#xFC;ckgreift, ist die Granularit&#xE4;t der von\n<code>malloc()</code> zur&#xFC;ckgegebenen Speicherbl&#xF6;cke vom Betriebssystem\nvorgegeben.</p>\n","correct":false}],"id":"eE/xHewVg+QAb4S5aQckzg","question":"<p>Welche Aussage zum Thema Adressraumverwaltung ist richtig?</p>\n"},{"options":[{"option":"<p>Der TLB puffert die Ergebnisse der Abbildung von physikalische auf\nlogische Adressen, sodass eine erneute Anfrage sofort beantwortet werden\nkann.</p>\n","correct":false,"comment":"<p>Nein, andersherum. Logische m&#xFC;ssen in physikalische Adressen\n&#xFC;bersetzt werden.</p>\n"},{"comment":"<p>Ja, da die Eintr&#xE4;ge im TLB beziehen sich auf einen bestimmten\nlogischen Adressraum.</p>\n","correct":true,"option":"<p>Ver&#xE4;ndert sich die Speicherabbildung von logischen auf physikalische\nAddressen aufgrund einer Adressraumumschaltung, so werden auch die Daten\nim TLB ung&#xFC;ltig.</p>\n"},{"option":"<p>Wird eine Speicherabbildung im TLB <mark>nicht</mark> gefunden, wird\nvom Prozessor <mark>immer</mark> eine Ausnahme (<em>Trap</em>) ausgel&#xF6;st\ndie vom Betriebssystem behandelt wird.</p>\n","correct":false,"comment":"<p>Nein, ist kein Eintrag im TLB zu finden, wird die Addresse von der\nMMU aufgel&#xF6;st.</p>\n"},{"comment":"<p>Nein, ist kein Eintrag im TLB zu finden, wird die Addresse von der\nMMU aufgel&#xF6;st. Der TLB agiert nur als <em>cache</em> f&#xFC;r\nAdress&#xFC;bersetzungen.</p>\n","correct":false,"option":"<p>Wird eine Speicherabbildung im TLB <mark>nicht</mark> gefunden, wird\nder auf den Speicher zugreifende Prozess mit einer Schutzraumverletzung\n(Segmentation Fault) abgebrochen.</p>\n"}],"multiple":false,"source":"2022-02","question":"<p>Sie kennen den Translation-Lookaside-Buffer (TLB). Welche Aussage ist\nrichtig?</p>\n","id":"JnT00/vBjmsbTTYFKwbaxg"},{"id":"FFTMjSiZAOVJg9kBXQmUPQ","question":"<p>Welche Aussage zu den verschiedenen Gewichtsklassen von Prozessen\ntrifft zu?</p>\n","source":"2022-02","multiple":false,"options":[{"comment":"<p>Nein. Auch leichtgewichtigen Prozessen (<em>kernel-level\nthreads</em>) ist ein <em>kernel thread</em> zugeordnet.</p>\n","option":"<p>Schwergewichtige Prozesse sind die einzige Klasse von Prozessen, die\nauf einem Multiprozessorsystem echt parallel ausgef&#xFC;hrt werden kann, da\nnur hier jeder Benutzerfaden einem eigenen Kernfaden zugeordnet ist.</p>\n","correct":false},{"comment":"<p>Ja, da bei federgewichtigen Prozessen mehrere Prozesse auf einen\nSystemkernfaden (<em>kernel-level thread</em>) gemultiplext werden, wird\ndie Ausf&#xFC;hrung der aller federgewichtigen Prozesse blockiert, die auf\neinem <em>kernel-level thread</em> ausgef&#xFC;hrt werden, bis dieser wieder\nbereit ist.</p>\n","correct":true,"option":"<p>Federgewichtige Prozesse (<em>user-level threads</em>) blockieren\nsich bei blockierenden Systemaufrufen gegenseitig.</p>\n"},{"option":"<p>Beim Blockieren eines schwergewichtigen Prozesses werden\n<mark>alle</mark> anderen schwergewichtigen Prozesse, die das selbe\nProgamm ausf&#xFC;hren, ebenfalls blockiert.</p>\n","correct":false,"comment":"<p>Nein. Man <mark>kann</mark> mehrere Prozesse mit dem gleichen\nProgramm ausf&#xFC;hren.</p>\n"},{"correct":false,"option":"<p>Zu <mark>jedem</mark> leichtgewichtigen Prozess (<em>kernel-level\nthread</em>) geh&#xF6;rt ein eigener, isolierter Adressraum.</p>\n","comment":"<p>Falsch, das w&#xE4;ren schwergewichtige Prozesse. Leichtgewichtige\nProzesse wie <code>pthread</code>s teilen sich einen Adressraum.</p>\n"}]},{"source":"2022-02","multiple":false,"options":[{"comment":"<p>Ja, die <em>page descriptor table</em> enth&#xE4;lt f&#xFC;r jeden\nSeitendeskriptor ein <em>valid</em>-Bit. Ist dieses <mark>nicht</mark>\ngesetzt, so wird ein <em>Trap</em> ausgel&#xF6;st.</p>\n","option":"<p>Im Seitendeskriptor wird ein spezielles Bit gef&#xFC;hrt, das der MMU\nzeigt, ob eine Seite eingelagert ist oder nicht. Falls die Seite\n<mark>nicht</mark> eingelagert ist, l&#xF6;st die MMU einen Trap aus.</p>\n","correct":true},{"comment":"<p>Nein, die MMU interagiert <mark>nicht</mark> mit dem\nHintergrundspeicher, sondern ist nur f&#xFC;r die Adressabbildung von\nlogischen zu realen Adressen zust&#xE4;ndig.</p>\n","option":"<p>Im Seitendeskriptor steht bei ausgelagerten Seiten eine Adresse des\nHintergrundspeichers und der Speichercontroller leitet den Zugriff auf\nden Hintergrundspeicher um.</p>\n","correct":false},{"comment":"<p>Nein, das Betriebssystem &#xFC;berpr&#xFC;ft <mark>nicht</mark>\n<mark>jede</mark> Instruktion vor der Ausf&#xFC;hrung (vgl.\n<strong>Teil</strong>interpretation).</p>\n","correct":false,"option":"<p>Das Betriebssystem erkennt die ung&#xFC;ltige Adresse vor Ausf&#xFC;hrung des\nMaschinenbefehls und lagert die Seite zuerst ein bevor ein Trap\npassiert.</p>\n"},{"option":"<p>Bei Programmen, die in virtuellen Adressr&#xE4;umen ausgef&#xFC;hrt werden\nsollen, erzeugt der Compiler speziellen Code, der vor Betreten einer\nSeite die Anwesenheit &#xFC;berpr&#xFC;ft und ggf. die Einlagerung veranlasst.</p>\n","correct":false,"comment":"<p>Nein, der Compiler f&#xFC;gt <mark>nicht</mark> in <mark>jedes</mark>\nProgramm eine Implementation der Speichervirtualisierung ein. Diese ist\neine Aufgabe des Betriebssystems und <mark>nicht</mark> der einzelnen\nBenutzerprogramme.</p>\n"}],"id":"HVzfbnOpqmU+BVzEsuTFCw","question":"<p>Wie wird erkannt, dass eine Seite eines virtuellen Adressraums, auf\ndie ein Maschinenbefehl zugreift, gerade ausgelagert ist?</p>\n"},{"multiple":false,"options":[{"option":"<p>Wenn der gleiche Seitenrahmen in zwei verschiedenen\nSeitendeskriptoren eingetragen wird, l&#xF6;st dies einen Seitenfehler aus\n(Gefahr von Zugriffskonflikten!).</p>\n","correct":false,"comment":"<p>Nein, das w&#xFC;rde z. B. zwischen Prozessen geteilten Speicher\nverhindern.</p>\n"},{"correct":false,"option":"<p>Ein Seitenfehler wird ausgel&#xF6;st, wenn der Offset in einer logischen\nAdresse gr&#xF6;&#xDF;er als die L&#xE4;nge der Seite ist.</p>\n","comment":"<p>Nein, dieser Fall <mark>kann</mark> per Definition <mark>nicht</mark>\neintreten. Seiten haben eine Gr&#xF6;&#xDF;e von 2<sup>n</sup> Byte, (bei x86-64\nz. B. 4 KiB), n Byte der Adresse werden als Offset interpretiert. Somit\nist dieser Fall au&#xDF;erhalb des &#xFC;berhaupt darstellbaren Wertebereichs f&#xFC;r\nden Offset. Im Gegensatz dazu wird bei Segmentierung &#xFC;berpr&#xFC;ft, ob die\nlogische Adresse im Speichersegment liegt, das dem Prozess zugeordnet\nist. Dort k&#xF6;nnte also ein derartiger Fehler auftreten.</p>\n"},{"comment":"<p>Nein, ein Seitenfehler <mark>kann</mark> auch dadurch ausgel&#xF6;st\nwerden, dass z. B. auf eine ausgelagerte Seite zugegriffen wird. Diese\nwird dann f&#xFC;r den Prozess transparent eingelagert. Zudem l&#xF6;st die MMU\nein Trap aus, welches sp&#xE4;ter zur Zustellung eines Signals f&#xFC;hren kann.\nJedoch schickt sie <mark>nicht</mark> selbst Signale an Prozesse.</p>\n","correct":false,"option":"<p>Ein Seitenfehler zieht eine Ausnahmebehandlung nach sich. Diese wird\ndadurch ausgel&#xF6;st, dass die MMU das Signal SIGSEGV an den aktuell\nlaufenden Prozess schickt.</p>\n"},{"correct":true,"option":"<p>Das Auftreten eines Seitenfehlers <mark>kann</mark> dazu f&#xFC;hren, dass\nder aktuell laufende Prozess in den Zustand beendet &#xFC;berf&#xFC;hrt wird.</p>\n","comment":"<p>Ja, wenn der Prozess auf eine ung&#xFC;ltige Adresse zugreift, also\ninsbesondere auch <mark>keine</mark> Seite eingelagert werden\n<mark>kann</mark> und das entsprechende Signal <mark>nicht</mark>\nabgefangen wird, wird er terminiert.</p>\n"}],"source":"2022-02","question":"<p>Welche der folgenden Aussagen zum Thema Seitenfehler (<em>Page\nFault</em>) ist richtig?</p>\n","id":"dDDPGpVkEgdc+YIuPMM/Dg"},{"question":"<p>Gegeben seien die folgenden Pr&#xE4;prozessor-Makros:</p>\n<pre><code>#define ADD(a, b) a + b\n#define DIV(a, b) a / b</code></pre>\n<p>Was ist das Ergebnis des folgenden Ausdrucks?</p>\n<pre><code>3 * DIV(ADD(4, 8), 2)</code></pre>\n","source":"2021-02","options":[{"option":"<p>18</p>\n","correct":false},{"correct":false,"option":"<p>10</p>\n"},{"option":"<p>24</p>\n","correct":false},{"correct":true,"option":"<p>16</p>\n","comment":"<p>Ja. Makros, die mit <code>#define</code> definiert sind, werden rein\ntextuell vor dem eigentlichen Kompiliervorgang vom Pr&#xE4;prozessor\nexpandiert, indem an der Stelle, an der das Makro verwendet wird, die\nDefinition dessen, bis auf Ersetzung der Parameter mit dem angegebenen\nText, unver&#xE4;ndert eingesetzt wird. Hier wird also nach dem\nPr&#xE4;prozessor-Schritt der folgende Ausdruck kompiliert:\n<code>3 * 4 + 8 / 2</code>. Das ergibt 16. Dieses Problem k&#xF6;nnte hier\ndurch das Einklammern der Definitionen gel&#xF6;st werden.</p>\n"}],"id":"7KkS/9d6d85Ny6cI5Ayh3g","multiple":false},{"options":[{"comment":"<p>Nein. Bei <em>round-robin</em> wird <mark>jedem</mark> Prozess reihum\neine gleich lange Zeitscheibe zugeteilt. Ein E/A-intensiver Prozess, der\noft fr&#xFC;h in seiner Zeitscheibe durch eine E/A-Operation in den Zustand\n<q>blockiert</q> &#xFC;bergeht, <mark>kann</mark> seine Zeitscheibe\n<mark>nicht</mark> bis zum Ende ausnutzen.</p>\n","option":"<p>Im Round-Robin-Verfahren nutzen E/A-intensive Prozesse die ihnen\nzugeteilte Zeitscheibe <mark>immer</mark> voll aus</p>\n","correct":false},{"correct":false,"comment":"<p>Nein. Insbesondere dort <mark>muss</mark> ein Prozess, der nur einen\nkurzen Rechensto&#xDF; macht, <mark>alle</mark> l&#xE4;nger dauernden Rechenst&#xF6;&#xDF;e\nin der Warteschlange abwarten.</p>\n","option":"<p>Der Konvoieffekt <mark>kann</mark> bei kooperativen\nEinplanungsverfahren wie First-Come-First-Served <mark>nicht</mark>\nauftreten.</p>\n"},{"correct":false,"option":"<p>Bei kooperativen Verfahren k&#xF6;nnen Prozesse die CPU <mark>nicht</mark>\nmonopolisieren.</p>\n","comment":"<p>Nein. Genau bei kooperativen Verfahren, bei denen Prozesse die CPU\nfreiwillig abgeben m&#xFC;ssen, ist dies m&#xF6;glich. Pr&#xE4;emptive Verfahren k&#xF6;nnen\nim Gegensatz dazu derartige Prozesse unterbrechen.</p>\n"},{"correct":true,"option":"<p>In einem asymmetrischen Multiprozessorsystem ist der Einsatz von\nasymmetrischen Verfahren zur Planung obligatorisch.</p>\n","comment":"<p>Ja. Man betrachte z. B. den Fall CPU + GPU. Ein Prozess, der auf der\nCPU rechnen m&#xF6;chte, <mark>kann</mark> <mark>nicht</mark> unbedingt auch\nauf der GPU rechnen. Deswegen ist der Einsatz einer Bereitliste f&#xFC;r\n<mark>alle</mark> Rechenkerne (symmetrisches Planungsverfahren) hier\nunm&#xF6;glich. Stattdessen m&#xFC;ssen zumindest f&#xFC;r GPU und CPU separate\nBereitlisten existieren. Dies zeichnet asymmetrische Planungsverfahren\naus.</p>\n"}],"multiple":false,"id":"Nr5YhHIOjHM+a5PhRK57hw","question":"<p>Welche Aussage &#xFC;ber Einplanungsverfahren ist richtig?</p>\n","source":"2021-02"},{"source":"2021-02","question":"<p>Welche Aussage zu virtuellem Speicher ist richtig?</p>\n","id":"ezwKVysW6W4hLJVZ7ELoJg","multiple":false,"options":[{"correct":false,"option":"<p>Virtueller Speicher sind die <mark>nicht</mark> vorhandenen Bereiche\ndes physikalischen Adressraums.</p>\n","comment":"<p>Nein. Mit virtuellem Speicher ist kein Bereich des physikalischen\nAdressraums gemeint. Stattdessen bezeichnet man damit die partielle\nAbbildung vom logischen zum physikalischen Adressraum.</p>\n"},{"comment":"<p>Nein. Die Implementation von <code>malloc</code> <mark>kann</mark>\ndas Betriebssystem dazu auffordern (<code>mmap(2)</code>,\n<code>brk(2)</code>), den verf&#xFC;gbaren Speicherbereich des Prozesses zu\nvergr&#xF6;&#xDF;ern. Benutzerprogramme k&#xF6;nnen jedoch <mark>nicht</mark> selbst\ndie Abbildung von virtuellen Adressen zu physikalischen Adressen\n&#xE4;ndern.</p>\n","option":"<p>Virtueller Speicher <mark>kann</mark> dynamisch zur Laufzeit von\neinem Programm mit der Funktion <code>malloc(3p)</code> erzeugt\nwerden.</p>\n","correct":false},{"correct":false,"comment":"<p>Nein. Die <em>memory management unit</em> &#xFC;bersetzt logische Adressen\nauf physikalische.</p>\n","option":"<p>Unter einem Virtuellen Speicher versteht man einen physikalischen\nAdressraum, dessen Adressen durch eine MMU vor dem Zugriff auf logische\nAdressen umgesetzt werden.</p>\n"},{"correct":true,"comment":"<p>Ja. Das bezeichnet man als <em>swapping</em>.</p>\n","option":"<p>Virtueller Speicher <mark>kann</mark> gr&#xF6;&#xDF;er sein als der\nphysikalisch vorhandene Arbeitsspeicher. Gerade <mark>nicht</mark>\nben&#xF6;tigte Speicherbereiche k&#xF6;nnen auf Hintergrundspeicher ausgelagert\nwerden.</p>\n"}]},{"multiple":false,"id":"kpVUiv2Naj7Ss58X5HVClg","options":[{"option":"<p>Bei allen RAID-Systemen ist ein h&#xF6;herer Lese-Durchsatz als bei einer\neinzelnen Platte m&#xF6;glich, da mehrere Platten gleichzeitig beauftragt\nwerden k&#xF6;nnen.</p>\n","comment":"<p>Ja, bei allen in SP betrachteten Systemen wird dies als Vorteil\ngenannt.</p>\n","correct":true},{"correct":false,"option":"<p>Bei RAID 4 Systemen wird Parit&#xE4;tsinformation gleichm&#xE4;&#xDF;ig &#xFC;ber\n<mark>alle</mark> beteiligten Platten verteilt.</p>\n","comment":"<p>Nein. Das w&#xE4;re RAID 5. Bei RAID 4 gibt es eine designierte\nParit&#xE4;tsplatte.</p>\n"},{"correct":false,"option":"<p>RAID 0 erzielt Fehlertoleranz durch das Verteilen der Daten auf\nmehrere Platten.</p>\n","comment":"<p>Nein. RAID 0 erzielt <mark>keine</mark> Fehlertoleranz sondern erh&#xF6;ht\nnur die Lese- und Schreibgeschwindigkeit.</p>\n"},{"correct":false,"option":"<p>Bei RAID 4 und 5 darf eine bestimmte Menge von Festplatten\n<mark>nicht</mark> &#xFC;berschritten werden, da es sonst <mark>nicht</mark>\nmehr m&#xF6;glich ist, die Parit&#xE4;tsinformation zu bilden</p>\n","comment":"<p>Nein. Derartige Einschr&#xE4;nkungen existieren nicht.</p>\n"}],"source":"2021-02","question":"<p>Beim Einsatz von RAID-Systemen <mark>kann</mark> durch zus&#xE4;tzliche\nFestplatten Fehlertoleranz erzielt werden. Welche Aussage dazu ist\nrichtig?</p>\n"},{"options":[{"correct":false,"comment":"<p>Nein. Systemaufrufe werden deterministisch ausgef&#xFC;hrt, also werden\nsie der Kategorie Trap zugeordnet.</p>\n","option":"<p>Weil das Betriebssystem <mark>nicht</mark> vorhersagen kann, wann ein\nProzess einen Systemaufruf t&#xE4;tigt, sind Systemaufrufe in die Kategorie\nInterrupt einzuordnen.</p>\n"},{"comment":"<p>Nein. Das w&#xE4;re die Definition von Traps. Interrupts, wie z. B. das\nEintreffen eines Netzwerkpakets treten ohne direkten Zusammenhang zum\nunterbrochenen Prozess auf.</p>\n","option":"<p>Bei der mehrfachen Ausf&#xFC;hrung eines unver&#xE4;nderten Programms mit\ngleichen Eingabedaten treten Interrupts <mark>immer</mark> an den\ngleichen Stellen auf.</p>\n","correct":false},{"option":"<p>Ein gerade laufendes Maschinenprogramm <mark>kann</mark> bei Bedarf\ndie Behandlung aller Programmunterbrechungen unterdr&#xFC;cken.</p>\n","comment":"<p>Nein. Das Unterdr&#xFC;cken von Interrupts ist eine privilegierte\nOperation, die dem Betriebssystem vorbehalten ist. (Das w&#xFC;rde sonst z.\nB. einem Benutzerprozess das Umgehen einer pr&#xE4;emptiven Einplanung\nerm&#xF6;glichen)</p>\n","correct":false},{"option":"<p>Normale Rechenoperationen k&#xF6;nnen zu einem Trap f&#xFC;hren.</p>\n","comment":"<p>Ja, wenn z. B. <a\nhref=\"https://www.felixcloutier.com/x86/div\">Division auf x86_64</a> mit\neinem Divisor von 0 ausgef&#xFC;hrt wird.</p>\n","correct":true}],"multiple":false,"id":"dfX3iU2hvR0ugBosKP0nKw","question":"<p>Man unterscheidet Programmunterbrechungen in Traps und Interrupts.\nWelche Aussage ist richtig?</p>\n","source":"2021-02"},{"options":[{"comment":"<p>Wahr, weil im physikalischem Addressraum <mark>nicht</mark>\n<mark>alle</mark> Addressen g&#xFC;ltig sind. Teilweise bestehen L&#xFC;cken, und\nje nach Addressbreite, wird es Addressen geben welche &#xFC;ber den\nverf&#xFC;gbaren Speicher hinaus zeigen.</p>\n","option":"<p>Der Zugriff auf eine physikalische Speicheradresse <mark>kann</mark>\nzu einem Trap f&#xFC;hren.</p>\n","correct":true},{"option":"<p>Normale Ganzzahl-Rechenoperationen (z. B. Addition, Division) k&#xF6;nnen\n<mark>nicht</mark> zu einem Trap f&#xFC;hren.</p>\n","correct":false,"comment":"<p>Doch, k&#xF6;nnen zu einem Trap f&#xFC;hren. Vergleiche Division durch 0 auf\nx86 Prozessoren.</p>\n"},{"comment":"<p>Doch, ein Trap wird <mark>immer</mark> durch einen internen Fehler\nausgel&#xF6;st. Im Gegensatz dazu ist dieses beim einem Interrupt\n<mark>nicht</mark> gegeben, weil die Ursache hier von au&#xDF;en kommt.</p>\n","option":"<p>Ein Trap steht <mark>nicht</mark> zwangsl&#xE4;ufig in urs&#xE4;chlichem\nZusammenhang mit dem unterbrochenen Programm.</p>\n","correct":false},{"comment":"<p>Nein, werden nach dem Beendigungsmodell und Wiederaufnahmemodell\nbehandelt.</p>\n","correct":false,"option":"<p>Traps werden <mark>immer</mark> nach dem\nBeendigungsmodell/Terminierungsmodell behandelt.</p>\n"}],"question":"<p>Bei Programmunterbrechungen (Ausnahmen) unterscheidet man zwischen\nTraps und Interrupts. Welche Aussage zu Traps ist richtig?</p>\n","source":"2020-08","id":"SlCLnCGqS2Ij8RIz0uTdRQ","multiple":false},{"multiple":false,"id":"EggpH6ZjljibK5eo1/XUAg","source":"2020-08","question":"<p>Welche der folgenden Aussagen &#xFC;ber UNIX-Dateisysteme ist richtig?</p>\n","options":[{"correct":false,"option":"<p>Wenn der letzte symbolic link, der auf eine Datei verweist, gel&#xF6;scht\nwird, wird auch der zugeh&#xF6;rige Dateikopf (inode) gel&#xF6;scht.</p>\n","comment":"<p>Nein, Symbolic Links sind nur Referenzen sind <mark>nicht</mark>\ndirekt mit einer Datei verbunden, im Sinne dass der einzige Weg zu\nbestimmen ob ein Symbolic Link auf eine Datei besteht, es w&#xE4;re\n<mark>alle</mark> Symbolic Links im Dateisystem zu pr&#xFC;fen, weil diese\nInformation ansonsten nirgends zentral gespeichert wird.</p>\n"},{"comment":"<p>Nein, ein Hard Link bezieht sich auf Dateien im Dateisystem,\n<mark>nicht</mark> auf beliebige Bl&#xF6;cke. Die Dateien selbst werden sich\nauf Bl&#xF6;cke im Datentr&#xE4;gers beziehen.</p>\n","option":"<p>Hard links k&#xF6;nnen innerhalb des selben Datentr&#xE4;gers auf beliebige\nBl&#xF6;cke zeigen.</p>\n","correct":false},{"comment":"<p>Doch, in <mark>jedem</mark> Verzeichnis verweist der <code>.</code>\n(<q>hier</q>) Eintrag auf das Verzeichnis selbst. Daher hat auch\n<mark>jedes</mark> Verzeichnis mindestens einen <q>nlink</q> (Anzahl\nVerweise auf diesen Inode) von 2, weil es von sich selbst und vom\nOberverzeichnis verwiesen wird (Ausnahme, das Root-Verzeichnis\n<code>/</code>, wo <code>.</code> und <code>..</code> beides Verweise\nauf sich selbst sind).</p>\n","option":"<p>In einem Verzeichnis darf es keinen Eintrag geben, der auf das\nVerzeichnis selbst verweist.</p>\n","correct":false},{"option":"<p>F&#xFC;r Zugriff &#xFC;ber verschiedene Hard links auf die selbe Datei gelten\nidentische Zugriffsrechte.</p>\n","correct":true,"comment":"<p>Ja, weil diese Informationen im Inode gespeichert werden unabh&#xE4;ngig\nvom Pfad, und <mark>nicht</mark> im Verzeichnis. W&#xFC;rde es im Verzeichnis\ngespeichert sein, dann k&#xF6;nnte man f&#xFC;r <mark>jede</mark> Instanz einer\nDatei in einem Verzeichnis verschiedene Zugriffsrechte vergeben. Weil\naber ein Verzeichnis nur eine Abbildung von Datei-Namen im Verzeichnis\nzu Inodes sind, ist das <mark>nicht</mark> m&#xF6;glich.</p>\n"}]},{"id":"HG7LH9O75oMlkxr8iCly5Q","source":"2020-08","options":[{"correct":false,"option":"<p>Das Ph&#xE4;nomen der Priorit&#xE4;tsumkehr hungert niedrigpriore Prozesse\naus.</p>\n","comment":"<p>Nein, es ist <q>das einem nachrangigen Prozess den Vorzug gegen&#xFC;ber\neinen vorrangigen Prozess gibt</q> (Woschglossar).</p>\n"},{"option":"<p>Ein hochpriorer Prozesse <mark>muss</mark> eventuell auf ein\nBetriebsmittel warten, das von einem niedrigprioren Prozess exklusiv\nbenutzt wird. Der niedrigpriore Prozess <mark>kann</mark> das\nBetriebsmittel jedoch wegen eines mittelhochprioren Prozesses\n<mark>nicht</mark> freigeben (Priorit&#xE4;tenumkehr).</p>\n","correct":true,"comment":"<p>Ja, siehe Woschglossar:</p>\n<blockquote>\n<p>Im Ergebnis beh&#xE4;lt ein Prozess niedriger Priorit&#xE4;t den Prozessor,\nobwohl ein Prozess h&#xF6;herer Priorit&#xE4;t darauf wartet, den Prozessor\nzugeteilt zu bekommen. Die Ursache daf&#xFC;r ist m&#xF6;glicherweise eine zuvor\ngeschehene Priorit&#xE4;tsverletzung bei der Zuteilung eines Betriebsmittels\nan einen darauf wartenden Prozess</p>\n</blockquote>\n"},{"comment":"<p>Nein, die Effizienz einer Auswahlstrategie sollte <mark>nicht</mark>\nvon der Anzahl an Prozessen welche Warten abh&#xE4;ngen.</p>\n","option":"<p>Eine priorit&#xE4;tenbasierte Auswahlstrategie arbeitet sehr ineffizient,\nwenn viele Prozesse im Zustand bereit sind.</p>\n","correct":false},{"option":"<p>Priorit&#xE4;tenbasierte Auswahlstrategien f&#xFC;hren zwangsl&#xE4;ufig zur\nAushungerung von Prozessen, wenn mindestens zwei verschiedene\nPriorit&#xE4;ten vergeben werden.</p>\n","correct":false,"comment":"<p>Nein, weil eine Prirorit&#xE4;tsebene eine andere <mark>nicht</mark>\ndominiert, sondern nur bevorzugt behandelt wird.</p>\n"}],"question":"<p>Bei einer priorit&#xE4;tengesteuerten Prozessauswahl-Strategie\n(Scheduling-Strategie) <mark>kann</mark> es zu Problemen kommen. Welches\nder folgenden Probleme <mark>kann</mark> auftreten?</p>\n","multiple":false},{"id":"fP9t0/HjTw+2bv6GdfxXUg","source":"2020-08","question":"<p>Welche der folgenden Aussagen zum Thema persistenter Datenspeicherung\nsind richtig?</p>\n","options":[{"comment":"<p>Ja, weil es unter Umst&#xE4;nden das umherbewegen von anderen Dateien,\nbzw. der zu vergr&#xF6;&#xDF;ernden Datei ben&#xF6;tigt, damit genug Speicher vorhanden\nist um die Datei kontinuierlich zu speichern.</p>\n","correct":true,"option":"<p>Bei kontinuierlicher Speicherung von Daten ist es unter Umst&#xE4;nden mit\nenormem Aufwand verbunden, eine bestehende Datei zu vergr&#xF6;&#xDF;ern.</p>\n"},{"option":"<p>Bei indizierter Speicherung <mark>kann</mark> es prinzipbedingt\n<mark>nicht</mark> zu Verschnitt kommen.</p>\n","correct":false,"comment":"<p>Doch, der Bl&#xF6;cke sind zwar <mark>alle</mark> gleich gro&#xDF;, k&#xF6;nnen aber\ntrotzdem teilweise <mark>nicht</mark> komplett gef&#xFC;llt sein. Au&#xDF;erdem\nbesteht ein Konflikt zwischen den Index-Knoten-Segment und dem\nDatei-Segment, wo wenn die Index-Knoten-Tabelle zu viele kleine Dateien\nenth&#xE4;lt, es <mark>nicht</mark> mehr m&#xF6;glich ist neue Dateien zu\nerstellen, obwohl der Speicher hierf&#xFC;r verf&#xFC;gbar ist.</p>\n"},{"option":"<p>Im Vergleich zu den anderen Verfahren ist bei indizierter Speicherung\ndie Positionierzeit des Festplatten-Armes beim Zugriff auf\n<mark>alle</mark> Datenbl&#xF6;cke einer Datei minimal.</p>\n","correct":false,"comment":"<p>Nein, indizierter Speicherung hat per se keinen Einfluss darauf wie\nAufwendig die Positionierung f&#xFC;r einen beliebigen Datenblock ist. Was\naufwendiger sein kann, ist es mehre Bl&#xF6;cke nacheinander auszulesen,\nwelche <mark>nicht</mark> konservativ abgespeichert werden m&#xFC;ssen.</p>\n"},{"comment":"<p>Doch, bspw. benutzen Ext4, Btrfs, NTFS diese.</p>\n","option":"<p>Extents finden aus Performanzgr&#xFC;nden <mark>keine</mark> Anwendung in\nmodernen Dateisystemen.</p>\n","correct":false}],"multiple":false},{"multiple":false,"id":"Qp+uA7LqmWu9XwKrkBZVow","options":[{"correct":false,"option":"<p>Auf Multiprozessorsystemen <mark>kann</mark> die Umschaltung von\nKern-Threads ohne Mitwirken des Systemkerns erfolgen.</p>\n","comment":"<p>Nein, bei Kern-Threads ist System erforderlich.</p>\n"},{"option":"<p>Kern-Threads teilen sich den kompletten Adressraum und verwenden\ndaher den selben Stack.</p>\n","correct":false,"comment":"<p>Nein, nur weil der Addressraum geteilt wird, <mark>muss</mark> man\n<mark>nicht</mark> den gleichen Stack benutzen.</p>\n"},{"option":"<p>Bei User-Threads ist die Schedulingstrategie <mark>keine</mark>\nFunktion des Betriebssystemkerns.</p>\n","correct":true,"comment":"<p>Ja, diese ist teil des Programms (&#xFC;blicherweise der\nProgrammiersprache oder einer Bibliothek), und arbeitet unabh&#xE4;ngig von\nder globalen Strategie des Betriebssystems.</p>\n"},{"comment":"<p>Nein, findet nur bei Kernel-Threads im Systemkern statt.</p>\n","correct":false,"option":"<p>Die Umschaltung von Threads <mark>muss</mark> <mark>immer</mark> im\nSystemkern erfolgen (privilegierter Maschinenbefehl).</p>\n"}],"question":"<p>Welche der folgenden Aussagen zum Thema Threads ist richtig?</p>\n","source":"2020-08"},{"id":"3o+cnDFkJQQ2SAeGfVYkKA","options":[{"option":"<p>Ein Semaphor <mark>kann</mark> ausschlie&#xDF;lich f&#xFC;r mehrseitige\nSynchronisation verwendet werden.</p>\n","correct":false,"comment":"<p>Nein, <mark>kann</mark> f&#xFC;r einseitige und mehrseitige\nSynchronisation verwendet werden.</p>\n"},{"correct":false,"option":"<p>Zur Synchronisation eines kritischen Abschnitts ist passives Warten\n<mark>immer</mark> besser geeignet als aktives Warten.</p>\n","comment":"<p>Nein. Aktives Warten ben&#xF6;tigt <mark>keine</mark> Unterst&#xFC;tzung durchs\nBetriebssystem (welches <mark>nicht</mark> <mark>immer</mark> gegeben\nist) und vergeudet <mark>nicht</mark> <mark>immer</mark> CPU-Zeit\ngegen&#xFC;ber passivem Warten.</p>\n"},{"comment":"<p>Nein, zum Beispiel mittels CAS, welches durch einen Befehl der\nRecherarchitektur umgesetzt wird, bspw auf x86 <a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_41.html\"><code>CMPXCHG</code></a>.</p>\n","option":"<p>F&#xFC;r nicht-blockierende Synchronisationsverfahren ist spezielle\nUnterst&#xFC;tzung durch das Betriebssystem notwendig.</p>\n","correct":false},{"option":"<p>Monitore sind Datentypen mit impliziten\nSynchronisationseigenschaften.</p>\n","correct":true,"comment":"<p>Wahr, im Woschglossar wird es als ADT (Abstrakter Datentyp)\nbeschrieben, dass in einer Programmiersprache wie C oder C++ eingesetzt\nwird, aber in anderer Literatur wird es haupts&#xE4;chlich als Eigenschaft\neiner Programmiersprache umgesetzt. Als ein Beispiel wo Nebenl&#xE4;ufigkeit\nund Synchronisation <mark>nicht</mark> innerhalb einer Sprache umgesetzt\nwerden, sondern primitiven der Sprache selbst (in C w&#xE4;ren Funktionen\nprimitiven, aber die Pthread Funktionalit&#xE4;t wird mittels Funktionen\nbereitgestellt) sind ist Ada mit dem Konzept von <a\nhref=\"https://learn.adacore.com/courses/intro-to-ada/chapters/tasking.html\">Tasks</a>.</p>\n"}],"question":"<p>Welche der folgenden Aussagen zum Thema Synchronisation sind\nrichtig?</p>\n","source":"2020-08","multiple":false},{"id":"FrK7iJ9KzjjrHKAlT19yPA","source":"2020-08","options":[{"comment":"<p>Nein, beispielsweise <mark>kann</mark> es schneller sein wenn\n<mark>nicht</mark> gewartet werden muss, weil es einen geringeren\nOverhead hat.</p>\n","correct":false,"option":"<p>Aktives Warten vergeudet gegen&#xFC;ber passivem Warten <mark>immer</mark>\nCPU-Zeit.</p>\n"},{"comment":"<p>Doch, es betrifft auch andere, weil beim Warten die CPU\n<mark>immer</mark> noch benutzt wird, biss der Prozess verdr&#xE4;ngt\n(<em>preempted</em>) wird. Bei passivem Warten w&#xFC;rde der Prozess in den\nZustand <q>blokiert</q> &#xFC;bergehen, und damit auch die CPU\n<mark>nicht</mark> mehr benutzen, bis es von anderer Seite wieder als\n<q>bereit</q> markiert wird.</p>\n","option":"<p>Bei verdr&#xE4;ngenden Scheduling-Strategien verz&#xF6;gert aktives Warten nur\nden betroffenen Prozess, behindert aber <mark>nicht</mark> andere.</p>\n","correct":false},{"correct":true,"option":"<p>Aktives Warten darf bei nicht-verdr&#xE4;ngenden Scheduling-Strategien auf\neinem Monoprozessorsystem <mark>nicht</mark> verwendet werden.</p>\n","comment":"<p>Wahr, weil ansonsten die CPU hoffnungslos monopolisiert wird, und es\n<mark>nicht</mark> mehr m&#xF6;glich w&#xE4;re, dass ein anderer Prozess die\nWarte-Bedingung aufhebt (eine Ausnahme hier k&#xF6;nnte das Warten auf Daten\nin I/O-Registern sein, welche von <q>externen (physikalischen)\nProzessen</q> manipuliert werden).</p>\n"},{"correct":false,"option":"<p>Auf Mehrprozessorsystemen ist aktives Warten unproblematisch und\ndeshalb dem passiven Warten <mark>immer</mark> vorzuziehen.</p>\n","comment":"<p>Falsch, die Nachteile bleiben bestehen, es wird nur\n<mark>nicht</mark> das gesamte System w&#xE4;hrend der Zeitscheibe\nmonopolisiert.</p>\n"}],"question":"<p>Welche der folgenden Aussagen zum Thema <q>Aktives Warten</q> ist\nrichtig?</p>\n","multiple":false},{"id":"oxOfnlrBEniIpwM0r3IthA","question":"<p>Welche der folgenden Aussagen zum Thema Seitenfehler (page fault) ist\nrichtig?</p>\n","options":[{"comment":"<p>Nein, die MMU sendet ein Trap an das BS. Signale werden vom\nBetriebsystem an Prozesse geschickt.</p>\n","option":"<p>Ein Seitenfehler zieht eine Ausnahmebehandlung nach sich. Diese wird\ndadurch ausgel&#xF6;st, dass die MMU das Signal SIGSEGV an den aktuell\nlaufenden Prozess schickt.</p>\n","correct":false},{"option":"<p>Seitenfehler k&#xF6;nnen auch auftreten, obwohl die entsprechende Seite\ngerade im physikalischen Speicher vorhanden ist.</p>\n","correct":true,"comment":"<p>Korrekt, beispielsweise wenn versucht wird auf eine Read-Only Seite\nzu schreiben.</p>\n"},{"comment":"<p>Nein, das ist m&#xF6;glich und wird benutzt um die Kosten von\n<code>fork(2)</code> zu minimieren, werden die gleichen Seiten im\nphysikalischem Speicher in verschiedenen Logischen Addressr&#xE4;umen\neingeblendet (siehe <em>Copy on Write</em>), oder wenn dynamische\nBibliothek, dessen Seiten ausf&#xFC;hrbare und <mark>nicht</mark>\nbeschreibbar sind, nur einmal geladen und dann von allen Programmen die\nes benutzen geteilt wird.</p>\n","correct":false,"option":"<p>Wenn der gleiche Seitenrahmen in zwei verschiedenen\nSeitendeskriptoren eingetragen wird, l&#xF6;st dies einen Seitenfehler aus\n(Gefahr von Zugriffskonflikten!).</p>\n"},{"option":"<p>Ein Seitenfehler wird ausgel&#xF6;st, wenn der Offset in einer logischen\nAdresse gr&#xF6;&#xDF;er als die L&#xE4;nge der Seite ist.</p>\n","correct":false,"comment":"<p>Nein, was diese Frage vertauscht ist Paging und Segmentation, wo beim\nletzteren ein Segmentations-Fehler auftreten kann, wenn der Offset &#xFC;ber\ndie Gr&#xF6;&#xDF;e des Segments hinausreicht. Beim Paging sind i.d.R.\n<mark>alle</mark> Seiten gleich gro&#xDF;.</p>\n"}],"source":"2020-08","multiple":false},{"multiple":false,"id":"v7FCYtRTwfkGzyTUmHcalw","question":"<p>Welches der folgenden Verfahren tr&#xE4;gt in der Praxis am besten dazu\nbei, die Auswirkungen eines Seitenfehlers zu minimieren?</p>\n","options":[{"correct":false,"option":"<p>Man lagert regelm&#xE4;&#xDF;ig l&#xE4;nger <mark>nicht</mark> genutzte Seiten aus\nund tr&#xE4;gt sie in einem Freiseitenpuffer ein.</p>\n","comment":"<p>Nein, der Freiseitenpuffer soll es erleichtern ausgelagerte Seiten\nwieder einzulagern, ohne <em>genau dann</em> daf&#xFC;r eine andere Seite\nbestimmen zu m&#xFC;ssen, welche ausgelagert werden soll daf&#xFC;r.\n<em>Regelm&#xE4;&#xDF;ig</em> daf&#xFC;r Seiten auszulagern w&#xFC;rde kontraproduktiv sein,\nweil man dann &#xFC;ber einen Punkt der hilfreichen Flexibilit&#xE4;t hinaus mehr\nSeiten auslagern w&#xFC;rde als notwendig, welche dann nur wieder eingelagert\nwerden m&#xFC;ssten.</p>\n<p>(Siehe auch diesen <a\nhref=\"https://forum.fsi.cs.fau.de/t/sinn-des-freiseitenpuffers/16912\">FSI-Forums</a>\nFaden)</p>\n"},{"comment":"<p>Nein, weil meine Zeitmaschine gerade noch kaputt ist. Ich warte aber\nnoch auf eine Lieferung aus der Zunkunft, dann wird das schon wieder\nfunktionieren. Bis dahin ist es aber <mark>nicht</mark> m&#xF6;glich\nvorherzusehen was das Programm in der Zunkunft machen wird.</p>\n","correct":false,"option":"<p>Man ermittelt, welche der Seiten eines Prozesses in Zukunft am\nl&#xE4;ngsten <mark>nicht</mark> angesprochen wird und lagert genau diese aus\n(OPT Strategie).</p>\n"},{"comment":"<p>Ja, das nennt man <a\nhref=\"https://en.wikipedia.org/wiki/Memory_segmentation#Segmentation_with_paging\"><q>Paged\nSegmentation</q></a> und ist eine Kombination beider Ans&#xE4;tze.</p>\n","correct":true,"option":"<p>Man setzt eine Segmentierung in Kombination mit Seitenadressierung\nein.</p>\n"},{"option":"<p>Man &#xFC;bergibt Prozesse, die einen Seitenfehler verursachen der\nmittelfristigen Prozesseinplanung, damit sie in n&#xE4;chster Zeit\n<mark>nicht</mark> wieder aktiv werden.</p>\n","correct":false,"comment":"<p>Nein, das w&#xFC;rde das Problem <mark>nicht</mark> l&#xF6;sen weil\nSeitenfehler Traps sind, und daher deterministisch auftreten</p>\n"}],"source":"2020-08"},{"source":"2020-08","question":"<p>Welche der folgenden Aussagen zum Thema Prozesszust&#xE4;nde sind\nrichtig?</p>\n","options":[{"comment":"<p>Ja, da pro laufendem Prozess eine CPU ben&#xF6;tigt wird. Es ist dabei gut\nsich daran zu erinnern, dass mache Zust&#xE4;nde eher als Konzepte zu\nverstehen sein, und dass dieser Zustand <mark>nicht</mark> unbedingt\ndurch ein <code>enum</code> am besten dargestellt wird, sondern durch\ndas Verhalten.</p>\n","correct":true,"option":"<p>Es k&#xF6;nnen sich maximal genauso viele Prozesse gleichzeitig im Zustand\nlaufend befinden, wie Prozessorkerne vorhanden sind.</p>\n"},{"option":"<p>Im Rahmen der mittelfristigen Einplanung <mark>kann</mark> ein\nProzess von Zustand laufend in den Zustand schwebend laufend\nwechseln.</p>\n","correct":false,"comment":"<p>Nein, die <q>schwebenden</q> Variationen von <q>bereit</q> und\n<q>blokiert</q> beziehen sich darauf, dass Teile des virtuellen\nAddressraums <mark>nicht</mark> bewusst mehr eingelagert sind, was bei\nlaufenden Prozessen <mark>nicht</mark> sinnvoll w&#xE4;re.</p>\n"},{"correct":false,"option":"<p>Bei Eintreffen eines Interrupts wird der aktuell laufende Prozess f&#xFC;r\ndie Dauer der Interrupt-Abarbeitung in den Zustand blockiert\n&#xFC;berf&#xFC;hrt.</p>\n","comment":"<p>Nein, <mark>nicht</mark> direkt, weil Interrupts und deren Behandlung\neinen Prozess nur unterbrechen und dessen Zustand <mark>nicht</mark>\nver&#xE4;ndern. Es ist jedoch m&#xF6;glich, dass die Behandlung des Interrupts\ndieses zur Folge h&#xE4;tte.</p>\n"},{"correct":true,"option":"<p>Ein Prozess <mark>kann</mark> nur durch seine eigene Aktivit&#xE4;t vom\nZustand laufend in den Zustand blockiert &#xFC;berf&#xFC;hrt werden.</p>\n","comment":"<p>Ja, per Definition <mark>kann</mark> ein Prozess nur durch sein\neigenes Verhalten in den Zustand <q>blockiert</q> &#xFC;berf&#xFC;hrt werden.</p>\n"},{"correct":true,"option":"<p>Das Auftreten eines Seitenfehlers <mark>kann</mark> dazu f&#xFC;hren, dass\nder aktuell laufende Prozess in den Zustand beendet &#xFC;berf&#xFC;hrt wird.</p>\n","comment":"<p>Wahr, bspw. wenn dem Prozess Aufgrund ein <code>SIGSEGV</code>\nzugestellt wird, welches in seinen default Einstellungen den betroffenen\nProzess terminiert.</p>\n"},{"correct":false,"option":"<p>Greift ein laufender Prozess lesend auf eine Datei zu und der\nentsprechende Datenblock ist <mark>nicht</mark> im Hauptspeicher\nvorhanden, dann wird der Prozess in den Zustand bereit &#xFC;berf&#xFC;hrt.</p>\n","comment":"<p>Nein, er wird in den Zustand blockiert &#xFC;berf&#xFC;hrt, da er auf\nBetriebsmittel wartet.</p>\n"},{"correct":false,"option":"<p>Bei kooperativem Scheduling ist kein direkter &#xDC;bergang vom Zustand\nlaufend in den Zustand bereit m&#xF6;glich.</p>\n","comment":"<p>Doch, wenn die CPU abgegeben wird, wird ein Prozess in bereit\n&#xFC;berfuhrt, da er die CPU <mark>nicht</mark> <q>hat</q> und auf\n<mark>keine</mark> Betriebsmittel wartet.</p>\n"},{"comment":"<p>Ja, aber <mark>nicht</mark> der Prozess selbst (weil dieser\n<mark>muss</mark> die <code>V</code>-Operation durchf&#xFC;hren), sondern ein\nandere Prozess welcher mit der <code>P</code>-Operation auf eine\nSemaphore wartet, welches gerade den Wert 0 hat.</p>\n","option":"<p>Die V-Operation eines Semaphors <mark>kann</mark> bewirken, dass ein\nProzess vom Zustand blockiert in den Zustand bereit &#xFC;berf&#xFC;hrt wird.</p>\n","correct":true}],"id":"Tk1fHHZrumB/ep/CKd5+vA","multiple":true},{"multiple":false,"question":"<p>Welche Aussage zu nicht-blockierender Synchronisation ist\nrichtig?</p>\n","id":"lqCK5Z9vq/Jl87iKY5hxJw","options":[{"comment":"<p>Nein, das ABA Problem <mark>kann</mark> vermieden werden, wenn man\nbedingte Transaktionen <mark>nicht</mark> basierend auf Werten best&#xE4;tigt\n(wie es CAS macht; es schaut ob der Wert in einer Speicherstelle sich\n<mark>nicht</mark> ge&#xE4;ndert hat, was die Wurzel des ABA Problems ist),\nsondern wenn man Pr&#xFC;fen <mark>kann</mark> ob eine Speicherstelle an sich\n<mark>nicht</mark> schreibend ber&#xFC;hrt wurde (wie es die <a\nhref=\"https://en.wikipedia.org/wiki/Load-link/store-conditional\">LL/SC</a>\nBefehle auf manchen RISC Systemen anbieten, weil man dann bspw. beim\nRingpuffer unterschieden <mark>kann</mark> ob ein Index einen ganzen\nUmlauf gemacht hat, und nur wieder an der gleichen Speicherstelle\nist).</p>\n","correct":false,"option":"<p>Bei allen nicht-blockierenden Verfahren tritt das ABA-Problem\nauf.</p>\n"},{"comment":"<p>Doch, die Premise von nicht-blockierenden Synchronisation ist es\nkomplexe Befehle der ISA zu benutzen, wie bspw. CAS (bzw. der analoge\nBefehl auf dem jeweiligem System) wird atomar lesen, vergleichen und\nbedingt schreiben, was ansonsten <mark>nicht</mark> m&#xF6;glich w&#xE4;re mit den\n<q>Standard</q> Befehlen.</p>\n","correct":false,"option":"<p>Verfahren zur nicht-blockierenden Synchronisation ben&#xF6;tigen\n<mark>keine</mark> spezielle Hardware-Unterst&#xFC;tzung.</p>\n"},{"comment":"<p>Nein, im Gegenteil ist nicht-blockierender h&#xE4;ufig viel spr&#xF6;der als\ndie blockierenden Methoden. W&#xE4;hrend letztere <q>nur</q> die richtigen\nkritischen Stellen isolieren m&#xFC;ssen, besteht die Komplexit&#xE4;t bei einem\nnicht-blockierendem Ansatz darin, dass man jederzeit mit nebenl&#xE4;ufigen\nModifikationen rechnen muss. Man <mark>kann</mark> sich also\n<mark>nicht</mark> darauf verlassen, dass zwei Variablen einen\nKonsistenten zustand haben (au&#xDF;er die Architektur unterst&#xFC;tzt <a\nhref=\"https://en.wikipedia.org/wiki/Double_compare-and-swap\">2CAS</a>\nBefehle). Der Vorteil hingegen besteht darin, dass Todessperren\n<mark>nicht</mark> m&#xF6;glich sind, und im besten Fall sogar\n<mark>alle</mark> Operationen in einer bestimmten endlichen Anzahl von\nSchritten terminieren m&#xFC;ssen (<q>Warte Frei</q>, siehe diese\nKonversation im <a\nhref=\"https://forum.fsi.cs.fau.de/t/behinderungsfrei-sperrfrei-wartefrei-nochmal-erklaren/16915\">FSI-Forum</a>).</p>\n","option":"<p>In vielen F&#xE4;llen sind die Algorithmen bei Verwendung\nnicht-blockierender Synchronisation einfacher zu beschreiben als bei\nblockierender Synchronisation.</p>\n","correct":false},{"option":"<p>Bei nicht-blockierenden Verfahren k&#xF6;nnen <mark>keine</mark>\nVerklemmungen auftreten.</p>\n","correct":true,"comment":"<p>Ja, es ist <mark>nicht</mark> m&#xF6;glich dass es zu einem Dead-Lock\nkommt, weil Prozesse <mark>nicht</mark> schlafen-gelegt werden vom\nScheduler. Aber ein Live-Lock auf Zeit <mark>kann</mark> grunds&#xE4;tzlich\nAuftreten, wenn sich die Prozesse gegenseitig st&#xE4;ndig ihren geteilten\nZustand &#xFC;berschreiben, und damit nur schwer ihre Transaktionen beenden\nk&#xF6;nnnen.</p>\n"}],"source":"2013-02"},{"source":"2013-02","options":[{"option":"<p>durch Seiten&#xFB02;attern</p>\n","correct":false,"comment":"<p>Nein, Seiten&#xFB02;attern ist ein Performanz Problem, wobei Zugriffe auf\nden Speicher verlangsamt werden, weil die Seiten im Hauptspeicher durch\npathologische Zugriffe f&#xE4;lschlicherweise ausgelagert werden, auch wenn\ndiese in naher Zukunft gebraucht werden.</p>\n"},{"comment":"<p>Nein, durch langfristiges Scheduling per se sollte <mark>keine</mark>\nNebenl&#xE4;ufigkeits-Probleme entstehen, welche <mark>nicht</mark> bereits\ngegeben w&#xE4;ren durch <q>gew&#xF6;hnliches</q> Scheduling. Ansonsten ist die\nGefahr von problematischen, nebenl&#xE4;ufigen Ereignissen im kurzfristigem\nScheduling h&#xF6;her, weil dass die Interferenz zwischen Prozessen\nwahrscheinlicher macht</p>\n","option":"<p>durch langfristiges Scheduling</p>\n","correct":false},{"correct":false,"option":"<p>durch Compiler-Optimierungen</p>\n","comment":"<p>Nein, es steht zwar einem &#xDC;bersetzer frei, unter invarianter Semantik\nProgramme zu transformieren, bspw. um verschiedene Optimierungen\n(Performanz, Speicherbedarf, Gr&#xF6;&#xDF;e der Ausf&#xFC;hrbaren Dateien, &#x2026;)\numzusetzen, aber Nebenl&#xE4;ufigkeiten &#x2013; aus Sicht der Sprache &#x2013; welche\n<mark>nicht</mark> in dem Programm per se gegeben waren,\n<em>sollten</em> dadurch <mark>nicht</mark> auftauchen. Was m&#xF6;glich ist,\nist das Nebenlaufigkeitsprobleme erst <em>wahrscheinlicher</em> werden,\nwenn ein Programm entsprechend beschleunigt wurde.</p>\n"},{"option":"<p>durch Interrupts</p>\n","correct":true,"comment":"<p>Ja, eine Unterbrechnungsbehandlung <mark>kann</mark> ein Programm\n(bspw. das Betriebsystem) an einer ungeeigneten Stelle unterbrechen, und\nDaten &#xFC;berschreiben, welche nach der R&#xFC;ckkehr in das Hauptprogramm ein\ninkonsistenten Zustand bewirken kann. In diesem Sinne ist es\nvergleichbar zu Signalbehahdlungen in Benutzerprozessen. Aus diesem\nGrund m&#xFC;ssen Betriebsysteme in kritischen Intervallen Interrupts\ndeaktivieren k&#xF6;nnen, bspw. auf x86 mit den <a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_31.html\"><code>CLI</code></a>\n(Clear Interrupt Flag) und und <a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_304.html\"><code>STI</code></a>\n(Set Interrupt Flag) Befehlen.</p>\n"}],"multiple":false,"question":"<p>Wodurch <mark>kann</mark> Nebenl&#xE4;u&#xFB01;gkeit in einem System\nentstehen?</p>\n","id":"g+7FjrfOiC8Fc/rJOV4e1A"},{"source":"2023-07","question":"<p>Man unterscheidet zwischen privilegierten und nicht-privilegierten\nMaschinenbefehlen. Welche Aussage ist richtig?</p>\n","options":[{"comment":"<p>Eigentlich nein, diese werden <mark>nicht</mark> direkt von\nAnwendungsprogrammen benutzt, sondern sind dem Betriebsystem\nvorenthalten, damit dieses sinnvoll Ressourcen virtualisieren und\nsch&#xFC;tzen kann. Das schwierige an dieser Frage ist das\n<q>grunds&#xE4;tzlich</q>, womit man meinen <em>k&#xF6;nnte</em>, dass ein Befehl\nwie <code>syscall</code>/<code>int</code> auf x86/x86_64, welches einen\nTrap ausl&#xF6;&#xDF;t, um Systemaufrufe abzusetzen, auch als <q>priviligiert</q>\nangesehen werden kann.</p>\n","correct":null,"option":"<p>Privilegierte Maschinenbefehle d&#xFC;rfen in Anwendungsprogrammen\ngrunds&#xE4;tzlich <mark>nicht</mark> verwendet werden.</p>\n"},{"option":"<p>Die Benutzung eines privilegierten Maschinenbefehls in einem\nAnwendungsprogramm f&#xFC;hrt zu einer asynchronen Programmunterbrechung.</p>\n","comment":"<p>Nein, es w&#xFC;rde zu einer <em>syncrhonen</em> Programmunterbrechung\nf&#xFC;hren, weil diese direkt durch den Versuch den Befehl zu interpretieren\nausgel&#xF6;st werden w&#xFC;rde.</p>\n","correct":false},{"correct":null,"comment":"<p>Abh&#xE4;ngig davon, was man unter <q>grunds&#xE4;tzlich</q> versteht; auf\nIntel CPUs werden hierzu gesonderte Befehle benutzt, aber\n<em>grunds&#xE4;tzlich</em> k&#xF6;nnte eine Rechnerarchitektur auch durch\nSpeicherschutz einen nicht-privilegierten Prozess daran hindern mittels\nnicht-priviligierten Befehlen auf Ger&#xE4;teregister zuzugreifen.</p>\n","option":"<p>Mit nicht-privilegierten Befehlen ist der Zugriff auf Ger&#xE4;teregister\ngrunds&#xE4;tzlich <mark>nicht</mark> m&#xF6;glich.</p>\n"},{"option":"<p>Privilegierte Maschinenbefehle k&#xF6;nnen durch Betriebssystemprogramme\nimplementiert werden.</p>\n","comment":"<p>Ja, hier <mark>muss</mark> an das <q>Multilevel Machines</q> Model\nvon <a\nhref=\"https://csc-knu.github.io/sys-prog/books/Andrew%20S.%20Tanenbaum%20-%20Structured%20Computer%20Organization.pdf#page=30\">Tannenbaum</a>\ndenken, wo <mark>jede</mark> Schicht der Implementierung zwischen einer\n<em>problemorientierte Programmiersprachenebene</em> und <em>digitale\nLogikebene</em> als Interpretation oder Implementierung einer Virtuellen\nMachine angesehen wird.</p>\n","correct":true}],"id":"3ngWNmoC+q1nfvC7/QQHjw","multiple":false},{"question":"<p>Was passiert, wenn Sie in einem C-Programm &#xFC;ber einen ung&#xFC;ltigen\nZeiger versuchen auf Speicher zuzugreifen?</p>\n","source":"2023-07","multiple":false,"options":[{"option":"<p>Das Betriebssystem erkennt die ung&#xFC;ltige Adresse bei der Weitergabe\ndes Befehls an die CPU (partielle Interpretation) und leitet eine\nAusnahmebehandlung ein.</p>\n","correct":false,"comment":"<p>Nein, das Betriebssystem gibt den Befehl selbst <mark>nicht</mark> an\ndie CPU weiter, und &#xFC;berpr&#xFC;ft daher auch <mark>nicht</mark> ob die\nAdressen g&#xFC;ltig seien.</p>\n"},{"correct":false,"comment":"<p>Nein, der &#xDC;bersetzer <mark>kann</mark> sich <mark>nicht</mark>\n<mark>immer</mark> sicher sein wo die problematische Code-Stellen sind,\nund generiert (f&#xFC;r C) auch <mark>nicht</mark> den Code um den Fehler\nauszul&#xF6;sen.</p>\n","option":"<p>Der Compiler erkennt die problematische Code-Stelle und generiert\nCode, der zur Laufzeit bei dem Zugriff einen entsprechenden Fehler\nausl&#xF6;st.</p>\n"},{"comment":"<p>Ja, wenn die MMU die Seite <mark>nicht</mark> aufl&#xF6;sen kann, dann\nwird es der CPU ein Trap zustellen und l&#xF6;st damit eine synchrone\nUnterbrechung im Programm aus.</p>\n","correct":true,"option":"<p>Beim Zugriff &#xFC;ber den Zeiger <mark>muss</mark> die MMU die\nerforderliche Adressumsetzung vornehmen, erkennt die ung&#xFC;ltige Adresse\nund l&#xF6;st einen Trap aus.</p>\n"},{"option":"<p>Der Speicher schickt an die CPU einen Interrupt. Hierdurch wird das\nBetriebssystem angesprungen, das den gerade laufenden Prozess mit einem\n<q>Segmentation fault</q>-Signal unterbricht.</p>\n","correct":false,"comment":"<p>Da der Fehler direkt bedingt ist durch das Verhalten des Programms,\nw&#xFC;rde es sich hier um ein <q>Trap</q> und kein <q>Interrupt</q>\n(unvorhersebar) handeln.</p>\n"}],"id":"H38acE7CjdMZC145R+FiBg"},{"source":"2023-07","question":"<p>Welche der folgenden Aussagen zum Thema Dateispeicherung sind\nrichtig?</p>\n","options":[{"option":"<p>Bei indizierter Speicherung von Dateien ensteht externer Verschnitt\nauf der Platte.</p>\n","correct":false,"comment":"<p>Nein, weil f&#xFC;r Dateien ganze Bl&#xF6;cke vergeben und herumgeschoben\nwerden k&#xF6;nnen, womit externer Verschnitt vermieden wird, weil es\n<mark>nicht</mark> dazu kommen kann, dass es l&#xFC;cken gibt die <q>zu\nklein</q> w&#xE4;ren f&#xFC;r eine Datei.</p>\n"},{"correct":true,"comment":"<p>Ja, weil der Lese-Schreib-Kopf der Festplatte schneller auf\nlokal-nahe Daten in der gleichen Leserichtung zugreifen kann, ist ist\nder Zugriff auch dementsprechend schneller.</p>\n","option":"<p>Festplatten eignen sich besser f&#xFC;r sequentielle als f&#xFC;r wahlfreie\nZugriffsmuster.</p>\n"},{"option":"<p>Eine Datei in einem Winows-NT-Dateisystem <mark>kann</mark> nur genau\neinen Dateinamen haben, da dieser in ihrem Master-File-Table-Eintrag\ngespeichert ist.</p>\n","correct":false,"comment":"<p>Nein, obwohl der Datei Name f&#xFC;r ein <q>fileID</q> im MFT gespeichert\nist, wird es auch in Verzeichnissen gespeichert und erlaubt es &#xE4;hnlich\nzu einem UFS-Inspiriertem Datei-System, mehrere Namen auf ein\n<q>Volume</q> zu definieren.</p>\n"},{"comment":"<p>Nein, Verschleis hat nichts mit der technischen Umsetzung des\nSpeichermediums zu tun.</p>\n","correct":false,"option":"<p>Da SSDs ohne mechanische Komponenten auskommen, gibt es auch durch\nh&#xE4;ufige Schreiboperationen keinen Verschleis.</p>\n"}],"id":"MsqPJyNiVtp1wizgsjzr7w","multiple":false},{"question":"<p>Welches Signal wird bei einer Speicherschutzverletzung versendet?</p>\n","source":"2023-07","multiple":false,"id":"6XCvUBQJC1KuLcbcYdgLyg","options":[{"option":"<p>SIGKILL</p>\n","correct":false,"comment":"<p><code>signal.h(7p)</code> sagt <q>Kill (cannot be caught or\nignored)</q>.</p>\n"},{"comment":"<p><code>signal.h(7p)</code> sagt <q>Invalid memory reference</q>.</p>\n","correct":true,"option":"<p>SIGSEGV</p>\n"},{"correct":false,"comment":"<p><code>signal.h(7p)</code> sagt <q>Termination signal</q>.</p>\n","option":"<p>SIGTERM</p>\n"},{"option":"<p>SIGABORT</p>\n","correct":false,"comment":"<p><code>signal.h(7p)</code> sagt <q>Process abort signal</q>.</p>\n"}]},{"question":"<p>Man unterscheidet kurz-, mittel- und langfristige Prozesseinplanung.\nWelche Aussage hierzu ist richtig?</p>\n","source":"2023-07","multiple":false,"id":"7MD3pi6tKCwwSHVrH2ZeHg","options":[{"option":"<p>Wenn ein Prozess auf einen Seitenfehler (page fault) trifft, wird er\nim Rahmen der kurzfristigen Einplanung in den Zustand <q>schwebend\nbereit</q> &#xFC;berf&#xFC;hrt, weil er ja unmittelbar nach dem Einlagern der\nSeite wieder weiterlaufen kann.</p>\n","correct":false,"comment":"<p>Nein, das w&#xE4;re mittelfristige Prozesseinplanung. Ein Prozess im\nZustand schwebend bereit <mark>kann</mark> <mark>keine</mark> gerade\neingelagerten Seiten haben, was <mark>nicht</mark> der Fall sein kann,\nwenn er zuvor im Zustand bereit sein musste.</p>\n"},{"option":"<p>Wenn ein Prozess auf einen Seitenfehler (page fault) trifft, wird er\nim Rahmen der kurzfristigen Einplanung <mark>immer</mark> in den Zustand\n<q>blockiert</q> &#xFC;berf&#xFC;hrt, bis die Seite eingelagert wurde.</p>\n","comment":"<p>Nein, <mark>nicht</mark> <em><mark>immer</mark></em>, weil es sein\nkann, dass die Seite <mark>nicht</mark> eingelagert werden\n<mark>kann</mark> und daher der Prozess in den finalen Zustand beendet\n&#xFC;bergeht.</p>\n","correct":false},{"correct":false,"comment":"<p>Nein, der Prozess ist weiterhin laufbereit, nur eben schwebend\nbereit.</p>\n","option":"<p>Wenn der Adressraum eines laufbereiten Prozesses aufgrund von\nSpeichermangel ausgelagert wird (<q>swap-out</q>), wird der Prozess im\nRahmen der mittelfristigen Einplanung in den Zustand <q>blockiert</q>\n&#xFC;berf&#xFC;hrt, bis die Daten wieder eingelagert werden.</p>\n"},{"option":"<p>Wenn ein Prozess auf Daten von der Platte warten muss, wird er in den\nZustand <q>blockiert</q> versetzt.</p>\n","correct":true,"comment":"<p>Ja, Prozess blockiert, bis ihm Betriebsmittel zugestellt werden\nk&#xF6;nnen.</p>\n"}]},{"multiple":false,"id":"Xz0R6VBaOfD9K6k/DtpYvQ","options":[{"option":"<p>Zur Implementierung einer Schlossvariable mit aktivem Warten ist\n<mark>keine</mark> Unterst&#xFC;tzung durch das Betriebssystem notwendig.</p>\n","comment":"<p>Ja, <mark>kann</mark> man zum Beispiel mit CAS umsetzen.</p>\n","correct":true},{"option":"<p>Aktives Warten vergeudet gegen&#xFC;ber passivem Warten <mark>immer</mark>\nCPU-Zeit.</p>\n","correct":false,"comment":"<p>Nein, vergeudet <mark>nicht</mark> unbedingt Zeit. Spezifisch dann,\nwenn das einbinden des Schedulers, um eben das passive Warten\numzusetzen, mehr Aufwand ben&#xF6;tigen w&#xFC;rde, als aktiv zu warten.</p>\n"},{"correct":false,"comment":"<p>Nein, bei passivem Warten w&#xFC;rden <mark>keine</mark> weiteren Prozesse\nverz&#xF6;gert werden, weil der Prozess im Blockieren Zustand ist. Bei\naktivem Warten ist der Prozess bereit und <mark>muss</mark>\n<mark>immer</mark> wieder eingelagert werden um aktiv nach der\nAbbruchbedingung zu pr&#xFC;fen, was den Durchsatz des System verz&#xF6;gert.</p>\n","option":"<p>Bei verdr&#xE4;ngenden Scheduling-Strategien verz&#xF6;gert aktives Warten nur\nden betroffenen Prozess, behindert aber <mark>nicht</mark> andere</p>\n"},{"correct":false,"comment":"<p>Nein, auf keinen Fall, weil man auf einem kooperativem\nMonoprozessor-System die CPU monopolisieren w&#xFC;rde, und wenn man auf eine\nBedingung von einem anderem Faden warten w&#xFC;rde, w&#xFC;rde man sich in einem\nlive-lock verfangen.</p>\n","option":"<p>Aktives Warten sollte bei einer nicht-verdr&#xE4;ngenden\nScheduling-Strategie auf einem Monoprozessorsystem dem passiven Warten\nvorgezogen werden.</p>\n"}],"question":"<p>Welche Aussage zum Thema <q>Aktiven Warten</q> ist richtig?</p>\n","source":"2023-07"},{"question":"<p>Welche Aussage zu den Eigenschaften eines Journaling-Filesystems ist\nrichtig?</p>\n","source":"2023-07","multiple":false,"id":"Cp6xtnxLYv0GLriBBH9ZdQ","options":[{"option":"<p>Es wird <mark>immer</mark> zuerst die &#xC4;nderung im Dateisystem auf der\nPlatte durchgef&#xFC;hrt und anschlie&#xDF;end zur Absicherung ein entsprechender\nEintrag in die Log-Datei geschrieben.</p>\n","comment":"<p>Nein, Log-Datei wird davor geschrieben</p>\n","correct":false},{"correct":true,"option":"<p>Die Eintr&#xE4;ge in der Protokolldatei m&#xFC;ssen <mark>immer</mark> auch\nInformationen zu einem Undo und Redo der Transaktion enthalten</p>\n"},{"comment":"<p>Nein, es ist notwendig das eine Datei mit einer unvollst&#xE4;ndigen\nTransaktion (kann auch damit zusammenh&#xE4;ngen, dass die Datei erweitert\nwird) insgesamt gel&#xF6;scht wird. Es sollte nur in einen konsistenten\nZustand zur&#xFC;ckgebracht werden.</p>\n","correct":false,"option":"<p>Alle &#xC4;nderungen am Dateisystem werden in Form von Transaktionen in\neine Log-Datei mitprotokolliert. Wird nach einem Systemabsturz\nfestgestellt, dass eine Transaktion in der Log-Datei unvollst&#xE4;ndig ist,\nwird die betroffene Datei gel&#xF6;scht.</p>\n"},{"correct":false,"comment":"<p>Nein, der Aufwand die Reparatur durchzuf&#xFC;hren ist <mark>nicht</mark>\ndirekt proportional zur Platte, sondern zur Gr&#xF6;&#xDF;e der Log Datei.</p>\n","option":"<p>Je gr&#xF6;&#xDF;er eine Platte ist, desto l&#xE4;nger dauert der Reparaturvorgang\neines Journaling-Filesystems nach einem Systemabsturz</p>\n"}]},{"question":"<p>Welche Aussagen zum Thema RAID sind richtig?</p>\n","source":"2023-07","multiple":true,"id":"u6p+mpuhZDb1y02SQ533qA","options":[{"correct":true,"option":"<p>Bei RAID 4 enth&#xE4;lt eine Platte die Parit&#xE4;tsinformationen, die anderen\nPlatten enthalten Daten.</p>\n"},{"correct":false,"comment":"<p>Nein, Parit&#xE4;tsplatte ist hoch beansprucht.</p>\n","option":"<p>Bei RAID 4 werden <mark>alle</mark> im Verbund beteiligten Platten\ngleichm&#xE4;&#xDF;ig beansprucht.</p>\n"},{"option":"<p>Bei RAID 0 f&#xFC;hrt der Ausfall einer der beteiligten Platten\n<mark>nicht</mark> zu Datenverlust.</p>\n","comment":"<p>Nein, Systemausfall bei Plattenausfall</p>\n","correct":false},{"correct":true,"option":"<p>Bei RAID 1 werden die Datenbl&#xF6;cke &#xFC;ber mehrere Festplatten verteilt\nund repliziert gespeichert.</p>\n"},{"option":"<p>Bei RAID 1 wird beim Lesen ein Geschwindigkeitsvorteil erzielt.</p>\n","correct":true},{"correct":false,"comment":"<p>Nein, Parit&#xE4;tsbl&#xF6;cke werden &#xFC;ber Platten verteilt.</p>\n","option":"<p>Bei RAID 5 liegen die Parit&#xE4;tsinformationen auf einer dedizierten\nPlatte.</p>\n"},{"comment":"<p>Ja, bei RAID 5 werden auch die Parit&#xE4;tsdaten verteilt gespeichert. Es\ngibt also <mark>keine</mark> designierte(n) Platte(n), die eine andere\nRolle einnehmen, wie es bei RAID 4 der Fall w&#xE4;re.</p>\n","correct":true,"option":"<p>Bei RAID 5 werden <mark>alle</mark> im Verbund beteiligten Platten\ngleichm&#xE4;&#xDF;ig beansprucht.</p>\n"},{"correct":false,"comment":"<p>Nein, <mark>nicht</mark> repliziert, nur verteilt, aber eben jeweils\nnur auf einer Platte.</p>\n","option":"<p>Bei RAID 0 werden die Datenbl&#xF6;cke &#xFC;ber mehrere Festplatten verteilt\nund repliziert gespeichert.</p>\n"}]},{"options":[{"option":"<p>Verdr&#xE4;ngende Prozesseinplanung bedeutet, dass das Eintreten des\nerwarteten Ereignisses unmittelbar die Einlastung des wartenden\nProzesses bewirkt.</p>\n","correct":false,"comment":"<p>Nein, die <q>Verdr&#xE4;ngung</q> bezieht sich auf die Tatsache, dass\neinem Prozess die CPU entzogen werden kann, ohne dessen Unwilling\n(<q>yield</q>).</p>\n"},{"option":"<p>Ein Prozess <mark>kann</mark> sich in realen Systemen\n<mark>nie</mark> im Zustand beendet befinden, da bei seiner Terminierung\ns&#xE4;mtliche Betriebsmittel freigegeben werden und damit auch der Prozess\nselbst verschwindet.</p>\n","comment":"<p>Nein, das ist der <q>Zombie Zustand</q>, es verbleibt auf einem Unix\nSystem darin bis waitpid o.&#xE4;. benutzt wird.</p>\n","correct":false},{"option":"<p>Prozesse im Zustand blockiert oder bereit k&#xF6;nnen unmittelbar in den\nZustand gestoppt &#xFC;berf&#xFC;hrt werden.</p>\n","comment":"<p>Ja, Prozesse k&#xF6;nnen gestoppt beendet werden, unabh&#xE4;ngig davon ob\ndiese gerade laufen oder <mark>nicht</mark> (denke an\n<code>kill -9</code>).</p>\n","correct":true},{"comment":"<p>Nein, das sind Prozess-Arten.</p>\n","correct":false,"option":"<p>Einplanungsverfahren lassen sich in drei Kategorien einteilen:\nfedergewichtig, leichtgewichtig und schwergewichtig.</p>\n"},{"correct":true,"comment":"<p>Ja, weil das im Kontext der mittelfristigen Planung geschehen w&#xFC;rde,\nwo der Speicher eines bereits blokierten Prozesses ausgelagert werden\nw&#xFC;rde.</p>\n","option":"<p>Ein Prozess, der sich im Zustand laufend befindet, <mark>kann</mark>\n<mark>nicht</mark> direkt in den Zustand schwebend blockiert &#xFC;berf&#xFC;hrt\nwerden.</p>\n"},{"correct":true,"option":"<p>Prozesse im Zustand gestoppt sind der langfristigen Einplanung\nzuzuordnen.</p>\n"},{"option":"<p>F&#xFC;r die mittelfristige Einplanung <mark>muss</mark> das\nBetriebssystem die Umlagerung (engl. swapping) von kompletten Programmen\nbzw. logischen Adressr&#xE4;umen unterst&#xFC;tzen.</p>\n","comment":"<p>Ja, mittelfristige Planung wird im Gegensatz zur kurzfristigen\nPlanung durch das Vorhandensein des Speichers von Prozessen im\nHauptspeicher.</p>\n","correct":true},{"option":"<p>Ein Prozess im Zustand erzeugt <mark>kann</mark> sich selbst durch\ndie Ausf&#xFC;hrung des Systemaufrufes <code>exec()</code> in den Zustand\nbereit &#xFC;berf&#xFC;hren.</p>\n","comment":"<p>Nein, um <code>exec</code> auszuf&#xFC;hren, m&#xFC;sste der Prozess ja bereits\nim Zustand <em>laufend</em> sein.</p>\n","correct":false}],"id":"WuN2fMLLb+xRv89qC/m1RQ","multiple":true,"source":"2023-07","question":"<p>Welche der folgenden Aussagen zum Thema Einplanung sind richtig?</p>\n"},{"question":"<p>Wie funktioniert Adressraumschutz durch Eingrenzung?</p>\n","id":"lgbEnVRDvnALHUPzscvSbg","source":"2016-02","multiple":false,"options":[{"comment":"<p>Nein, das ist <mark>nicht</mark> was mit <q>Eingrenzung</q> gemeint\nist. Ansonsten w&#xE4;re es recht umst&#xE4;ndlich, die L&#xFC;cken im physikalischem\nSpeicher welche f&#xFC;r Memory-Mapped I/O, den BIOS, PCI, etc. f&#xFC;r eine\ndynamische Anzahl an Prozessen auszunutzen.</p>\n","correct":false,"option":"<p>Der Lader positioniert Programme <mark>immer</mark> so im\nArbeitsspeicher, dass unerlaubte Adressen mit nicht-existierenden\nphysikalischen Speicherbereichen zusammenfallen.</p>\n"},{"option":"<p>Begrenzungsregister legen einen Adressbereich im logischen Adressraum\nfest, auf den <mark>alle</mark> Speicherzugriffe beschr&#xE4;nkt werden.</p>\n","comment":"<p>Nein, bei Eingrenzung ist der Addressbereich im physikalischen\nAdressraum.</p>\n","correct":false},{"comment":"<p>Ja, Bei Eingrenzung, bzw. <q>Einfriedung</q> wird ein Teil des\nphysikalischen Speichers mittels Grenzregistern &#xFC;berpr&#xFC;ft, noch bevor\nder Addressbus angeprochen wird.</p>\n","correct":true,"option":"<p>Begrenzungsregister legen einen Adressbereich im physikalischen\nAdressraum fest, auf den <mark>alle</mark> Speicherzugriffe beschr&#xE4;nkt\nwerden.</p>\n"},{"option":"<p>Jedes Programm bekommt zur Ladezeit mehrere Wertepaare aus Basis- und\nL&#xE4;ngenregistern zugeordnet, die die Gr&#xF6;&#xDF;e aller Segmente des darin\nlaufenden Prozesses festlegen.</p>\n","comment":"<p>Nein, das umschreibt Segmentierung.</p>\n","correct":false}]},{"source":"2016-02","multiple":false,"options":[{"option":"<p>Der Prozess hat auf das Einlesen von Daten von der Festplatte\ngewartet, die nun verf&#xFC;gbar sind.</p>\n","comment":"<p>Ja, die Ressource (Daten von der Festplatte) waren <mark>nicht</mark>\nverf&#xFC;gbar, und waren daher Grund weshalb der Prozess im Blokiertem\nZustand war. Man geht <mark>nicht</mark> direkt von <q>Blokiert</q> nach\n<q>Laufend</q> &#xFC;ber, sondern macht den Umweg &#xFC;ber <q>Bereit</q>, d.h.\nder Prozess ist in der Bereitliste vom Scheduler eingeordnet.</p>\n","correct":true},{"option":"<p>Ein Prozess, der zu einem fr&#xFC;heren Zeitpunkt aufgrund von\nSpeichermangel auf den Hintergrundspeicher ausgelagert wurde, ist nun\nwieder eingelagert und <mark>kann</mark> weiterlaufen.</p>\n","comment":"<p>Ich glaube das sollte falsch sein, weil ein Prozess <em>als\nsolches</em> <mark>nicht</mark> <em>aufgrund</em> von Speichermangel in\nden Hintergrundspeicher ausgelagert wird.</p>\n","correct":null},{"correct":false,"comment":"<p>Nein, dieser erstgennante Prozess w&#xE4;re <q>Bereit</q> gewesen, und\nw&#xFC;rde nun im Zustand <q>Laufend</q> sein. Der andere Prozess w&#xE4;re den\nUmgekehrten weg, von <q>Laufend</q> nach <q>Bereit</q> &#xFC;bergegangen\n(diesem Fehlt nichts au&#xDF;er die CPU).</p>\n","option":"<p>Ein anderer Prozess wurde vom Betriebssystem verdr&#xE4;ngt und der\nerstgenannte Prozess wird nun auf der CPU eingelastet.</p>\n"},{"comment":"<p>Nein, es ist kein &#xDC;berganz von <q>Blokiert</q> nach <q>Laufend</q>\nm&#xF6;glich, aber ein blockierter Prozess <mark>kann</mark> in <q>Bereit</q>\n&#xFC;berf&#xFC;hrt werden, sobald der Grund f&#xFC;r das Blockiertsein aufgel&#xF6;st\nwurde.</p>\n","correct":false,"option":"<p>Es ist kein direkter &#xDC;bergang von blockiert nach bereit m&#xF6;glich.</p>\n"}],"question":"<p>Ein Prozess wird vom Zustand blockiert in den Zustand bereit\n&#xFC;berf&#xFC;hrt. Welche Aussage passt zu diesem Vorgang?</p>\n","id":"6lRugMbc3jXryinSblM7Eg"},{"multiple":false,"source":"2016-02","options":[{"comment":"<p>Nein, in diesem Fall w&#xFC;rde es nur zu einer Auslagerung von Seiten\nkommen, was aber <mark>nicht</mark> zwingend <q>Seitenflattern</q>\nbedingen w&#xFC;rde.</p>\n","correct":false,"option":"<p>Wenn die Zahl der residenten Seiten die Gr&#xF6;&#xDF;e des physikalischen\nSpeichers &#xFC;berschreitet.</p>\n"},{"comment":"<p>Nein, Seitenflattern bezeichnet das pathologische Ph&#xE4;nomen, wenn die\nSeitenumlagerungsstrategie eine Menge von Seiten zu h&#xE4;ufig Umlagern\nmuss, und damit den Zugriff auf den Speicher verlangsamt. Es an sich hat\nnichts mit dem Dateisystem zu tun.</p>\n","correct":false,"option":"<p>Durch Programme, die eine Defragmentierung auf der Platte\ndurchf&#xFC;hren.</p>\n"},{"option":"<p>Wenn ein Prozess zum Weiterarbeiten <mark>immer</mark> gerade die\nSeiten ben&#xF6;tigt, die durch das Betriebssystem im Rahmen einer globalen\nErsetzungsstrategie gerade erst ausgelagert wurden.</p>\n","correct":true,"comment":"<p>Ja, das ist die Definition vom Begriff. Siehe im <a\nhref=\"https://www4.cs.fau.de/~wosch/glossar.pdf\">Wosch Glossar</a>, den\nEintrag <q>Flattern</q>.</p>\n"},{"option":"<p>Wenn zu viele Prozesse im Rahmen der mittelfristigen Einplanung auf\nden Hintergrundspeicher ausgelagert wurden (swap-out).</p>\n","comment":"<p>Nein, der Begriff ist unabh&#xE4;ngig von der Planungsstrategie zu\nverstehen.</p>\n","correct":false}],"id":"yi3ZeXW8jCivkQGc3nxx6w","question":"<p>Wodurch <mark>kann</mark> es zu Seitenflattern kommen?</p>\n"},{"question":"<p>Man unterscheidet bei Programmunterbrechungen zwischen Traps und\nInterrupts. Welche Aussage dazu ist richtig?</p>\n","id":"ND6lHyUQekzfQYkIhSXJwA","options":[{"option":"<p>Die Behandlung eines Traps f&#xFC;hrt <mark>immer</mark> zur Beendigung\ndes unterbrochenen Programms, da Traps nur durch schwerwiegende Fehler\nausgel&#xF6;st werden.</p>\n","comment":"<p>Nein, Traps k&#xF6;nnen auch durch Systemaufrufe (Quasi-Nachrichten an das\nBetriebsystem) oder durch fehlende aber einlagerbare Speicherseiten\nausgel&#xF6;st werden.</p>\n","correct":false},{"option":"<p>Da das Betriebssystem <mark>nicht</mark> vorhersagen kann, wann ein\nBenutzerprogramm einen Systemaufruf absetzt, sind Systemaufrufe als\nInterrupts zu klassifizieren.</p>\n","correct":false,"comment":"<p>Nein, Systemaufrufe treten <mark>immer</mark> dann deterministisch\nauf, wenn der entsprechende Maschinenbefehl (<code>syscall</code> auf ,\n<code>int</code> auf x86, <code>ecall</code> of RISC-V).</p>\n"},{"option":"<p>Bei der mehrfachen Ausf&#xFC;hrung eines unver&#xE4;nderten Programms mit\ngleicher Eingabe treten Traps <mark>immer</mark> an den gleichen Stellen\nauf.</p>\n","comment":"<p>Ja, das folgt aus dem Determinismus von Traps.</p>\n","correct":true},{"option":"<p>Da Interrupts in keinem Zusammenhang mit dem unterbrochenen Programm\nstehen, <mark>muss</mark> der Prozessorstatus des unterbrochenen\nProgramms w&#xE4;hrend der Behandlung <mark>nicht</mark> speziell gesichert\nwerden.</p>\n","correct":false,"comment":"<p>Doch, weil die Behandlung des Interrupts den Prozessorstatus durchaus\nbeeinflusst, und damit es aber das unterbrochenen Programm\n<mark>nicht</mark> direkt ver&#xE4;ndert (es braucht ja nur f&#xFC;r die\nBehandlung die CPU f&#xFC;r eine kurze Zeit), wird vor der Behandlung der\nZustand des Prozessors gespeichert &#x2013; bspw. in dem dieser auf dem Stack\nkopiert wird, dann die Unterbrechungsroutine eingeleitet wird, und\ndanach wiederhergestellt wird.</p>\n"}],"multiple":false,"source":"2016-02"},{"options":[{"correct":false,"comment":"<p>Nein, die Wurzel des Namensraums ist (zun&#xE4;chst, siehe\n<code>chroot(2)</code>) fest und unabh&#xE4;ngig von Prozessen und ihren\nArbeitsverzeichnissen.</p>\n","option":"<p>Das Arbeitsverzeichnis eines Prozesses definiert die Wurzel des\nhierarchisch organisierten Namensraums in einem Dateisystem.</p>\n"},{"comment":"<p>Ja, so <mark>kann</mark> es sowohl <code>/home/alice/shopping</code>\nund <code>/home/bob/shopping</code> geben. Nur in einem Verzeichnis darf\n<em>ein</em> Name <em>einmal</em> vergeben werden.</p>\n","correct":true,"option":"<p>In einem hierarchisch organisierten Namensraum d&#xFC;rfen gleiche Namen\nin unterschiedlichen Kontexten enthalten sein.</p>\n"},{"option":"<p>Flache Namensr&#xE4;ume erlauben pro Benutzer nur einen Kontext.</p>\n","correct":null,"comment":"<p>Ein Benutzer hat <mark>immer</mark> nur einen Kontext, unabh&#xE4;ngig\ndavon ob der Namensraum flach ist oder nicht.</p>\n"},{"correct":false,"comment":"<p>Nein, hierarchische Namensr&#xE4;ume k&#xF6;nnen auch nur von Hardlinks\naufgespannt werden (wie es der Fall war bevor BSD diese f&#xFC;r UNIX\nimplementiert hat).</p>\n","option":"<p>Hierarchische Namensr&#xE4;ume werden erzeugt, indem man in einem Kontext\nsymbolische Verweise auf Dateien eintr&#xE4;gt.</p>\n"}],"multiple":false,"source":"2016-02","id":"z9NT/e+wmyLMRAecYuy2kg","question":"<p>Namensr&#xE4;ume dienen u. a. der Organisation von Dateisystemen. Welche\nAussage ist richtig?</p>\n"},{"multiple":false,"source":"2016-02","options":[{"correct":false,"comment":"<p>Doch, wir k&#xF6;nnen eine Menge von Obejktdateien mit <code>ar</code> zu\neinem Archiv zusammenbinden. Das war historisch auch der Standard.</p>\n","option":"<p>Statische Bibliotheken k&#xF6;nnen in C <mark>nicht</mark> implementiert\nwerden.</p>\n"},{"correct":false,"comment":"<p>Nein, weil die Bibliotheken beim Binden des Programms eingebunden\nwerden, und gleich bleiben wenn das Archiv ge&#xE4;ndert wird.</p>\n","option":"<p>Eine &#xC4;nderung am Code einer statischen Bibliothek (z. B. Bugfixes)\nerfordert kein erneutes Binden der Programme, die diese Bibliothek\nbenutzen.</p>\n"},{"comment":"<p>Ja, weil die Inhalte des Archivs wurden beim Binden des Archivs in\ndie ausf&#xFC;hrbare Datei <q>kopiert</q>, und werden zur Ausf&#xFC;hrung aus der\nausf&#xFC;hrbaren Datei geladen und <mark>nicht</mark> aus dem urspr&#xFC;nglichem\nArchiv, was daher auch <mark>nicht</mark> mehr existieren muss.</p>\n","correct":true,"option":"<p>Eine statische Bibliothek, mit der ein Programm gebunden wurde,\n<mark>muss</mark> zum Ladezeitpunkt des Programms <mark>nicht</mark>\nmehr als eigenst&#xE4;ndige Datei im Dateisystem vorhanden sein.</p>\n"},{"comment":"<p>Nein, das w&#xE4;re dynamisches Binden. Beim statischem Binden wird der\ngesamte Programmtext der Bibliothek im Programm kopiert.</p>\n","correct":false,"option":"<p>Beim Binden mit einer statischen Bibliothek werden in einem Programm\nnur Verweise auf verwendete Symbole der Bibliothek angelegt.</p>\n"}],"question":"<p>Welche Aussage zu Programmbibliotheken ist richtig?</p>\n","id":"rCfFeYTT4/M4rBIidwqRrg"},{"multiple":false,"options":[{"comment":"<p>Nein, weil <code>(0xb &lt;&lt; 11) | 0xa1d = 0x5a1d</code>.</p>\n","correct":false,"option":"<p>Seitennummer <code>0xb</code>, Versatz <code>0xa1d</code>.</p>\n"},{"comment":"<p>Ja, weil <code>(0x17 &lt;&lt; 11) | 0x21d = 0xba1d</code>, oder\nalternativ:</p>\n<pre><code>  (0xba1d &amp;  (2048-1))       = 0x21d\n  (0xba1d &amp; ~(2048-1)) &gt;&gt; 11 = 0x17</code></pre>\n<p>Die Idee hier ist, dass man mit einer Seitengr&#xF6;&#xDF;e von 2048 Byte mit\n11 Bit adressieren kann. Die ersten 11 Byte von</p>\n<pre><code>  0b1011101000011101 = 0xba1d</code></pre>\n<p>sind</p>\n<pre><code>       0b01000011101 = 0x21d</code></pre>\n<p>und damit bleiben f&#xFC;r die Page Nummer nur noch</p>\n<pre><code>  0b10111            = 0x17</code></pre>\n","correct":true,"option":"<p>Seitennummer <code>0x17</code>, Versatz <code>0x21d</code>.</p>\n"},{"option":"<p>Seitennummer <code>0xba</code>, Versatz <code>0x1d</code>.</p>\n","correct":false,"comment":"<p>Nein, weil <code>(0xba &lt;&lt; 11) | 0x1d = 0x5d01d</code>.</p>\n"},{"comment":"<p>Nein, weil <code>(0x2e &lt;&lt; 11) | 0x21d = 0x1721d</code>.</p>\n","correct":false,"option":"<p>Seitennummer <code>0x2e</code>, Versatz <code>0x21d</code>.</p>\n"}],"source":"2016-02","id":"TGWyvpd+zbxE/fa2QBV1FA","question":"<p>Welche Seitennummer und welcher Versatz geh&#xF6;ren bei einstufiger\nSeitennummerierung und einer Seitengr&#xF6;&#xDF;e von 2048 Bytes zu folgender\nlogischer Adresse: <code>0xba1d</code></p>\n"},{"question":"<p>Man unterscheidet die Begriffe Programm und Prozess. Welche der\nfolgenden Aussagen zu diesem Themengebiet ist richtig?</p>\n","id":"sel53PZI87Cl8u57/JohZA","options":[{"comment":"<p>Nein, mehrere Prozessinstanzen k&#xF6;nnen das gleiche Programm ausf&#xFC;hren,\nzumindest auf einem UNIX&#x2122; System, welches <mark>keine</mark> solchen\nEinsch&#xE4;nkungen vorsieht.</p>\n","correct":false,"option":"<p>Ein Programm <mark>kann</mark> <mark>immer</mark> nur von einem\nProzess gleichzeitig ausgef&#xFC;hrt werden.</p>\n"},{"option":"<p>Das Programm ist der statische Teil (Rechte, Speicher, etc.), der\nProzess der aktive Teil (Programmz&#xE4;hler, Register, Stack).</p>\n","comment":"<p>Nein, der Speicher ist auch <q>aktiv</q> an der Ausf&#xFC;hrung beteiligt,\naber ansonsten ist auch die Begriffsunterscheidung hier (f&#xFC;r mich)\n<mark>nicht</mark> klar.</p>\n","correct":false},{"comment":"<p>Nein, der Begriff <q>Threads</q> (F&#xE4;den) verstanden als\n<q>Leichtgewichtiger Prozess</q>, beschreibt einen Ausf&#xFC;hrungsstrang,\nwelches mit anderen Threads <em>in einem Prozess</em> den gleichen\nSpeicherraum teil. Jedenfalls nennt man ein Programm weder Prozess oder\nThreads (Kategorien-Fehler), sondern ein Programm wird in bzw. von einem\nProzess oder in einem Thread ausgef&#xFC;hrt.</p>\n","correct":false,"option":"<p>Wenn ein Programm nur einen aktiven Ablauf enth&#xE4;lt, nennt man diesen\nProzess, enth&#xE4;lt das Programm mehrere Abl&#xE4;ufe, nennt man diese\nThreads.</p>\n"},{"comment":"<p>Ja, das ist die Definition. Ein Prozess <mark>kann</mark> sein\nProgramm Mittels eines <code>exec</code> Systemaufrufs auswechseln.</p>\n","correct":true,"option":"<p>Ein Prozess ist ein Programm in Ausf&#xFC;hrung - ein Prozess\n<mark>kann</mark> aber w&#xE4;hrend seiner Lebenszeit auch mehrere\nverschiedene Programme ausf&#xFC;hren.</p>\n"}],"source":"2016-02","multiple":false},{"id":"0vtYVw80qCobkT20iQGEhA","question":"<p>Welche der folgenden Aussagen zum Thema Seiteneinlagerungs- und\nSeitenersetzungsstrategien ist richtig?</p>\n","multiple":true,"options":[{"correct":true,"comment":"<p>Ja, MIN (oder <q>B0</q>, <q>OPT</q>) m&#xFC;sste die Referenzfolge zuvor\nwissen; der Ansatz ist <q>meist nur zum Vergleich von Strategien\nbrauchbar</q>.</p>\n","option":"<p>Die Ersetzungsstrategie MIN ist in der Praxis nur schwer\nrealisierbar, weil Wissen &#xFC;ber das zuk&#xFC;nftige Verhalten des\nGesamtsystems notwendig ist.</p>\n"},{"comment":"<p>Nein, weil bei einer globalen Ersetzungsstrategie verh&#xE4;llt sich ein\nSeitenfehler wie ein <em>Interrupt</em>, weil es <mark>nicht</mark>\ndirekt vorhersehbar ist anhand vom Verhalten des eigenen Programms.</p>\n","correct":false,"option":"<p>Bei der Verwendung von globalen Seitenersetzungsstrategien sind\nSeitenfehler vorhersagbar bzw. reproduzierbar.</p>\n"},{"option":"<p>Mit dem Systemaufruf <code>free()</code> <mark>kann</mark> eine\nSpeicherseite in den Freiseitenpuffer eingef&#xFC;gt werden.</p>\n","comment":"<p>Nein, mit <code>free()</code> wird im <em>Freispeicher</em> ein\nreservierte Speicherbereich zur&#xFC;ck gegeben. Es ist dar&#xFC;ber hinaus kein\nSystemaufruf, sondern verwaltet Speicher im Userspace.</p>\n","correct":false},{"correct":true,"comment":"<p>Ja, da Akronym LRU &#x2013; <em>Least Recently Used</em> &#x2013; deutet darauf\nhin.</p>\n","option":"<p>Die Ersetzungsstrategie LRU ersetzt die am l&#xE4;ngsten\n<mark>nicht</mark> mehr referenzierte Seite.</p>\n"},{"option":"<p>Bei der Verwendung von lokalen Seitenersetzungsstrategien sind\nSeitenfehler vorhersagbar bzw. reproduzierbar.</p>\n","correct":true,"comment":"<p>Ja, weil bei einer lokalen Ersetzungsstrategie ist ein Seitenfehler\nein <em>Trap</em>.</p>\n"},{"comment":"<p>Nein, FIFO (<em>First In, First Out</em>) <mark>kann</mark>\n<mark>immer</mark> gleich bestimmen welche Seite zu ersetzen ist,\nw&#xE4;hrend man bei LRU (<em>Least Recently Used</em>) erst berechnen m&#xFC;sste\nwelche Seite am l&#xE4;ngsten <mark>nicht</mark> benutzt wurde.</p>\n","correct":false,"option":"<p>Die Ersetzungsstrategie LRU ben&#xF6;tigt im Vergleich zu FIFO\n<mark>immer</mark> weniger Versuche, bis eine zu ersetzende Seite\ngefunden werden kann.</p>\n"},{"correct":false,"comment":"<p>Nein, bei einer lokalen Ersetzungsstrategien, ist ein Prozess selbst\ndaf&#xFC;r verantwortlich seine eigenen Seiten zu ersetzen.</p>\n","option":"<p>Lokale Seitenersetzungsstrategien w&#xE4;hlen die zu ersetzende Seite\n<mark>immer</mark> aus der Menge aller im System verf&#xFC;gbaren\nSeitenrahmen aus.</p>\n"},{"correct":true,"comment":"<p>Ja, das Akronym &#x2013; <em>Least Frequently Used</em> &#x2013; deutet darauf\nhin.</p>\n","option":"<p>Bei der Ersetzungsstrategie LFU wird die am seltensten referenzierte\nSeite aus dem Speicher verdr&#xE4;ngt.</p>\n"}],"source":"2016-02"},{"multiple":true,"options":[{"comment":"<p>Nein, ein Mutex <mark>kann</mark> auch zur mehrseitigen\nSynchronisation bei asymmetrischer Nebenl&#xE4;ufigkeit dienen (die\n<em>Mutual Exclusion</em>, welche mit einem <q>Mut Ex</q> umgesetzt\nwird, wird eben oft dazu benutzt um andere Handlungsstr&#xE4;nge davon\nabzuhalten, einen kritischen Abschnitt zu betreten, wo man unter der\nAnnahme arbeiten will, dass <mark>keine</mark> Wettlaufsituationen\nauftreten k&#xF6;nnen).</p>\n","correct":false,"option":"<p>Ein Mutex <mark>kann</mark> ausschlie&#xDF;lich f&#xFC;r einseitige\nSynchronisation verwendet werden.</p>\n"},{"option":"<p>Der Einsatz von nicht-blockierenden Synchronisationsmechanismen\n<mark>kann</mark> zu Verklemmungen (dead-locks) f&#xFC;hren.</p>\n","correct":false,"comment":"<p>Nein, ein Dead-Lock setzt voraus, dass ein Faden blockiert werden\nkann, bspw. durch ein Mutex oder eine Semaphore, was aber\n<mark>nicht</mark> der Fall ist bei nicht-blockierender Syncrhonisation,\ndessen Ansatz darauf basiert atomare Befehle zu verwenden, um\ntransaktional kritische Operationen auszuf&#xFC;hren. Bemerke aber, dass es\ndennoch zu einem Live-Lock, oder einem effektivem Live-Lock kommen kann,\nweil Nicht-Blockierende synchronisation, <mark>nicht</mark> bedeutet,\ndass der Ansatz Wartefrei/Sperrfrei/Behinderunfsfrei sein muss.</p>\n"},{"comment":"<p>Ja, im Gegensatz zu einem Mutex ist der Benutzer <mark>nicht</mark>\ndazu gezwungen erst die Semaphore zu <q>sperren</q> (<code>P</code>) und\ndanach auf dem gleichen Faden wieder <q>freizugeben</q>\n(<code>V</code>).</p>\n","correct":true,"option":"<p>Die V-Operation <mark>kann</mark> auf einem Semaphor auch von einem\nFaden aufgerufen werden, der zuvor <mark>keine</mark> P-Operation auf\ndem selben Semaphor ausgef&#xFC;hrt hat.</p>\n"},{"option":"<p>Ein Anwendungsprozess <mark>muss</mark> bei der Verwendung von\nSemaphoren Interrupts sperren, um Probleme durch Nebenl&#xE4;u&#xFB01;gkeit zu\nverhindern.</p>\n","comment":"<p>Nein, ein Anwendungsprozess <mark>kann</mark> selbst\n<mark>keine</mark> Interrupts Sperren, und unabh&#xE4;ngig davon ist das\n<mark>nicht</mark> notwendig, da Semaphoren selbst eine\nSyncrhonisationsmittel sind.</p>\n","correct":false},{"correct":true,"comment":"<p>Ja, Operationen wie CAS (Compare and Swap), TAS (Test and Set), FFA\n(Fetch and Add) werden bei verschienden Architekturen auf verschiedene\nBefehle abgebildet, welche &#x2013; ohne Betriebsystemunterst&#xFC;tzung &#x2013; in der\nLage sind die meist komplexen Operationen atomar auszuf&#xFC;hren. Siehe\nBeispilesweise auf x86 <a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_41.html\"><code>CMPXCHG</code></a>,\n<a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_25.html\"><code>BTS</code></a>\noder <a\nhref=\"https://c9x.me/x86/html/file_module_x86_id_327.html\"><code>XADD</code></a>\nmit dem <code>LOCK</code> prefix. Auf anderen Architekturen (h&#xE4;ufig\nRISC-artig) k&#xF6;nnen diese nachgebildet werden mittels <a\nhref=\"https://en.wikipedia.org/wiki/Load-link/store-conditional\">Load-link/store-conditional</a>\nbefehlen (siehe Vorlesungsfolien von der Vorlesung <a\nhref=\"https://www4.cs.fau.de/Lehre/WS19/V_CS/Vorlesung/folien/handout/5-elops.pdf\">Concurrent\nSystems</a> f&#xFC;r mehr zu dem Thema).</p>\n","option":"<p>F&#xFC;r nichtblockierende Synchronisation werden spezielle Befehle der\nHardware genutzt, die wechselseitigen Ausschluss garantieren.</p>\n"},{"correct":true,"comment":"<p>Ja. Bei einseitige Synchronisation <mark>kann</mark> man zwei\nsignalisierende Semaphoren benutzen, bei mehrseitige Synchronisation ein\nausschlie&#xDF;ende Semaphore.</p>\n","option":"<p>Semaphore k&#xF6;nnen sowohl f&#xFC;r einseitige als auch f&#xFC;r mehrseitige\nSynchronisation verwendet werden.</p>\n"},{"comment":"<p>Nein, allgemein <mark>kann</mark> man das <mark>nicht</mark> sagen,\nweil es auch davon abh&#xE4;ngt ob man ein Betriebsystem hat, oder wie lange\nman erwartet zu warten, wo die Kosten von passivem Warten ggf.\n<mark>nicht</mark> zu vernachl&#xE4;ssigen w&#xE4;ren.</p>\n","correct":false,"option":"<p>Zur Synchronisation eines kritischen Abschnitts ist passives Warten\n<mark>immer</mark> besser geeignet als aktives Warten.</p>\n"},{"option":"<p>Gibt ein Faden einen Mutex frei, den er selbst zuvor\n<mark>nicht</mark> angefordert hatte, stellt dies einen\nProgrammierfehler dar; der fehlerhafte Prozess sollte dann abgebrochen\nwerden.</p>\n","correct":true,"comment":"<p>Ja, weil das die beabsichtige Verwendung einer Semaphore verletzen\nw&#xFC;rde, welches eben diese Benutzung voraussetzt.</p>\n"}],"source":"2016-02","question":"<p>Welche der folgenden Aussagen zum Thema Synchronisation sind\nrichtig?</p>\n","id":"BEHCc7EHkkLdXMxbHn/k6Q"},{"id":"VQ4Sdk+cE8FArln2OWw7nQ","source":"2022-07","question":"<p>In einem UNIX-UFS-Dateisystem gibt es symbolische Namen/Verweise\n(Symbolic Links) und feste Links (Hard Links) auf Dateien. Welche\nAussage ist richtig?</p>\n","multiple":false,"options":[{"comment":"<p>Wenn kein <q>Hardlink</q> auf eine Datei existiert, dann l&#xF6;scht das\nDateisystem die Datei. Daher <mark>muss</mark> auf <mark>jede</mark>\nexistierende Datei mindestens ein Verweis existieren.</p>\n","correct":true,"option":"<p>F&#xFC;r <mark>jede</mark> regul&#xE4;re Datei existiert mindestens ein\nHard-Link im selben Dateisystem.</p>\n"},{"correct":false,"option":"<p>Wird der letzte Symbolic Link auf eine Datei gel&#xF6;scht, so wird auch\ndie Datei selbst gel&#xF6;scht.</p>\n","comment":"<p>Symbolic Links sind nur verweise auf Dateipfade, wobei die Datei\nhinter dem Dateipfad nichts von diesem Verweis wissen muss. Es ist ja\nauch m&#xF6;glich auf eine nicht-existierende Datei zu verweisen.</p>\n"},{"correct":false,"option":"<p>Ein Symbolic Link <mark>kann</mark> <mark>nicht</mark> auf Dateien\nanderer Dateisysteme verweisen.</p>\n","comment":"<p>Nein, weil Symbolic Links nur Pfade sind, welche das Betriebsystem\ntransparent aufl&#xF6;st, wenn man versucht auf die Datei zuzugreifen, aber\ndiese nichts &#xFC;ber das tats&#xE4;chliche System wissen. Bei Hard-Links ist das\nhingegen <mark>nicht</mark> der Fall, weil diese die gleiche\nInode-Nummer teilen m&#xFC;ssen, was von Datei-System abh&#xE4;ngig ist.</p>\n"},{"comment":"<p>Hard-Links k&#xF6;nnen auf beides verweisen, nur ist es mit dem\n<code>link</code> (bzw. dem <code>ln</code> Befehl) Systemaufruf dem\nBenutzer <mark>nicht</mark> erlaubt selbst Verweise auf Verzeichnisse zu\nerstellen. Damit wird sichergestellt, dass der Datei-Baum, der durch\nHard-Link aufgespannt wird, <mark>nicht</mark> zu einem Graphen\ndegeneriert, was Probleme bereiten w&#xFC;rde f&#xFC;r Werkzeuge wie\n<code>find</code>.</p>\n","option":"<p>Ein Hard Link <mark>kann</mark> nur auf Verzeichnisse verweisen,\n<mark>nicht</mark> jedoch auf Dateien.</p>\n","correct":false}]},{"options":[{"option":"<p>Ein Trap signalisiert einen schwerwiegenden Fehler und f&#xFC;hrt deshalb\n<mark>immer</mark> zur Beendigung des unterbrochenen Programms.</p>\n","correct":false,"comment":"<p>Nein, ein Trap <mark>kann</mark> auch durch eine <mark>nicht</mark>\neingelagerte Seite (wo dann mit der MMU versucht wird diese einzulagern,\nund dann das Programm weiter l&#xE4;uft) oder durch einen Systemaufruf\nausgel&#xF6;st werden.</p>\n"},{"comment":"<p>Nein, weil ein Interrupt nichts mit dem Programm zu tun hat, und\ndaher dieses <mark>nicht</mark> (direkt) abbrechen sollte.</p>\n","option":"<p>Ein durch einen Interrupt unterbrochenes Programm darf je nach der\nInterruptursache entweder abgebrochen oder fortgesetzt werden.</p>\n","correct":false},{"correct":true,"option":"<p>Obwohl Traps <mark>immer</mark> synchron auftreten, <mark>kann</mark>\nes im Rahmen ihrer Behandlung zu Wettlaufsituationen mit dem\nunterbrochenen Programm kommen.</p>\n","comment":"<p>Ja. Dazu <mark>muss</mark> man sich an die Definition vom Programm\nerinnern:</p>\n<blockquote>\n<p>Festlegung einer Folge von Anweisungen f&#xFC;r einen Prozessor, nach der\ndie zur Bearbeitung einer (durch einen Algorithmus wohldefinierten)\nHandlungsvorschrift erforderlichen Aktionen stattfinden sollen.</p>\n</blockquote>\n<p>darunter <mark>kann</mark> auch das <q>Hauptprogramm</q> vom\nBetriebsystem verstanden werden, welches von einem Trap-Handler (ein\nweiteres Programm) unterbrochen wird. Sollten beide (m&#xF6;glicherweise auf\nverschiedenen Kernen) versuchen synchronisierte Operationen auszuf&#xFC;hren,\nk&#xF6;nnen diese sich gleichzeitig verklemmen.</p>\n"},{"correct":false,"option":"<p>Ein Systemaufruf im Anwendungsprogramm ist der Kategorie Interrupt\nzuzuordnen.</p>\n","comment":"<p>Nein, ein Systemaufruf ist ein Trap, weil diese deterministisch bei\nder Ausf&#xFC;hrung auftreten, bspw. wenn je nach Rechenarchitektur ein <a\nhref=\"https://www.felixcloutier.com/x86/syscall\"><code>syscall</code></a>\n(x86_64) Befehl ausgef&#xFC;hrt wird.</p>\n"}],"multiple":false,"question":"<p>Ausnahmesituationen bei einer Programmausf&#xFC;hrung werden in die beiden\nKategorien Trap und Interrupt unterteilt. Welche der folgenden Aussagen\nist zutreffend?</p>\n","id":"A/fH7banNyahxsZ2ohEwpQ","source":"2022-07"},{"options":[{"option":"<p>Durch die Bereitstellung von Systemaufrufen, <mark>kann</mark> ein\nBenutzerprogramm das Betriebssystem um eigene Funktionen erweitern.</p>\n","correct":false,"comment":"<p>Nein, Systemaufrufe sind die Schnittstelle, die das Betriebssystem\nBenutzerprozessen zur Verf&#xFC;gung stellt, um privilegierte Operationen,\nkontrolliert ausf&#xFC;hren zu lassen. Benutzerprozesse k&#xF6;nnen (u. a. aus\nSicherheitsgr&#xFC;nden) das Betriebssystem <mark>nicht</mark> in dieser\nHinsicht ver&#xE4;ndern.</p>\n"},{"correct":true,"option":"<p>Mit Hilfe von Systemaufrufen <mark>kann</mark> ein Benutzerprogramm\nprivilegierte Operationen durch das Betriebssystem ausf&#xFC;hren lassen, die\nes im normalen Ablauf <mark>nicht</mark> selbst ausf&#xFC;hren d&#xFC;rfte.</p>\n","comment":"<p>Ja, m&#xF6;chte ein Programm z. B. eine Datei lesen, so sendet es\n<mark>nicht</mark> selbst z. B. NVMe-Befehle an den Speicher\n(privilegierte Operation, k&#xF6;nnte zum Verlust aller Daten f&#xFC;hren),\nsondern beauftragt das Betriebssystem (im Fall von POSIX mit\n<code>read(2)</code>), den Dateiinhalt zu lesen.</p>\n"},{"comment":"<p>Nein, bei der Bearbeitung eines Systemaufrufs im Systemkern\n(<em>kernel</em>) ist der <em>kernel address space</em>, der\n<mark>nicht</mark> f&#xFC;r Benutzerprozesse sichtbar ist, verf&#xFC;gbar.</p>\n","option":"<p>Die Bearbeitung eines Systemaufrufs findet <mark>immer</mark> im\nselben Adressraum statt, aus dem heraus der Systemaufruf abgesetzt\nwurde.</p>\n","correct":false},{"correct":false,"option":"<p>Benutzerprogramme d&#xFC;rfen <mark>keine</mark> Systemaufrufe absetzen,\ndiese sind dem Betriebssystem vorbehalten.</p>\n","comment":"<p>Nein, Benutzerprozesse verwenden Systemaufrufe, um Operationen\nauszuf&#xFC;hren, f&#xFC;r die sie selbst <mark>nicht</mark> die Privilegien\nbesitzen.</p>\n"}],"multiple":false,"id":"rze1+m3bsrHZ8QGIK5CBhg","source":"2022-07","question":"<p>Welche Aussage zum Thema Systemaufrufe ist richtig?</p>\n"},{"multiple":false,"options":[{"option":"<p>Nach dem Beendigungsmodell werden Interrupts bearbeitet. Gibt man z.\nB. CTRL-C unter UNIX &#xFC;ber die Tastatur ein, wird ein Interrupt-Signal an\nden gerade laufenden Prozess gesendet und dieser dadurch beendet.</p>\n","correct":false,"comment":"<p>Nein, der Interrupt wird vom Betriebssystem abgefangen. Dieses\n<mark>kann</mark> dann einem Prozess ein Signal zustellen. Dieser\n<mark>muss</mark> jedoch <mark>nicht</mark> unbedingt der gerade\nlaufende Prozess sein (Auch Hintergrundprozesse (<em>daemons</em>)\nk&#xF6;nnen sich im Zustand <q>laufend</q> befinden).</p>\n"},{"correct":false,"option":"<p>Das Beendigungsmodell sieht das Herunterfahren des Betriebssystems im\nFalle eines schwerwiegenden Fehlers vor.</p>\n","comment":"<p>Nein. Es reicht aus, nur den problematischen Prozess zu beenden. Das\nhier beschriebene Herunterfahren w&#xFC;rde die Robustheit eines\nBetriebssystems senken.</p>\n"},{"comment":"<p>Ja. Auch bei Traps wie z. B. einem Seitenfehler, bei dem ein Prozess\nauf eine Seite zugreift, die gerade ausgelagert ist (<em>swapping</em>),\nist das Weiterlaufen des Prozesses, nachdem die Seite wieder eingelagert\nwurde, sinnvoll.</p>\n","option":"<p>Das Wiederaufnahmemodell ist f&#xFC;r Interrupts und Traps gleicherma&#xDF;en\ngeeignet.</p>\n","correct":true},{"comment":"<p>Nein, Interrupts sind unvorhersagbare Ereignisse wie z. B. das\nEingehen eines Netzwerkpaketes oder das Dr&#xFC;cken einer Taste auf der\nTastatur. Der aktuell laufende Prozess sollte i. A. <mark>nicht</mark>\ndirekt wegen einem derartigen Ereignis beendet werden, da dieser\n<mark>nicht</mark> unbedingt einen Bezug zu einer derartigen Eingabe\nhat.</p>\n","option":"<p>Interrupts sollten nach dem Beendigungsmodell behandelt werden, weil\nein Zusammenhang zwischen dem unterbrochenen Prozess und dem Grund des\nInterrupts bestehen kann.</p>\n","correct":false}],"source":"2022-07","id":"nQgZhl7kN1ExGL7cd0DQ0w","question":"<p>Bei der Behandlung von Ausnahmen (Traps oder Interrupts)\nunterscheidet man zwei Bearbeitungsmodelle. Welche Aussage hierzu ist\nrichtig?</p>\n"},{"question":"<p>Welche Aussage zum Thema Programme und Prozesse ist richtig?</p>\n","id":"6jLIiaGDL3Yy3Q/R9O1gQg","source":"2022-07","multiple":false,"options":[{"correct":true,"option":"<p>Ein Programm <mark>kann</mark> durch mehrere Prozesse gleichzeitig\nausgef&#xFC;hrt werden</p>\n","comment":"<p>Ja, teste z. B.</p>\n<pre><code>sleep 5 &amp;\nsleep 5</code></pre>\n<p>Hier wird das Programm <code>sleep</code> gleichzeitig ausgef&#xFC;hrt,\nweswegen dieser Befehl nur 5 Sekunden (statt 10) ben&#xF6;tigt.</p>\n"},{"correct":false,"option":"<p>In einem Prozess <mark>kann</mark> <mark>immer</mark> nur ein\nProgramm ausgef&#xFC;hrt werden.</p>\n","comment":"<p>Nein, nach POSIX <mark>kann</mark> mit <code>exec(3)</code> ein\nProzess zu einem anderen Programm wechseln.</p>\n"},{"correct":false,"option":"<p>Ein Prozess <mark>kann</mark> gleichzeitig mehrere verschiedene\nProgramme ausf&#xFC;hren.</p>\n","comment":"<p>Nein, ein Prozess ist <em>ein</em> Programm in Ausf&#xFC;hrung. Es\n<mark>kann</mark> zwar zu einem anderen Programm gewechselt werden,\nm&#xF6;chte man jedoch nebenl&#xE4;ufig ein anderes Programm ausf&#xFC;hren,\n<mark>muss</mark> man einen neuen Prozess erzeugen (<code>fork(2)</code>\n+ <code>exec(3)</code> oder <code>posix_spawn(3)</code>)</p>\n"},{"correct":false,"option":"<p>Der Compiler erzeugt aus mehreren Programmteilen (Module) einen\nProzess.</p>\n","comment":"<p>Nein. Der Compiler erzeugt Programme (oder Objektdateien, die zu\nProgrammen gebunden werden), ein Prozess wird aber erst zur Laufzeit vom\nBetriebssystem erstellt.</p>\n"}]},{"multiple":false,"options":[{"option":"<p>Es ist kein direkter &#xDC;bergang von laufend nach bereit m&#xF6;glich.</p>\n","correct":false},{"comment":"<p>Ja, der Prozess k&#xF6;nnte noch weiter rechnen, ist also\n<em>bereit</em>.</p>\n","option":"<p>Der Prozess wird durch einen anderen Prozess verdr&#xE4;ngt, oder gibt die\nCPU freiwillig ab.</p>\n","correct":true},{"comment":"<p>Nein, der Prozess ist dann <em>blockiert</em>, bis die Daten gelesen\nsind.</p>\n","correct":false,"option":"<p>Der Prozess wartet auf Daten von der Festplatte.</p>\n"},{"comment":"<p>Nein, der Prozess ist dann <em>blockiert</em>, bis der andere Prozess\nbeendet ist. Eine Ausnahme k&#xF6;nnte hier der Aufruf mit dem Parameter\n<code>WNOHANG</code> darstellen, mit welchem der Systemaufruf sofort\nzur&#xFC;ckgibt.</p>\n","option":"<p>Der Prozess wartet mit dem Systemaufruf <code>waitpid(3)</code> auf\ndie Beendigung eines anderen Prozesses.</p>\n","correct":false}],"id":"owkzT23gSuN6Lgxv/Ao61g","source":"2022-07","question":"<p>Ein laufender Prozess wird in den Zustand bereit &#xFC;berf&#xFC;hrt. Welche\nAussage passt zu diesem Vorgang?</p>\n"},{"options":[{"comment":"<p>Ja, <code>0x0802 = 0b0000 10|00 0000 0010</code> also ist die\nSeitennummer <code>0b00 0010 = 0x2</code> und der Offset\n<code>0b00 0000 0010 = 0x2</code></p>\n","option":"<p>Seitennummer 0x2, Offset 0x2</p>\n","correct":true},{"comment":"<p>Nein. Hier sind beide Angaben falsch.</p>\n","correct":false,"option":"<p>Seitennummer 0x8, Offset 0x8</p>\n"},{"correct":false,"option":"<p>Seitennummer 0x2, Offset 0x8</p>\n","comment":"<p>Nein. Hier ist der Offset falsch.</p>\n"},{"comment":"<p>Nein. Da hier der Offset 10 Bit und kein Vielfaches von 4 hat, darf\nman <mark>nicht</mark> einfach die Hexadezimaldarstellung an der Grenze\neines <a\nhref=\"https://de.wikipedia.org/wiki/Nibble\"><em>nibbles</em></a> (=\nHalbbyte, 4 Bit, ein Zeichen in Hexadezimaldarsetllung) zerlegen.\nDeswegen ist hier die Seitennummer falsch.</p>\n","option":"<p>Seitennummer 0x8, Offset 0x2</p>\n","correct":false}],"multiple":false,"question":"<p>Welche Seitennummer und welcher Offset geh&#xF6;ren bei einstufiger\nSeitennummerierung und einer Seitengr&#xF6;&#xDF;e von 1024 (= 2<sup>10</sup>)\nBytes zu folgender logischer Adresse: 0x0802?</p>\n","id":"qL1S/eROOnxl9+Nmo2rScQ","source":"2022-07"},{"options":[{"correct":true,"option":"<p>Nach dem Aufruf von <code>fork(2)</code> teilen sich Eltern und\nKindprozess die den gemeinsamen Dateideskriptoren zu Grunde liegenden\nKernel-Datenstrukturen.</p>\n","comment":"<p>Ja, vergleiche zum Beispiel <q>sister</q>, bei der ein Kindprozess\nf&#xFC;r die Bearbeitung einer Anfrage zust&#xE4;ndig war und den Dateideskriptor\nverwendet, der im Elternprozess von <code>accept(3)</code> zur&#xFC;ckgegeben\nwurde.</p>\n"},{"correct":false,"option":"<p>Da Dateideskriptoren Zeiger auf Betriebssystem-Interne Strukturen\nsind, k&#xF6;nnen diese zwischen Prozessen geteilt werden.</p>\n","comment":"<p>Der Dateideskriptor ist lediglich ein Wert, der vom Betriebssystem\nals eine Referenz auf einen Wert in einer pro Prozess im <em>kernel\nspace</em> angelegte Datenstruktur interpretiert wird (z. B. ein Index\nin ein Array an Dateideskriptionen). Da diese <mark>nicht</mark> geteilt\nist, ist auch das Teilen von Dateideskriptoren im Allgemeinen\n<mark>nicht</mark> zielf&#xFC;hrend.</p>\n"},{"comment":"<p>Nein, das w&#xE4;re die <q>inode</q>. Der Dateideskriptor ist eine\nReferenz (jedoch kein Pointer) auf eine Datenstruktur im Betriebssystem,\ndie u. a. auch die Position des Prozesses in der Datei enth&#xE4;lt.</p>\n","option":"<p>Der Dateideskriptor enth&#xE4;lt die n&#xF6;tigen Metadaten einer Datei und ist\nauf der Festplatte gespeichert.</p>\n","correct":false},{"comment":"<p>Nein, dieses Flag existiert <mark>nicht</mark> (bis <a\nhref=\"https://pubs.opengroup.org/onlinepubs/9799919799/index.html\">POSIX\n2024</a>). Angespielt wird hier auf <code>FD_CLOEXEC</code>, was die\nbeschriebene Wirkung bei einem Aufruf von <code>exec(3)</code>\nzeigt.</p>\n","correct":false,"option":"<p>Das Flag <code>FD_CLOFORK</code> eines Dateideskriptors sorgt daf&#xFC;r,\ndass der Dateideskriptor bei einem Aufruf von <code>fork(2)</code>\nautomatisch geschlossen wird.</p>\n"}],"multiple":false,"id":"kT2pKmcbIS6q/fZ1i2IswQ","source":"2022-07","question":"<p>Welche Aussage zu UNIX/Linux-Dateideskriptoren ist korrekt?</p>\n"},{"multiple":false,"options":[{"option":"<p>F&#xFC;r die Synchronisation zwischen dem Hauptprogramm und einer\nSignalbehandlungsfunktion sind Schlossvariablen (Locks) ungeeignet.</p>\n","correct":true,"comment":"<p>Ja. Signalbehandlung stellt asymmetrische Nebenl&#xE4;ufigkeit dar. Der\naktuelle Ausf&#xFC;hrungsstrang wird also unterbrochen, um zum <em>signal\nhandler</em> zu springen. Wenn dieser nun versucht, ein <em>lock</em> zu\nsperren, das schon vom Hauptprogramm gesperrt wurde, so wartet dieser\nauf das Hauptprogramm, welches jedoch durch die Signalbehandlung\nunterbrochen ist. Es kommt zu einer Verklemmung.</p>\n"},{"comment":"<p>Nein. Einerseits ist das Sperren von Interrupts, die ja\n<mark>nicht</mark> notwendigerweise im Zusammenhang mit dem Prozess\nstehen m&#xFC;ssen, eine privilegierte Operation, die dem Betriebssystem\nvorenthalten ist. Andererseits w&#xFC;rde dies bei manchen Formen von\nNebenl&#xE4;ufigkeit <mark>nicht</mark> den gew&#xFC;nschten Effekt erzielen, da\nz. B. auf einem Multiprozessorsystem mehrere leichtgewichtige Prozesse\n(<em>kernel-level threads</em>) echt nebenl&#xE4;ufig Speicherzugriffe\ndurchf&#xFC;hren k&#xF6;nnen, ohne dass einer der Prozesse durch einen Interrupt\nverdr&#xE4;ngt wird.</p>\n","option":"<p>Ein Unix-Prozess <mark>kann</mark> durch das Sperren von\nUnterbrechungen (Interrupts) den Speicherzugriff in einem kritische\nAbschnitte [sic!] synchronisieren.</p>\n","correct":false},{"option":"<p>In einem Unix-Prozess <mark>kann</mark> es keinen kritischen\nAbschnitt geben, da <mark>immer</mark> nur ein Aktivit&#xE4;tstr&#xE4;ger pro\nProzess aktiv ist.</p>\n","correct":false,"comment":"<p>Nein. Die Ressourcen eines schwergewichtigen Prozesses k&#xF6;nnen\nzwischen verschiedenen leichtgewichtigen Prozessen geteilt sein, die\nnebenl&#xE4;ufig einen Aktivit&#xE4;tsstrang ausf&#xFC;hren.</p>\n"},{"correct":false,"option":"<p>Kritische Abschnitte k&#xF6;nnen unter Unix nur mit Semaphoren\nsynchronisiert werden.</p>\n","comment":"<p>Nein. es gibt vielerlei Synchronisationsmechanismen f&#xFC;r verschiedene\nArten von Nebenl&#xE4;ufigkeit, f&#xFC;r kritische Abschnitte <mark>kann</mark>\ninsbesondere auch <code>pthread_mutex</code> verwendet werden.</p>\n"}],"source":"2022-07","id":"p0CCOugFigYrt57qf5d33Q","question":"<p>Welche Aussage &#xFC;ber die Koordinierung von kritischen Abschnitten\nunter Unix ist richtig?</p>\n"},{"source":"2022-07","id":"ryAiZqXox/u20Np7DtaCqQ","question":"<p>Welche der Aussagen zu folgendem Programmfragment sind richtig?</p>\n<pre><code>static int a = 2022;\nvoid f1 (const int *y) {\n    static int b;\n    int c;\n    char *d = malloc(0x802);\n    void (*e)(const int *) = f1;\n    y++;\n    //...\n}</code></pre>\n","multiple":true,"options":[{"correct":true,"option":"<p><code>e</code> liegt im Stacksegment und zeigt in das\nTextsegment.</p>\n","comment":"<p>Ja. <code>e</code> ist ein Zeiger auf die Funktion <code>f1</code>.\nFunktionen liegen im Textsegment. Zudem ist <code>e</code> eine lokale\nVariable, liegt also im Stacksegment.</p>\n"},{"correct":false,"option":"<p><code>c</code> ist mit dem Wert 0 initialisiert.</p>\n","comment":"<p>Nein, nur Variablen der Speicherklasse <code>auto</code>, also\nglobale Variablen und lokale <code>static</code>-Variablen werden auf 0\ngesetzt, wenn sie <mark>nicht</mark> anderweitig initialisiert werden.\n<code>c</code> ist uninitialisiert.</p>\n"},{"option":"<p>Die Anweisung <code>y++</code> f&#xFC;hrt zu einem Laufzeitfehler, da\n<code>y</code> konstant ist.</p>\n","correct":false,"comment":"<p>Nein. Das Ziel von <code>y</code> ist hier <code>const</code>,\n<code>y</code> selbst jedoch nicht. Pointerarithmetik auf <code>y</code>\nist also erlaubt. Eine Merkregel hierf&#xFC;r lautet <q><code>const</code>\nbezieht sich auf das Schl&#xFC;sselwort links davon, au&#xDF;er es steht ganz\nlinks. Dann bezieht sich <code>const</code> auf das Schl&#xFC;sselwort rechts\ndavon.</q> Hier bez&#xF6;ge sich const also auf <code>int</code>,\n<mark>nicht</mark> auf <code>*</code>. Siehe auch <a\nhref=\"https://c-faq.com/decl/spiral.anderson.html\">hier</a></p>\n"},{"comment":"<p>Ja. Mit <code>malloc(3)</code> wird Haldenspeicher allokiert.</p>\n","correct":true,"option":"<p><code>d</code> ist ein Zeiger, der in den Heap zeigt.</p>\n"},{"comment":"<p>Ja. <code>a</code> ist eine globale Variable. Globale Variablen\nliegen im Datensegment. <code>a</code> liegt im Datensegment.</p>\n","option":"<p><code>a</code> liegt im Datensegment.</p>\n","correct":true},{"correct":null,"option":"<p><code>y</code> liegt im Stacksegment.</p>\n","comment":"<p>Gem&#xE4;&#xDF; der x86_64-System V-ABI liegen Funktionsparameter wie\n<code>y</code> in einem Register, das ist jedoch <mark>nicht</mark>\nplattformunabh&#xE4;ngig garantiert. Ich vermute trotzdem, die erwartete\nAntwort hier ist <q>ja</q>.</p>\n"},{"comment":"<p>Durch die Verwendung von <code>static</code> innerhalb einer Funktion\nerzeugt man eine Variable, die zwar nur in diesem G&#xFC;ltigkeitsbereich\nsichtbar ist, bei der jedoch &#xC4;nderungen in einem Aufruf der Funktion in\nsp&#xE4;teren Aufrufen sichtbar sind. Derartige Variablen liegen im\nDatensegment.</p>\n","option":"<p><code>b</code> liegt im Stacksegment.</p>\n","correct":false},{"option":"<p>Die Speicherstelle, auf die <code>d</code> zeigt, verliert beim\nR&#xFC;cksprung aus der Funktion <code>f1()</code> ihre G&#xFC;ltigkeit.</p>\n","correct":false,"comment":"<p>Nein, da diese Speicherstelle im Heap liegt und - im Gegensatz zu\nStackspeicher - erst durch den Aufruf von <code>free(3)</code> ung&#xFC;ltig\nwird.</p>\n"}]},{"options":[{"comment":"<p>Nein, die <em>P</em>-Operation (<a\nhref=\"https://en.wikipedia.org/wiki/Semaphore_(programming)#Operation_names\">vom\nNiederl&#xE4;ndischen <em>probeer te verlagen</em> - versuche, zu\nverringern</a>) verringert den Wert der Semaphore um 1 und blockiert,\nwenn dies den Wert unter 0 bringen w&#xFC;rde, bis eine V-Operation\naufgerufen wird. Daher <q>verwechselt</q> diese Frage <em>P</em> und\n<em>V</em>.</p>\n","option":"<p>Die <em>P</em>-Operation eines Semaphors erh&#xF6;ht den Wert des\nSemaphors um 1 und deblockiert gegebenenfalls wartende Prozesse.</p>\n","correct":false},{"correct":true,"option":"<p>Die V-Operation eines Semaphors erh&#xF6;ht den Wert des Semaphors um 1\nund deblockiert gegebenenfalls wartende Prozesse.</p>\n","comment":"<p>Ja, die <em>V</em>-Operation (urspr&#xFC;nglich vom Niederl&#xE4;ndischen\n<em>vrijgave</em> - freigeben) erh&#xF6;ht den Wert der Semaphore um 1. Dabei\nwird eventuell eine wartende <em>P</em>-Operation entblockiert.</p>\n"},{"comment":"<p>Nein, eine bin&#xE4;re Semaphore (Semaphore mit Startwert 1), bei der P\nund V <mark>immer</mark> paarweise nacheinander aufgerufen werden,\nimplementiert gegenseitigen Ausschluss.</p>\n","correct":false,"option":"<p>Ein Semaphor <mark>kann</mark> nur zur Signalisierung von\nEreignissen, <mark>nicht</mark> jedoch zum Erreichen gegenseitigen\nAusschlusses verwendet werden.</p>\n"},{"comment":"<p>Nein, eine Semaphore erlaubt dies im Gegensatz zu einem\n<em>mutex</em>, wo das nicht-einhalten dieser Vorschrift als\nProgrammierfehler angesehen wird.</p>\n","option":"<p>Die V-Operation eines Semaphors <mark>kann</mark> ausschlie&#xDF;lich von\neinem Thread aufgerufen werden, der zuvor mindestens eine P-Operation\nauf dem selben Semaphor aufgerufen hat.</p>\n","correct":false}],"question":"<p>Welche Aussage zu Semaphoren ist richtig?</p>\n","source":"2017-02","id":"l3HebarBJdZGK37bVC8i3w","multiple":false},{"multiple":false,"source":"2017-02","id":"hN0W0MhHxWWM/BN99LHwEw","question":"<p>Welche Seitennummer und welcher Offset geh&#xF6;ren bei einstufiger\nSeitennummerierung und einer Seitengr&#xF6;&#xDF;e von 1024 Bytes zu folgender\nlogischer Adresse: <code>0xc01a</code>?</p>\n","options":[{"correct":false,"option":"<p>Seitennummer 0xc, Offset 0x1a</p>\n"},{"correct":true,"option":"<p>Seitennummer <code>0x30</code>, Offset <code>0x1a</code></p>\n","comment":"<p>1024 = 2<sup>10</sup> Byte pro Seite, d.&#xA0;h. 6 Bit Seitennummer, 10\nBit Offset. <code>0xc01a = 0b1100 00|00 0001 1010</code> also ist der\n<em>Offset</em> <code>0b00 0001 1010 = 0x1a</code> und die Seitennummer\n<code>0b0011 0000 = 0x30</code>.</p>\n"},{"option":"<p>Seitennummer <code>0xc0</code>, Offset <code>0x1a</code></p>\n","correct":false,"comment":"<p>Nein. Da hier der Offset 10 Bit und damit kein Vielfaches von 4 Bit\nhat, darf man <mark>nicht</mark> einfach die Hexadezimaldarstellung an\nder Grenze eines <a\nhref=\"https://de.wikipedia.org/wiki/Nibble\"><em>nibbles</em></a> (=\nHalbbyte, 4 Bit, ein Zeichen in Hexadezimaldarsetllung) zerlegen.\nDeswegen ist hier die Seitennummer falsch.</p>\n"},{"option":"<p>Seitennummer <code>0xc01</code>, Offset <code>0xa</code></p>\n","correct":false}]},{"options":[{"correct":false,"option":"<p>Lokale automatic-Variablen, die auf dem Stack angelegt werden, werden\n<mark>immer</mark> mit dem Wert 0 initialisiert.</p>\n","comment":"<p>Lokale Variablen sind uninitialisiert, bis sie (eventuell zusammen\nmit der Deklaration) initialisiert werden. Lesender Zugriff auf\nuninitialisierte Werte ist undefiniertes Verhalten. Globale\n<em>modul-interne</em> Variablen (<code>static</code>) sind hingegen\nstandardm&#xE4;&#xDF;ig auf 0 initialisiert.</p>\n"},{"comment":"<p>Nein. C ist <em>call-by-value</em>, &#xFC;bergeben wird also tats&#xE4;chlich\nder Wert der Variable, <mark>nicht</mark> etwa eine Referenz darauf\n&#xFC;bergeben. Dass hier beschriebene <em>call-by-reference</em>-Verhalten\n<mark>kann</mark> z. B. in C++ durch die Verwendung von\n<code>&amp;</code> (<a\nhref=\"https://en.cppreference.com/w/cpp/language/reference\">References</a>)\noder in Ada mit <a\nhref=\"http://www.ada-auth.org/standards/22rm/html/RM-6-2.html\">IN\nOUT</a> Parameter erzeugt oder in C durch <em>Zeiger</em> nachgebildet\nwerden.</p>\n","option":"<p>Wird dem Parameter einer Funktion innerhalb der Funktion ein neuer\nWert zugewiesen, so &#xE4;ndert sich auch der Wert der Variablen, welche in\nder aufrufenden Funktion als Parameter angegeben wurde.</p>\n","correct":false},{"option":"<p>Eine Funktion, die mit dem Schl&#xFC;sselwort static definiert wird,\n<mark>kann</mark> nur innerhalb des Moduls aufgerufen werden, in dem sie\ndefiniert wurde, <mark>nicht</mark> jedoch aus einem anderen Modul\nheraus.</p>\n","correct":true,"comment":"<p>Ja. <code>static</code> bei Funktionen und globalen Variablen\nver&#xE4;ndert die Sichtbarkeit wie hier beschrieben. (<code>static</code>\nbei lokalen Variablen in Funktionen sorgt daf&#xFC;r, dass der Wert der\nVariablen Funktionsaufrufe hinweg erhalten bleibt.) Es ist dennoch\nm&#xF6;glich einen Zeiger auf die Funktion an andere Module zu &#xFC;bergeben,\nwomit man den indirekten Aufruf einer <code>static</code> Funktion\nerlaubt.</p>\n"},{"option":"<p>Es ist <mark>nicht</mark> m&#xF6;glich, Zeiger als Parameter an Funktionen\nzu &#xFC;bergeben.</p>\n","correct":false,"comment":"<p>Nein, das ist m&#xF6;glich.</p>\n"}],"question":"<p>Welche Aussage &#xFC;ber Variablen in C-Programmen ist richtig?</p>\n","id":"/9zPhOBPsKWhGVZPasMMTA","source":"2017-02","multiple":false},{"options":[{"comment":"<p>Nein, das ist nur bei <em>Hansen</em> und <em>Hoare</em> der Fall,\nbei <em>Mesa</em> <mark>kann</mark> der Signalgeber im Monitor\nfortfahren. (vgl. <a\nhref=\"https://sys.cs.fau.de/extern/lehre/ws23/sp2/vorlesung/folien/SP2-102-A4.pdf#page=13\">SP2\nKapitel 10.2 S. 13</a>)</p>\n","correct":false,"option":"<p>Bei allen Monitorkonzepten (<em>Hansen, Hoare, Mesa</em>) verl&#xE4;sst\nder Prozess, der den Eintritt eines Ereignisses anzeigt (Signalgeber),\nden Monitor unmittelbar nach der Signalisierung.</p>\n"},{"correct":true,"option":"<p>Wartet ein Prozess in einem Monitor auf ein Ereignis, so\n<mark>muss</mark> er den Monitor w&#xE4;hrend der Wartezeit zwingend\nfreigeben, um einer Verklemmung vorzubeugen.</p>\n","comment":"<p>Ja. Sonst k&#xF6;nnte kein anderer Prozess den Monitor betreten, um die\nWartebedingung aufzuheben. Vergleiche z. B. blockierende Warteschlange.\nW&#xFC;rde hier der Konsument den Monitor <mark>nicht</mark> freigeben, so\nk&#xF6;nnte ein Produzent kein Element einf&#xFC;gen, es liegt also eine\nVerklemmung vor.</p>\n"},{"comment":"<p>Nein, ein Monitor nach <em>Hansen</em> setzt <mark>alle</mark>\nSignalnehmer auf <q>bereit</q>. Dadurch m&#xFC;ssen Signalnehmer auch im\nkritischen Abschnitt erneut &#xFC;berpr&#xFC;fen, ob die Wartebedingung noch gilt\n(vgl. Semaphore bei <em>jbuffer</em>). Ein Monitor nach <em>Hoare</em>\nsetzt im Gegensatz dazu nur genau einen Signalnehmer auf <q>bereit</q>.\n(vgl. Folie)</p>\n","option":"<p>Ein Monitor nach Hansen befreit bei der Signalisierung h&#xF6;chstens\neinen der wartenden Prozesse.</p>\n","correct":false},{"option":"<p>Wird einem Prozess durch einen Monitor nach Hoare die Aufhebung\nseiner Wartebedingung signalisiert, so wird die Bedingung erneut\nausgewertet; falsche Signalisierungen k&#xF6;nnen also toleriert werden.</p>\n","correct":false,"comment":"<p>Nein, bei einem Monitor nach <em>Hoare</em> wird genau ein Prozess\nauf bereit gesetzt. Der Prozess darf also davon ausgehen, dass die\nBedingung erf&#xFC;llt ist (sonst w&#xE4;re <mark>nicht</mark> signalisiert\nworden) und <mark>nicht</mark> nebenl&#xE4;ufig von einem anderen Prozess\nwieder ver&#xE4;ndert wurde, bevor er den kritischen Abschnitt betreten hat.\nMan betrachte hier z. B. das Beispiel <em>blocking queue</em>. Im Modell\n<em>Hoare</em> ist beim Aufwecken eines Konsumententhreads garantiert,\ndass ein Element in die Warteschlange gelegt wurde. Zudem wurde nur\nh&#xF6;chstens ein Konsumententhread aufgeweckt, also wurde das Element noch\n<mark>nicht</mark> herausgenommen. Der Konsument (Signalnehmer) darf\nalso den Monitor betreten und das Element entnehmen, ohne im kritischen\nAbschnitt zu &#xFC;berpr&#xFC;fen, ob ein anderer Konsument schneller war. Ein\nfalsches Signal k&#xF6;nnte hier dazu f&#xFC;hren, dass aus einer leeren\nWarteschlange entnommen wird.</p>\n"}],"question":"<p>Welche Aussage zu Monitoren ist richtig?</p>\n","id":"BUMuXHYg2s5fBnOostXpbQ","source":"2017-02","multiple":false},{"source":"2017-02","id":"Dl3ijWFoaLEN8vLaGwpwPA","multiple":false,"options":[{"option":"<p>Der Name einer Datei wird in ihrem Dateikopf (<em>inode</em>)\ngespeichert.</p>\n","correct":false,"comment":"<p>Nein, der Name wird in dem Verzeichnis gespeichert, das die Datei\nenth&#xE4;lt. Es k&#xF6;nnen auch mehrere Verzeichnisse Eintr&#xE4;ge mit\nunterschiedlichen Namen haben, die auf dieselbe <em>inode</em>\nverweisen.</p>\n"},{"comment":"<p>Nein. Jedes Verzeichnis enth&#xE4;lt sogar mindestens einen solchen\nEintrag (<code>.</code>, der Selbstverweis).</p>\n","option":"<p>In einem Verzeichnis darf es keinen Eintrag geben, der auf das\nVerzeichnis selbst verweist.</p>\n","correct":false},{"comment":"<p>Nein, auf eine regul&#xE4;re Datei <mark>muss</mark> nur mindestens ein\n<em>hard link</em> verweisen, damit sie <mark>nicht</mark> gel&#xF6;scht\nwird. Die Aussage gilt nur f&#xFC;r Verzeichnisse, die <mark>immer</mark>\neinen Verweis auf sich selbst (<code>.</code>) beinhalten und den\nVerweis des Elternverzeichnisses innehaben.</p>\n","option":"<p>Auf eine Datei in einem Dateisystem verweisen <mark>immer</mark>\nmindestens zwei <em>hard-links</em>.</p>\n","correct":false},{"option":"<p>Innerhalb eines Verzeichnisses k&#xF6;nnen mehrere Verweise auf den selben\n<em>inode</em> existieren, sofern diese unterschiedliche Namen\nhaben.</p>\n","correct":true,"comment":"<p>Ja, das <mark>kann</mark> z. B. mit <code>ln datei auch-datei</code>\nf&#xFC;r eine Datei <code>datei</code> im aktuellen Arbeitsverzeichnis\nerzielt werden, indem die neue Datei <code>auch-datei</code> erstellt\nwird welches sich die gleiche <em>inode</em> teilt.</p>\n"}],"question":"<p>Welche der folgenden Aussagen &#xFC;ber UNIX-Dateisysteme ist richtig?</p>\n"},{"question":"<p>Welche der folgenden Aussagen zum Thema persistenter Datenspeicherung\nsind richtig?</p>\n","options":[{"correct":false,"option":"<p>Bei kontinuierlicher Speicherung ist es <mark>immer</mark> problemlos\nm&#xF6;glich, bestehende Dateien zu vergr&#xF6;&#xDF;ern.</p>\n","comment":"<p>Nein, eventuell ist der Platz nach dem Ende der Datei bereits belegt,\nweswegen sie <mark>nicht</mark> <em>in-place</em> vergr&#xF6;&#xDF;ert werden\nkann.</p>\n"},{"option":"<p>Bei indizierter Speicherung <mark>kann</mark> es prinzipbedingt\n<mark>nicht</mark> zu Verschnitt kommen.</p>\n","correct":false,"comment":"<p>Nein, hier ist einer Datei eine bestimmte Anzahl an Bl&#xF6;cken\nzugeordnet. Ist die Datei kleiner als diese Bl&#xF6;cke, so liegt Verschnitt\nvor.</p>\n"},{"comment":"<p>Ja, das ist m&#xF6;glich.</p>\n","option":"<p>Bei verketteter Speicherung mittels FAT-Ansatz <mark>kann</mark> die\nVerkettungsinformation redundant gespeichert werden, um die\nFehleranf&#xE4;lligkeit zu reduzieren.</p>\n","correct":true},{"comment":"<p>Nein, das w&#xE4;re bei sequentieller Speicherung der Fall. Die Bl&#xF6;cke\neiner Datei bei indizierter Speicherung liegen <mark>nicht</mark>\nnotwendigerweise nah beieinander.</p>\n","option":"<p>Im Vergleich zu den anderen Verfahren ist bei indizierter Speicherung\ndie Positionierzeit des Festplatten-Armes beim Zugriff auf\n<mark>alle</mark> Datenbl&#xF6;cke einer Datei minimal.</p>\n","correct":false},{"comment":"<p>Ja, RAID 1 verteilt die Daten redundant &#xFC;ber zwei oder mehr Platten.\nF&#xE4;llt eine Platte aus, so gibt es noch mindestens eine Kopie.</p>\n","option":"<p>Beim Einsatz von RAID 1 <mark>kann</mark> eine der beteiligten\nPlatten ausfallen, ohne dass das Gesamtsystem ausf&#xE4;llt.</p>\n","correct":true},{"comment":"<p>Nein, RAID 0 verteilt die Daten per <em>striping</em>\n<mark>nicht</mark> redundant auf die Platten, sondern erzielt nur einen\nGeschwindigkeitsvorteil, dadurch dass auf mehrere Platten gleichzeitig\ngeschrieben oder von mehreren Platten gleichzeitig gelesen werden\nkann.</p>\n","option":"<p>Beim Einsatz von RAID 0 <mark>kann</mark> eine der beteiligten\nPlatten ausfallen, ohne dass das Gesamtsystem ausf&#xE4;llt.</p>\n","correct":false},{"correct":true,"option":"<p>Journaling-Dateisysteme garantieren, dass auch nach einem\nSystemausfall <mark>alle</mark> Metadaten wieder in einen konsistenten\nZustand gebracht werden k&#xF6;nnen.</p>\n","comment":"<p>Ja, auch die Transaktionalit&#xE4;t der &#xC4;nderung von Metadaten wird\ndadurch erzielt, dass Beginn und Fertigstellung aller &#xC4;nderungen am\nDateisystem in einem Journal aufgezeichnet werden, das beim Hochfahren\nauf Vollst&#xE4;ndigkeit aller Transaktionen &#xFC;berpr&#xFC;ft wird.</p>\n"},{"option":"<p>Festplatten eignen sich besser f&#xFC;r sequentielle als f&#xFC;r wahlfreie\nZugriffsmuster.</p>\n","correct":true,"comment":"<p>Ja, bei Festplatten (<em>HDD</em>s) <mark>muss</mark> auf\nphysikalischer Ebene der Lese-/Schreibarm sich an der Stelle befinden,\nan der die gew&#xFC;nschten Daten auf der Magnetscheibe stehen. Bei\nwahlfreiem Zugriff <mark>muss</mark> dieser zwischen den\n<mark>nicht</mark> beieinanderliegenden Sektoren bewegt werden, bei\nsequentiellem Zugriff <mark>kann</mark> entlang der Spur gelesen\nwerden.</p>\n"}],"multiple":true,"id":"Hk1RYYW3JiMnS+DqNCmYvg","source":"2017-02"},{"question":"<p>Welche der folgenden Aussagen zur Einplanung von Prozessen sind\nrichtig?</p>\n","options":[{"correct":true,"option":"<p>Bei kooperativer Einplanung <mark>kann</mark> es zur Monopolisierung\nder CPU kommen</p>\n","comment":"<p>Ja, bei kooperativer Einplanung <mark>muss</mark> das Programm per\nSystemaufruf die Ressource CPU abgeben. Ein unkooperatives Programm\n<mark>kann</mark> dies unterlassen, und die CPU monopolisieren.</p>\n"},{"comment":"<p>Nein, der Konvoieffekt existiert auch hier, da die Vergabe der\nZeitscheiben reihum wie bei <em>FCFS</em> funktioniert. Prozesse mit\nlangen Rechenst&#xF6;&#xDF;en nutzen hier ihre Zeitscheibe voll aus, w&#xE4;hrend\nE/A-intensive Prozesse benachteiligt sind.</p>\n","correct":false,"option":"<p>Bei der Verwendung des Round-Robin-Verfahrens <mark>kann</mark> der\nKonvoi-Effekt <mark>nicht</mark> auftreten.</p>\n"},{"correct":true,"option":"<p>Der Einsatz des <em>FCFS</em>-Verfahrens setzt kooperative Prozesse\nvoraus.</p>\n","comment":"<p>Ja, <em>FCFS</em> ist ein kooperatives Einplanungsverfahren. Ein\nunkooperativer Prozess k&#xF6;nnte hier die CPU monopolisieren.</p>\n"},{"comment":"<p>Nein, probabilistische Einplanungsverfahren arbeiten mit\nAbsch&#xE4;tzungen der ben&#xF6;tigten Sto&#xDF;l&#xE4;ngen.</p>\n","option":"<p>Die Verwendung probabilistischer Einplanungsverfahren ist nur\nm&#xF6;glich, wenn dem Planer <mark>alle</mark> Prozesse und ihre\nCPU-Sto&#xDF;l&#xE4;ngen im Voraus bekannt sind.</p>\n","correct":false},{"comment":"<p>Ja. Man betrachte z. B. den Fall CPU + GPU. Ein Prozess, der auf der\nCPU rechnen m&#xF6;chte, <mark>kann</mark> <mark>nicht</mark> unbedingt auch\nauf der GPU rechnen. Deswegen ist der Einsatz einer Bereitliste f&#xFC;r\n<mark>alle</mark> Rechenkerne (symmetrisches Planungsverfahren) hier\nunm&#xF6;glich. Stattdessen m&#xFC;ssen zumindest f&#xFC;r GPU und CPU separate\nBereitlisten existieren. Dies zeichnet asymmetrische Planungsverfahren\naus.</p>\n","correct":true,"option":"<p>In einem asymmetrischen Multiprozessorsystem ist der Einsatz\nasymmetrischer Einplanungsverfahren obligatorisch.</p>\n"},{"correct":false,"option":"<p>Statische (off-line) Einplanungsverfahren sind besonders f&#xFC;r den\nEinsatz in interaktiven Systemen geeignet.</p>\n","comment":"<p>Nein. <em>offline</em> Algorithmen sind <mark>alle</mark>\nEingabedaten wie z. B. die zu planenden Prozesse im Voraus bekannt.\nDamit sind sie f&#xFC;r interaktiven Betrieb ungeeignet, da dort zur Laufzeit\nvorher unbekannte Anforderungen auftreten.</p>\n"},{"comment":"<p>Nein. Bei <em>VRR</em> werden Prozesse, die eine Ein- oder Ausgabe\nbeenden, bevorzugt eingeplant. Bei Ende einer Zeitscheibe werden dann\nzuerst die Prozesse auf der Vorzugsliste eingelastet.</p>\n","correct":false,"option":"<p>Virtual-Round-Robin benachteiligt E/A-intensive Prozesse zu Gunsten\nvon rechenintensiven Prozessen.</p>\n"},{"option":"<p>Beim Einsatz des multilevel-queue-Verfahrens (MLQ) werden die\nProzesse nach ihrem Typ in separate Bereitlisten aufgeteilt, die jeweils\neine eigene lokale Einplanungsstrategie verwenden.</p>\n","correct":true,"comment":"<p>Ja, bei diesem Verfahren werden mehrere Bereitlisten f&#xFC;r\nunterschiedliche Arten von Prozessen (z. B. System-, Dialog- und\nStapelprozesse) verwendet. Jede dieser Listen verwendet eine lokale\nEinplanungsstrategie. (Um zwischen den Listen zu wechseln wird\nzus&#xE4;tzlich eine globale Strategie verwendet).</p>\n"}],"multiple":true,"source":"2017-02","id":"inluhtKziUq/HrsK7GPagQ"},{"multiple":false,"question":"<p>Welche Aussage &#xFC;ber Funktionen der <code>exec()</code>-Familie ist\nrichtig?</p>\n","options":[{"correct":false,"comment":"<p>Nein, bei <code>exec</code> wird ein Programm innerhalb von einem\nProzess ersetzt. Die Funktion kehrt nur im Fehlerfall zur&#xFC;ck, und\nkommuniziert nichts direkt an den Vater-Prozess.</p>\n","option":"<p>Dem Vater-Prozess wird die Prozess-ID des Kind-Prozesses\nzur&#xFC;ckgeliefert.</p>\n"},{"comment":"<p>Nein, weil <code>exec</code> Funktionen <mark>keine</mark>\nFunktionszeiger nehmen, sondern ein Verweis auf eine Datei, in welchem\ndas auszuf&#xFC;hrende Programm drin steht.</p>\n","option":"<p>Der an <code>exec()</code> &#xFC;bergebene Funktionszeiger wird durch\neinen neuen Thread im aktuellen Prozess ausgef&#xFC;hrt.</p>\n","correct":false},{"option":"<p>Falls kein Fehler auftritt, kehrt der Aufruf von <code>exec()</code>\n<mark>nicht</mark> zur&#xFC;ck</p>\n","comment":"<p>Ja, weil dann das alte Programm im Prozess ersetzt wurde, und\n<mark>nicht</mark> mehr weiter laufen k&#xF6;nnte.</p>\n","correct":true},{"comment":"<p>Nein, weil <code>exec</code> <mark>keine</mark> neuen Prozesse\nerstellt.</p>\n","option":"<p><code>exec()</code> erzeugt einen neuen Kind-Prozess und startet\ndarin das angegebene Programm.</p>\n","correct":false}],"id":"kV8o7BtYzeMkoEr1PqMwog","source":"2018-07"},{"source":"2018-07","id":"h6viH9vSidFV4qZAKAWWFg","question":"<p>Welche Aussage &#xFC;ber den R&#xFC;ckgabewert von <code>fork()</code> ist\nrichtig?</p>\n","options":[{"correct":true,"option":"<p>Dem Vater-Prozess wird die Prozess-ID des Kind-Prozesses\nzur&#xFC;ckgeliefert.</p>\n"},{"option":"<p>Der Kind-Prozess bekommt die Prozess-ID des Vater-Prozesses.</p>\n","comment":"<p>Nein, es bekommt den festen Wert 0; der Eltern-Prozess\n<mark>kann</mark> mit <code>getppid</code> (eindeutig) bestimmt\nwerden.</p>\n","correct":false},{"comment":"<p>Nein, im Fehlerfall (d.h. es konnte kein Kind erstellt werden)\nbekommt der Eltern-Prozess eine Fehler mit.</p>\n","option":"<p>Im Fehlerfall wird im Kind-Prozess -1 zur&#xFC;ckgeliefert.</p>\n","correct":false},{"comment":"<p>Nein, Kind bekommt 0, damit es wei&#xDF; es ist das Kind und Vater bekommt\ndie PID vom Kind.</p>\n","option":"<p>Der R&#xFC;ckgabewert ist in <mark>jedem</mark> Prozess (Kind und Vater)\njeweils die eigene Prozess-ID.</p>\n","correct":false}],"multiple":false},{"source":"2018-07","multiple":false,"options":[{"correct":false,"comment":"<p>Nein, weil ein aktuelles Verzeichnis wird einem Prozess\nzugeordnet.</p>\n","option":"<p>Jedem UNIX-Benutzer ist zu jeder Zeit ein aktuelles Verzeichnis\nzugeordnet.</p>\n"},{"option":"<p>Pfadnamen, die <mark>nicht</mark> mit dem Zeichen <code>/</code>\nbeginnen, werden relativ zu dem aktuellen Arbeitsverzeichnis\ninterpretiert.</p>\n","correct":true},{"correct":false,"option":"<p>Mit dem Systemaufruf <code>chdir()</code> <mark>kann</mark> das\naktuelle Arbeitsverzeichnis eines Prozesses durch seinen Vaterprozess\nver&#xE4;ndert werden.</p>\n","comment":"<p>Nein, das &#xE4;ndert den CWD von dem aufrufendem Prozess.</p>\n"},{"correct":false,"option":"<p>Besitzt ein UNIX-Prozess kein Current Working Directory, so beendet\nsich der Prozess mit einem Segmentation Fault.</p>\n"}],"question":"<p>Welche Aussage &#xFC;ber das aktuelle Arbeitsverzeichnis (Current Working\nDirectory) trifft zu?</p>\n","id":"5EO4HQ5jQrP10pk8i9il7g"},{"source":"2018-07","multiple":false,"question":"<p>Welche der folgenden Aussagen zum Thema Threads ist richtig?</p>\n","options":[{"correct":true,"option":"<p>Bei User-Threads ist die Scheduling-Strategie <mark>nicht</mark>\ndurch das Betriebssystem vorgegeben.</p>\n","comment":"<p>Ja, weil das Scheduling innerhalb vom Prozess stattfindet, und damit\nunabh&#xE4;ngig vom Betriebsystem ist.</p>\n"},{"option":"<p>Kernel-Threads k&#xF6;nnen Multiprozessoren <mark>nicht</mark>\nausnutzen.</p>\n","comment":"<p>Doch, weil das Betriebsystem diese kennt und in der Lage ist diese\nauf verschiedene Kerne einzulagern.</p>\n","correct":false},{"option":"<p>Die Umschaltung von User-Threads ist eine privilegierte Operation und\n<mark>muss</mark> deshalb im Systemkern erfolgen.</p>\n","comment":"<p>Nein, weil dieses Umschalten <mark>keine</mark> privilegierte\nOperation ist.</p>\n","correct":false},{"correct":false,"option":"<p>Zu <mark>jedem</mark> Kernel-Thread geh&#xF6;rt ein eigener, gesch&#xFC;tzter\nAdressraum.</p>\n","comment":"<p>Nein, ein Kernel-Thread <mark>kann</mark> auch den gleichen\nSpeicherraum mit anderen Threads teilen (bspw. im Kontext von echtem\nMulti-Threading, siehe Pthread).</p>\n"}],"id":"Q/K7Ht0hGEhW5uUV31B/iw"},{"source":"2012-02","id":"2yAjmn0UMm3n8NX4XuXWJA","options":[{"option":"<p>Ein Zugriff &#xFC;ber den zur&#xFC;ckgelieferten Zeiger liefert v&#xF6;llig\nzuf&#xE4;llige Ergebnisse oder einen Segmentation fault.</p>\n","comment":"<p>Nein, die Idee von diesem <code>stat</code> w&#xE4;re, dass anstatt selbst\nden Speicher bereitzustellen, das Betriebsystem oder die Libc daf&#xFC;r\nsorgen m&#xFC;sste den Speicherbereitzustellen. Das Problem dabei ist, dass\nSysteme hierf&#xFC;r pro Prozess nur einemal den Speicher statisch\nallozieren, und dann zwischen Aufrufen geteilt werden kann. Mehrere\nAufrufe der Funktion &#xFC;berschrieben also alte Werte. Jedenfalls ist es\nm&#xF6;glich und notwendig auf den Speicher zuzugreifen, und der Inhalt\nsollte <em>bis zu dem n&#xE4;chstem Aufruf</em> von diesem <code>stat</code>\ng&#xFC;ltig bleiben, damit auch der Inhalt definiert.</p>\n","correct":false},{"option":"<p>Der Systemaufruf liefert einen Zeiger zur&#xFC;ck, &#xFC;ber den die aufrufende\nFunktion direkt auf eine Datenstruktur zugreifen kann, welche die\nDateiattribute enth&#xE4;lt.</p>\n","comment":"<p>Ja, anstatt selbst den Speicher bereitzustellen, wie die die\ngew&#xF6;hnliche Signatur von <code>stat</code> es andeutet:</p>\n<pre><code>  int stat(char *pathname, struct stat *statbuf);</code></pre>\n<p>w&#xFC;rde diese Implementierung den Speicher selbst bereitstellen m&#xFC;ssen.\nIn diesem Speicher w&#xE4;ren dann die Informationen nach dem bekannten\n<code>struct stat</code> Typen einsehbar.</p>\n","correct":true},{"option":"<p>Solch eine Schnittstelle ist <mark>nicht</mark> sch&#xF6;n, da dadurch die\naufrufende Funktion auf internen Speicher des Betriebssystems zugreifen\nk&#xF6;nnte.</p>\n","comment":"<p>Es ist schwer eine &#xE4;sthetische Frage mit <q>ja</q> oder <q>nein</q>\nzu beantworten. Grunds&#xE4;tzlich stimmt die Aussage, dass es m&#xF6;glich w&#xE4;re\nauf den internen Speicher des Betriebsystems zuzugreifen, wenn es so\nimplementiert werden w&#xFC;rde, und das Betriebsystem den Speicherschutz\nentsprechend einrichten w&#xFC;rde. F&#xFC;r gew&#xF6;hnlich (oder zumindest wie es in\nder Regel <code>readdir(3)</code> umgesetzt wird), sollte der Speicher\nf&#xFC;r den <code>struct stat</code> R&#xFC;ckgabewert im Prozess selbst\ngespeichert sein, und <mark>nicht</mark> im Betriebsystemkern.</p>\n","correct":null},{"correct":false,"comment":"<p>Nein, <code>readdir</code> verspricht <mark>nicht</mark> den Speicher\ndynamisch auf der Halde anzulegen, <em>darf</em> daher auch\n<mark>nicht</mark> mit <code>free(3)</code> aufger&#xE4;umt werden.</p>\n","option":"<p>Der Aufrufer <mark>muss</mark> sicherstellen, dass er den\nzur&#xFC;ckgelieferten Speicher mit <code>free(3)</code> wieder freigibt,\nwenn er die Dateiattribute <mark>nicht</mark> mehr weiter ben&#xF6;tigt.</p>\n"}],"question":"<p>Nehmen Sie an, der Ihnen bekannte Systemaufruf <code>stat(2)</code>\nw&#xE4;re analog zu der Funktion <code>readdir(3)</code> mit folgender\nSchnittstelle implementiert:</p>\n<pre><code> struct stat *stat(const char *path);</code></pre>\n<p>Welche Aussage ist richtig?</p>\n","multiple":false},{"multiple":false,"question":"<p>In einem UNIX-UFS-Dateisystem gibt es symbolische Namen/Verweise\n(Symbolic Links). Welche Aussage ist richtig?</p>\n","id":"1KVoNDMiHzUOntQ4TypbCA","options":[{"option":"<p>Der Systemaufruf <code>stat()</code> liefert im Gegensatz zum\nSystemaufruf <code>lstat()</code> die Dateiattribute des symbolischen\nVerweises und <mark>nicht</mark> die Attribute vom Ziel des\nVerweises.</p>\n","comment":"<p>Nein, in dieser Antwort wurden die beiden Systemaufrufe vertauscht.\n<code>stat(2)</code> l&#xF6;st die Verweise auf, w&#xE4;hrend\n<code>lstat(2)</code> sich <q>bewusst</q> ist, ob eine Datei ein Verweis\nist oder nicht, und sich weigert Verweisen zu folgen.</p>\n<p>Der Grund f&#xFC;r diese Unterscheidung versteht man am besten mit dem\nhistorischem Kontext. Obwohl MULTICS, der vorg&#xE4;nger von UNIX&#x2122; bereits <a\nhref=\"https://multicians.org/features.html#tag11\">symbolische Verweise\nunterst&#xFC;tzt hat</a>, wurden diese in Unix <mark>nicht</mark>\nnachimplementiert, um das System einfacher zu halten. Es gab daher auch\n<mark>keine</mark> Unterschiedung, welche den Namen <q>Hard Link</q>\nnotwendig gemacht h&#xE4;tte. Mit BSD 4.1 wurden auf Unix-Artigen Systemen\n<q>Symbolic Links</q> implementiert (d.h. der Systemaufruf\n<code>symlink</code> wurde hinzugef&#xFC;gt), damit aber diese sich gut in\ndas bestehende System integrieren, wurden Symlinks bei allen bis dahin\nbestehenden Anwendungen <em>automatisch</em> aufgel&#xF6;st, und dann nur bei\n<q>out out</q> Systemaufrufen wie eben <code>lstat</code> gesondert\nbehandelt, wo es eben notwendig war (bspw. bei <code>find</code>, wo\nSymbolische Verweise den Datei-Baum zu einem allgemeinem Digraphen\ndegenerieren lassen kann, und damit Tiefensucht <mark>nicht</mark>\nzwingend erfolgreich terminieren muss).</p>\n","correct":false},{"comment":"<p>Nein, ein symbolischer Verweise <mark>kann</mark> einen belibigen\nPfad enthalten, egal ob die Refernz dabei wirklich existiert, auf dem\ngleichem System liegt, welchen Typ die Datei hat (inklusive andere oder\nsogar der gleiche Verweis!) oder sich in der Zwischenzeit ge&#xE4;ndert\nhat.</p>\n","option":"<p>Ein symbolischer Verweis <mark>kann</mark> ausschlie&#xDF;lich auf\nregul&#xE4;re Dateien verweisen.</p>\n","correct":false},{"option":"<p>Beim Zugriff auf einen Symbolic Link <mark>kann</mark> ein <q>No such\n&#xFB01;le or directory.</q>-Fehler auftreten (<code>errno==ENOENT</code>),\nobwohl der Symbolic Link existiert.</p>\n","comment":"<p>Ja, wenn der Symbolischer Verweis auf ein Verzeichnis beziehen\nsollte, aber dieses Verzeichnis <mark>nicht</mark> existiert, wird das\nBetriebsystem dann <q>transparent</q> den Verweis aufl&#xF6;sen, und dann\nFestestellen, dass es das Verziechnis <mark>nicht</mark> gibt. Hier ein\nBeispiel:</p>\n<pre><code>  $ ln -s /this/directory/does/not/exist ~/link\n  $ ls -ld ~/link\n  lrwxrwxrwx 1 philip philip 13 Feb 18 12:53 link -&gt; /this/directory/does/not/exist\n  $ ls ~/link\n  ls: cannot access &#39;link&#39;: No such file or directory</code></pre>\n<p>wo <q>No such file or directory</q> die englische Fehlermeldung f&#xFC;r\nden Fehlercode <code>ENOENT</code> ist.</p>\n","correct":true},{"option":"<p>In <mark>jedem</mark> Inode ist ein Referenzz&#xE4;hler gespeichert,\nwelcher die Anzahl der Symbolic Links angibt, die auf ihn verweisen.</p>\n","comment":"<p>Nein, der <q>nlink</q> Z&#xE4;hler betrifft die Anzahl der <em>Hard\nLinks</em> auf eine Datei. Es wird protokoliert, damit das Dateisystem\nwissen <mark>kann</mark> ob der Speicher f&#xFC;r die Datei von der\nFestplatte gel&#xF6;scht werden kann. In diesem Sinne &#xE4;hnelt es dem Ansatz\nvon <a href=\"https://en.wikipedia.org/wiki/Reference_counting\">Reference\nCountin</a> den Hochsprache f&#xFC;r die Automatische Speicherbereinung\neinsetzen.</p>\n","correct":false}],"source":"2012-02"},{"question":"<p>Sie kennen den Begriff Seiten&#xFB02;attern (Thrashing). Welche Aussage ist\nrichtig?</p>\n","multiple":false,"id":"nAt3w+JS10fjYrC8X6WVWw","source":"2012-02","options":[{"comment":"<p>Nein, das ist ein anderes Problem, welches durch den Kontext-Wechsel\n(egal ob zwischen Benutzer-Prozessen oder zwischen User-Space und\nKernel-Space) die Beschleunigung des TLBs verliert.</p>\n","option":"<p>Als Seiten&#xFB02;attern bezeichnet man das wiederholte L&#xF6;schen und Neuladen\ndes Translation-Look-Aside-Buffer (TLB), ausgel&#xF6;st durch h&#xE4;u&#xFB01;gen\nProzesswechsel.</p>\n","correct":false},{"option":"<p>Als Seiten&#xFB02;attern bezeichnet man das wiederholte Einlagern einer erst\nvor kurzem verdr&#xE4;ngten Speicherseite. Die Prozesse verbringen als Folge\ndie meiste Zeit mit dem Warten auf die Behebung von Seitenfehlern.</p>\n","comment":"<p>Ja, es handelt sich hierbei um ein Problem in der\nAuslagerungsstrategie der Speicherverwaltung. Es trifft sozusagen die\n<q>Resonanzfrequenz</q>, und verlangsamt Speicherzugriffe welche bei\neiner anderen Strategie keien Zugriffe auf externen Speicher ben&#xF6;tigen\nm&#xFC;ssten.</p>\n","correct":true},{"comment":"<p>Nein, Seitenflattern hat h&#xF6;rt man nicht, und es <mark>kann</mark>\nauch auf Thin-Client auftreten, insofern diese die m&#xF6;glichkeit haben\nSeiten ein- und auszulagern.</p>\n","option":"<p>Seiten&#xFB02;attern erkennt man an der starken Ger&#xE4;uschentwicklung der\nFestplatte, da auf Grund h&#xE4;u&#xFB01;ger Seitenzugriffe der Lesekopf st&#xE4;ndig neu\npositioniert wird. Bei Systemen ohne Festplatte (z. B. Thin-Clients)\n<mark>kann</mark> das Seiten&#xFB02;attern <mark>nicht</mark> auftreten.</p>\n","correct":false},{"correct":false,"comment":"<p>Doch, bspw. im Extreemfall von nur drei Seiten, wo nur zwei\neingelagert sein k&#xF6;nnten. W&#xFC;rden diese zyklisch angesprochen werden (1,\n2, 3, 1, 2, 3, &#x2026;), w&#xFC;rde <mark>immer</mark> die Seite auf die als\nn&#xE4;chstes zugegriffen wird ausgelagert werden.</p>\n","option":"<p>Bei Verwendung der LRU-Seitenersetzungstrategie <mark>kann</mark>\nSeiten&#xFB02;attern prinzipbedingt <mark>nicht</mark> auftreten.</p>\n"}]},{"id":"cgzb6hIZj5YAeljuoStubA","source":"2012-02","options":[{"option":"<p>Der zu verwaltende Speicher wird in Speichereinheiten\nunterschiedlicher Gr&#xF6;&#xDF;e unterteilt.</p>\n","comment":"<p>Nein, einer Bitliste (oder <em>Bitkarte</em>) werden <q>Hohlr&#xE4;ume\nfester Gr&#xF6;&#xDF;e</q> gespeichert, wobei <mark>jedes</mark> Bit die Belegung\neines solchen Holraums designiert.</p>\n","correct":false},{"option":"<p>Zur Suche nach freiem Speicher <mark>kann</mark> es n&#xF6;tig sein, die\ngesamte Bitliste zu durchsuchen.</p>\n","comment":"<p>Ja, insofern <mark>keine</mark> zus&#xE4;tzlichen Hillfsstrukturen wie ein\n<q>zuletzt freigegeben</q> index verwaltet wird, ist es unter umst&#xE4;nden\nnotwendig die gesammte Bitliste abzusuchen, um ein Speicherinterval der\npasenden Gr&#xF6;&#xDF;e zu finden.</p>\n","correct":true},{"correct":false,"option":"<p>Das Zusammenfassen von benachbarten freien Speichereinheiten ist\nbesonders aufw&#xE4;ndig.</p>\n","comment":"<p>Nein, es ist <mark>keine</mark> gesonderte Zusammenfassung notwendig,\nweil die Verwaltungsstrukturen au&#xDF;erhalb des verwalteten Speichers\nliegen. Damit benachbarte Speicherintervalle zusamengefasst werden\nk&#xF6;nnen bei der Vergabe des Speichers, m&#xFC;ssen diese nur <mark>alle</mark>\nunbelegt gewesen sein.</p>\n"},{"comment":"<p>Nein, granularit&#xE4;t ist inverse proportional zur L&#xE4;nge der Bitliste.\nJe feinere Granularit&#xE4;t, d.h. mit <mark>jedem</mark> Bit wird auf\nweniger Speicher verweisen, ben&#xF6;tigt eine <em>l&#xE4;ngere</em> Bitliste,\ndamit der gleiche Speicher-Interval abgedeckt werden kann.</p>\n","option":"<p>Je feiner die Granularit&#xE4;t der Speichereinheiten ist, desto k&#xFC;rzer\nist die Bitliste.</p>\n","correct":false}],"multiple":false,"question":"<p>Welche Aussage bez&#xFC;glich der Freispeicherverwaltung mittels einer\nBitliste ist richtig?</p>\n"},{"id":"40VJUt4a6+s+kTC16Vc2qw","options":[{"correct":false,"option":"<p>Der Aufruf von <code>listen()</code> wartet solange an einem Socket,\nbis eine einkommende Verbindungsanfrage vorliegt.</p>\n","comment":"<p>Nein, das w&#xE4;re der (blokierende) Systemaufruf\n<code>accept()</code>.</p>\n"},{"correct":false,"comment":"<p>Nein, mit <code>listen()</code> <mark>kann</mark> man\n<mark>nicht</mark> allgemeine Daten speichern.</p>\n","option":"<p>Der Aufruf von <code>listen()</code> erzeugt eine leere verkettete\nListe, die zum Speichern von Daten verwendet werden kann.</p>\n"},{"comment":"<p>Ja, der <code>backlog</code> Parameter gibt an, wie viele\nVerbindungen schon mal <q>vorbehandelt</q> werden sollen, bis diese von\n<code>accept</code> im Benutzerprogramm ein gesonderter Datei-Deskriptor\nvergeben wird. Au&#xDF;erdem versetzt der <code>listen()</code> Systemaufruf\neinen TCP socket in den <q>Server Modus</q>.</p>\n","option":"<p>Mit <code>listen()</code> wird ein Socket f&#xFC;r die Verbindungsannnahme\nvorbereitet. Ein Parameter gibt an, wieviele Verbindungsanfragen vor\nderen Annahme gepuffert werden k&#xF6;nnen.</p>\n","correct":true},{"option":"<p>Mit <code>listen()</code> wird ein Socket f&#xFC;r die Verbindungsannahme\nvorbereitet. Ein Parameter gibt an, wieviele laufende Verbindungen\nmaximal m&#xF6;glich sind.</p>\n","comment":"<p>Nein, der <code>backlog</code> Parameter beschr&#xE4;nkt\n<mark>nicht</mark> wie viele Verbindungen m&#xF6;glich sind, weil (zumindest\nf&#xFC;r TCP, wo <code>listen</code> relevant ist) neue Verbidnungen\nunabh&#xE4;ngig vom Listen-Socket auf anderen Ports kommunizieren.</p>\n","correct":false}],"source":"2012-02","multiple":false,"question":"<p>F&#xFC;r welchen Zweck wird der Systemaufruf <code>listen()</code>\nbenutzt?</p>\n"},{"question":"<p>Wozu dient die CAS (Compare-And-Swap) Instruktion?</p>\n","options":[{"option":"<p>Zur Realisierung einer effizienten Verdr&#xE4;ngungssteuerung bei\neinseitiger Synchronisation.</p>\n","comment":"<p>Nein. Dies wird je nach Art der einseitigen Synchronisation (z. B.\nBlockieren der Signalbehandlung) unterschiedlich, jedoch\n<mark>nicht</mark> mit CAS, gel&#xF6;st.</p>\n","correct":false},{"correct":false,"comment":"<p>Nein, f&#xFC;r die Implementation dessen ist das Betriebssystem\nzust&#xE4;ndig.</p>\n","option":"<p>Um in einem System mit Seitennummerierung (Paging) Speicherseiten in\ndie Auslagerungspartition (swap area) schreiben zu k&#xF6;nnen.</p>\n"},{"option":"<p>Um auf einem Multiprozessorsystem einfache Modifikationen an\nVariablen ohne Sperren implementieren zu k&#xF6;nnen.</p>\n","comment":"<p>Ja, die CAS-Instruktion erlaubt, eine Variable transaktional nur dann\nauf einen neuen Wert zu setzen, wenn sie <mark>nicht</mark> anderweitig\nmodifiziert wurde. Mittels einer CAS-Schleife <mark>kann</mark> somit\nder Wert einer Variable atomar ohne gegenseitigen Ausschluss ge&#xE4;ndert\nwerden.</p>\n","correct":true},{"correct":false,"option":"<p>Um bei der Implementierung von Schlossvariablen (Locks) aktives\nWarten zu vermeiden.</p>\n","comment":"<p>Nein, allein mit einer atomaren Variable <em>locks</em> zu\nimplementieren, setzt aktives Warten auf die &#xC4;nderung des Wertes voraus.\nStattdessen m&#xFC;sste f&#xFC;r passives Warten der wartende Prozess in den\nZustand blockiert &#xFC;bergehen, bis er von einem anderen Prozess\n<q>geweckt</q> wird. Hierf&#xFC;r ist Betriebssystemunterst&#xFC;tzung in Form\neines Schedulers n&#xF6;tig.</p>\n"}],"multiple":false,"id":"RxwrW6r8VKoe/0w0SwTNvg","source":"2020-02"},{"source":"2020-02","id":"V5WfvKe+ZzbYdu9452IYaw","multiple":false,"question":"<p>Was versteht man unter RAID 0?</p>\n","options":[{"correct":false,"option":"<p>Ein auf Flash-Speicher basierendes, extrem schnelles\nSpeicherverfahren.</p>\n","comment":"<p>Nein, RAID 0 und andere RAID <em>level</em> bezeichnen, wie Daten auf\nmehrere Speichermedien (ein <em>redundant array of independent\ndisks</em>) aufgeteilt werden und nicht, wie der Speicher auf der\nphysikalischen Ebene implementiert ist.</p>\n"},{"correct":false,"option":"<p>Auf Platte 0 wird Parity-Information der Datenbl&#xF6;cke der Platten 1 -\n4 gespeichert.</p>\n","comment":"<p>Nein, RAID 0 sorgt <mark>nicht</mark> f&#xFC;r Redundanz, sondern dient\nnur zur Beschleunigung von Speicherzugriffen. Es werden\n<mark>keine</mark> Parit&#xE4;tsdaten angelegt.</p>\n"},{"correct":true,"comment":"<p>Ja, ein Begriff hierf&#xFC;r lautet <em>striping</em></p>\n","option":"<p>Datenbl&#xF6;cke eines Dateisystems werden &#xFC;ber mehrere Platten verteilt\ngespeichert.</p>\n"},{"correct":false,"comment":"<p>Nein, RAID 0 sorgt <mark>nicht</mark> f&#xFC;r Redundanz, sondern dient\nnur zur Beschleunigung von Speicherzugriffen. Es werden\n<mark>keine</mark> Replikate von Datenbl&#xF6;cken angelegt.</p>\n","option":"<p>Datenbl&#xF6;cke werden &#xFC;ber mehrere Platten verteilt und repliziert\ngespeichert.</p>\n"}]},{"options":[{"option":"<p>Virtuelle Adressr&#xE4;ume sind Voraussetzung f&#xFC;r die Realisierung\nlogischer Adressr&#xE4;ume.</p>\n","comment":"<p>Nein, andersherum. Ein logischer Adressraum ist ein zusammenh&#xE4;ngender\nAdressbereich. Der virtuelle Adressbereich setzt auf diesen auf, indem\nAdressen, die <mark>nicht</mark> auf den Speicher abgebildet werden\nk&#xF6;nnen, beim Zugriff einen Adress&#xFC;bersetzungsfehler ausl&#xF6;sen. Die\nZuordnung vom logischen zum realen Adressraum <mark>kann</mark> somit\nals totale Funktion betrachtet werden, im Gegensatz dazu\n<mark>kann</mark> die Zuordnung vom virtuellen zum realen Adressraum als\npartielle Funktion auf den logischen Adressen betrachtet werden (vgl.\nSP1 B Vl. 2 S. 12 ff., 27).</p>\n","correct":false},{"option":"<p>Der virtuelle Adressraum <mark>kann</mark> <mark>nie</mark> gr&#xF6;&#xDF;er\nsein als der im Rechner vorhandene Hauptspeicher.</p>\n","comment":"<p>Nein, durch Speichervirtualisierung k&#xF6;nnen Seiten auf den\nHintergrundspeicher ausgelagert werden (<em>swapping</em>).</p>\n","correct":false},{"option":"<p>Die maximale Gr&#xF6;&#xDF;e des virtuellen Adressraums <mark>kann</mark>\nunabh&#xE4;ngig von der verwendeten Hardware frei gew&#xE4;hlt werden.</p>\n","comment":"<p>Nein, z. B. ist diese auf einem 32-Bit-System in der Regel auf\nh&#xF6;chstens 2&#xB3;&#xB2; Datenw&#xF6;rter beschr&#xE4;nkt (In der Praxis also nur 4 GiB).</p>\n","correct":false},{"correct":true,"option":"<p>Der physikalische Adressraum ist durch die gegebene\nHardwarekonfiguration definiert.</p>\n","comment":"<p>Ja, <mark>jede</mark> physikalische Adresse korrespondiert zu einer\ntats&#xE4;chlichen Stelle im Hauptspeicher, von dem eine bestimmte Menge in\neinem System verbaut ist.</p>\n"}],"question":"<p>Welche der folgenden Aussagen zum Thema Adressr&#xE4;ume ist richtig?</p>\n","multiple":false,"id":"rOJZXb5WtBSvLWVlZwd4MQ","source":"2020-02"},{"multiple":false,"options":[{"correct":true,"comment":"<p>Ja. C ist <em>call-by-value</em>, da Funktionsparameter als Kopie und\n<mark>nicht</mark> als Referenz weitergegeben werden. Zeiger sind jedoch\nReferenzen auf Speicherstellen im Adressraum. Erh&#xE4;lt eine Funktion also\neinen Zeiger als Wert, so <mark>kann</mark> sie mit dem Ziel des Zeigers\nso verfahren, als h&#xE4;tte sie das Ziel selbst per Referenz erhalten.</p>\n","option":"<p>Zeiger k&#xF6;nnen verwendet werden, um in C eine call-by-reference\n&#xDC;bergabesemantik nachzubilden.</p>\n"},{"option":"<p>Zeiger vom Typ <code>void*</code> existieren in C nicht, da solche\nZeiger auf <q>Nichts</q> keinen sinnvollen Einsatzzweck h&#xE4;tten.</p>\n","comment":"<p>Nein, <em>void pointer</em> zeigen auf Daten mit unspezifiziertem\nTyp. Ein <code>void*</code> <mark>muss</mark> jedoch zuerst zu einem\nZeiger auf einen nicht-<code>void</code>-Wert gecastet werden, bevor er\ndereferenziert werden kann, oder Pointerarithmetik durgef&#xFC;hrt werden\nkann.</p>\n","correct":false},{"correct":false,"option":"<p>Ein Zeiger <mark>kann</mark> zur Manipulation von Daten in\nschreibgesch&#xFC;tzten Speicherbereichen verwendet werden.</p>\n","comment":"<p>Nein. Wird versucht, schreibend auf einen schreibgesch&#xFC;tzten Bereich\nzuzugreifen, so verhindert dies die MMU, unabh&#xE4;ngig davon, mit welchem\nProgrammierkonzept der Zugriff versucht wurde.</p>\n"},{"option":"<p>Die &#xDC;bergabesemantik f&#xFC;r Zeiger als Funktionsparameter ist\ncall-by-reference.</p>\n","comment":"<p>Nein, ein Zeiger wird <mark>immer</mark> noch als Wert an eine\nFunktion &#xFC;bergeben, d.&#xA0;h. es wird eine Kopie des Zeigers in das\nentsprechende Register oder auf den Stack abgelegt. Das ein Zeiger eine\nReferenz auf eine Speicherstelle <em>ist</em>, spielt hierbei\n<mark>keine</mark> Rolle. Beispiel: W&#xFC;rde die Aussage stimmen, so w&#xFC;rde\ndas folgende Programm <q>10</q> ausgeben. Es gibt jedoch <q>5</q>\naus.</p>\n<pre><code>static int b = 10;\n\nstatic void pointers_are_values_too(int* arg) {\n  arg = &amp;b; // arg zeigt hier auf b, ptr in main bleibt aber unver&#xE4;ndert.\n}\n\nint main(void) {\n  int a = 5;\n  int* ptr = &amp;a; // ptr zeigt auf a.\n  pointers_are_values_too(ptr);\n  printf(&quot;%d\\n&quot;, *ptr); // ptr zeigt immer noch auf a.\n}</code></pre>\n","correct":false}],"question":"<p>Welche Aussage zu Zeigern in C-Programmen ist richtig?</p>\n","id":"l6+cBY2awWCRbH8m2BafQg","source":"2020-02"},{"id":"QFvg9pGwOGVlEwhoBCbYwQ","source":"2020-02","multiple":false,"question":"<p>Welche Aussage zu Programmbibliotheken ist richtig?</p>\n","options":[{"comment":"<p>Nein, das w&#xE4;re bei einer dynamischen Bibliothek der Fall. Bei\nstatischen Binden wird bereits zur <em>link time</em> der Objektcode der\nBibliothek in das Programm kopiert.</p>\n","option":"<p>Eine statische Bibliothek, die in ein Programm eingebunden wurde,\n<mark>muss</mark> zum Ladezeitpunkt dieses Programms im Dateisystem\nvorhanden sein.</p>\n","correct":false},{"correct":false,"option":"<p>Beim Binden mit einer statischen Bibliothek werden in einem Programm\nnur Verweise auf verwendete Symbole der Bibliothek angelegt.</p>\n","comment":"<p>Nein, das w&#xE4;re bei einer dynamischen Bibliothek der Fall. Bei einer\nstatischen Bibliothek wird zun&#xE4;chst die gesamte Bibliothek in die\nausf&#xFC;hrbare Datei eingebunden.</p>\n"},{"comment":"<p>Ja, eine dynamische Bibliothek <mark>kann</mark> von mehreren\nProgrammen referenziert werden. Somit ist nur eine Kopie dieser auf dem\nSystem n&#xF6;tig. So <mark>kann</mark> Speicherplatz gespart werden.</p>\n","option":"<p>Programm-Module, die von mehreren Anwendungen gemeinsam genutzt\nwerden, k&#xF6;nnen in Form einer dynamischen Bibliothek zentral installiert\nwerden, um Speicherplatz zu sparen.</p>\n","correct":true},{"comment":"<p>Nein, bei statischen Bibliotheken wird der Objektcode zum\nBindezeitpunkt in das Zielprogramm kopiert. Soll dieser ge&#xE4;ndert werden,\nso <mark>muss</mark> das Programm neu gebunden werden. Es reicht\n<mark>nicht</mark> aus, nur die statische Bibliothek zu &#xE4;ndern, da das\nProgramm <mark>immer</mark> noch den urspr&#xFC;nglichen Objektcode\nenth&#xE4;lt.</p>\n","option":"<p>Eine &#xC4;nderung am Code einer statischen Bibliothek (z. B. Bugfixes)\nerfordert kein erneutes Binden der Programme, die diese Bibliothek\nbenutzen.</p>\n","correct":false}]},{"multiple":false,"question":"<p>Welche der folgenden Aussagen &#xFC;ber Einplanungsverfahren ist\nrichtig?</p>\n","options":[{"correct":false,"comment":"<p>Nein, das w&#xE4;re kooperative Einplanung. Bei pr&#xE4;emptiver Einplanung\n<mark>kann</mark> einem Prozess durch einen Timer-Interrupt die CPU\nentzogen werden (Pr&#xE4;emption).</p>\n","option":"<p>Beim Einsatz pr&#xE4;emptiver Einplanungsverfahren <mark>kann</mark>\nlaufenden Prozessen die CPU <mark>nicht</mark> entzogen werden.</p>\n"},{"correct":false,"option":"<p>Probabilistische Einplanungsverfahren m&#xFC;ssen die exakten\nCPU-Sto&#xDF;l&#xE4;ngen aller im System vorhandenen Prozesse kennen.</p>\n","comment":"<p>Nein, diese betrachten nur die ungef&#xE4;hren Sto&#xDF;l&#xE4;ngen.</p>\n"},{"correct":true,"comment":"<p>Ja, bei kooperativer Einplanung <mark>kann</mark> der laufende\nProzess erst gewechselt werden, wenn das Programm kooperativ ist und die\nCPU abgibt. Ein unkooperatives Programm <mark>kann</mark> dies\nunterlassen, und die CPU f&#xFC;r eine unbegrenzte Zeit in Anspruch\nnehmen.</p>\n","option":"<p>Bei kooperativer Einplanung <mark>kann</mark> es zur Monopolisierung\nder CPU kommen.</p>\n"},{"correct":false,"option":"<p>Asymmetrische Einplanungsverfahren k&#xF6;nnen ausschlie&#xDF;lich auf\nasymmetrischen Multiprozessor-Systemen zum Einsatz kommen.</p>\n","comment":"<p>Nein, asymmetrische Planung (eine Bereitliste pro Prozessor)\n<mark>muss</mark> zwar auf asymmetrischen Multiprozessorsystemen (z. B.\nCPU und GPU) eingesetzt werden, <mark>kann</mark> jedoch auch auf\nsymmetrischen Multiprozessorsystemen, bei welchen jeder Prozessor\ngleicherma&#xDF;en dieselben Programme ausf&#xFC;hren kann, eingesetzt werden.\n(vgl. SP1 C IX.2 S. 11 ff.)</p>\n"}],"source":"2020-02","id":"hmz/kAW6lwxB3kZX13+FRg"},{"multiple":false,"question":"<p>Welche Aussage zum Thema Speicherzuteilung ist richtig?</p>\n","id":"s3pDNc5CjzN8ntSrjatW+Q","source":"2016-06","options":[{"comment":"<p>Doch, weil der Speicher intern in Zweier-Potenzen aufgeteilt wird,\nund wenn man weniger braucht, hat man Speicher-Verschlie&#xDF;.</p>\n","option":"<p>Beim Halbierungsverfahren (buddy-Verfahren) <mark>kann</mark>\n<mark>keine</mark> interne Fragmentierung auftreten.</p>\n","correct":false},{"correct":false,"option":"<p>Speicherbereiche, die vor Beendigung eines Prozesses\n<mark>nicht</mark> mit free freigegeben wurden, sind bis zum Neustart\ndes Systems unwiederbringlich verloren.</p>\n","comment":"<p>Nein, weil diese bereits dann <q>unwiederbringlich</q> verloren\ngehen, sobald der Prozess sich beendet.</p>\n"},{"comment":"<p>Nur <q>echte Nachbarn</q>, d.h. Speicherbereiche welche intern\n<mark>nicht</mark> weiter getrennt sind, und aus einem Speicherbereich\nentstanden sind, k&#xF6;nnen verschmolzen werden. Es ist m&#xF6;glich, dass zwei\nSpeicherbereiche zwar neben einander liegen, aber <mark>nicht</mark>\ngleich gro&#xDF; sind.</p>\n","correct":true,"option":"<p>Beim Halbierungsverfahren (buddy-Verfahren) <mark>kann</mark> es\nvorkommen, dass zwei nebeneinander liegende freie Speicherbereiche\n<mark>nicht</mark> miteinander verschmolzen werden k&#xF6;nnen.</p>\n"},{"option":"<p>best-&#xFB01;t ist in <mark>jedem</mark> Fall das beste Verfahren.</p>\n","correct":false,"comment":"<p>Nein, das versucht nur den Verschnitt zu minimieren, und opfert daf&#xFC;r\nLaufzeit, weshalb es <mark>nicht</mark> <q>in <mark>jedem</mark>\nFall</q> das beste sein kann.</p>\n"}]},{"question":"<p>Welche Aussage zum Thema Adressr&#xE4;ume ist richtig?</p>\n","id":"Yk2tb1ib67ppii+J5Gx75Q","options":[{"correct":false,"option":"<p>Im realen Adressraum sind <mark>alle</mark> theoretisch m&#xF6;glichen\nAdressen auch g&#xFC;ltig.</p>\n","comment":"<p>Nein, weil der reale Addressraum L&#xFC;cken haben kann, bedingt durch den\nSpeicher.</p>\n"},{"comment":"<p>Ja, das Betriebsystem <mark>kann</mark> dann versuchen die Seite\neinzulagern, oder einen Speicherfehler an den Prozess\nweiterzuleiten.</p>\n","correct":true,"option":"<p>Der Zugriff auf eine virtuelle Adresse, die zum Zeitpunkt des\nZugriffs <mark>nicht</mark> im Hauptspeicher abgebildet ist, f&#xFC;hrt zu\neinem Trap.</p>\n"},{"correct":false,"option":"<p>Die Gr&#xF6;&#xDF;e eines virtuellen Adressraums darf die Gr&#xF6;&#xDF;e des vorhandenen\nHauptspeichers <mark>nicht</mark> &#xFC;berschreiten.</p>\n","comment":"<p>Nein, der virtuelle Adressraum abstrahiert &#xFC;ber dem realem\nAddressraum, und <mark>kann</mark> vort&#xE4;uschen (/virtualisieren/) die\ngesamte Wortbreite adressierbar zu machen.</p>\n"},{"comment":"<p>Nein, <mark>alle</mark> Seiten haben die gleiche Gr&#xF6;&#xDF;e (Ausnahme:\nHuge-Pages, welche ein Vielfaches gr&#xF6;&#xDF;er sind), damit diese leichter\nein- und ausgelagert werden k&#xF6;nnen.</p>\n","correct":false,"option":"<p>Bei Seitennummerierung besitzt <mark>jede</mark> Seite eine\nunterschiedliche Gr&#xF6;&#xDF;e.</p>\n"}],"source":"2016-06","multiple":false},{"multiple":false,"question":"<p>Ein laufender Prozess wird in den Zustand blockiert &#xFC;berf&#xFC;hrt. Welche\nAussage passt zu diesem Vorgang?</p>\n","source":"2016-06","options":[{"correct":false,"option":"<p>Der Prozess terminiert.</p>\n","comment":"<p>Nein, weil ein blockierter Prozess <mark>kann</mark> sp&#xE4;ter weiter\nlaufen, sobald die Ursache, d.h. eine fehlende Ressource, behoben\nwurde.</p>\n"},{"correct":false,"option":"<p>Es ist kein direkter &#xDC;bergang von laufend nach blockiert m&#xF6;glich.</p>\n","comment":"<p>Nein, ein laufender Prozess <mark>kann</mark> direkt blockiert werden\n(ohne bspw. &#xFC;ber <q>bereit</q> zu gehen), wenn ein blockierender\nSystemaufruf (<code>read(2)</code>, <code>accept(2)</code>,\n<code>wait(2)</code>, &#x2026;) get&#xE4;tigt wird.</p>\n"},{"option":"<p>Der Prozess wartet auf Daten von der Standardeingabe.</p>\n","correct":true,"comment":"<p>Ja, weil das den Prozess so lange blockiert, bis diese Daten\nverf&#xFC;gbar sind.</p>\n"},{"option":"<p>Der bisher laufende Prozess wurde vom Betriebssystem verdr&#xE4;ngt und\nein anderer Prozess auf der CPU eingelastet.</p>\n","correct":false,"comment":"<p>Nein, der Prozess <mark>muss</mark> <mark>nicht</mark> (sofort) auf\neiner anderen CPU eingelastet werden.</p>\n"}],"id":"5IFN2plAyZRwDBaaAW/tIA"},{"options":[{"correct":false,"option":"<p>Der Server signalisiert durch einen Aufruf von\n<code>connect()</code>, dass er zur Annahme von Verbindungen bereit ist;\nein Client <mark>kann</mark> dies durch <code>accept()</code>\nannehmen.</p>\n","comment":"<p>Nein, dazu benutzt der Server den Systemaufruf <code>listen()</code>,\n<code>connect()</code> wird auf der Client-Seite benutzt um sich mit\neinem Server zu verbinden.</p>\n"},{"comment":"<p>Nein, wenn der <em>Server</em> den Socket <mark>nicht</mark> f&#xFC;r\nVerbindungen vorbereitet hat mittels <code>listen()</code>, wird der\n<em>Client</em> mit <code>connect()</code> einen Fehler erfahren. Es ist\n<mark>nicht</mark> in diesem Sinne mit <code>listen()</code> f&#xFC;r den\nClient m&#xF6;glich auf zuk&#xFC;nftige Dienstleistungen zu warten.</p>\n","correct":false,"option":"<p>Der Server erzeugt einen Socket und ruft anschlie&#xDF;end\n<code>bind()</code> auf &#x2013; der Client <mark>muss</mark> durch einen\nAufruf von <code>listen()</code> warten, bis der Server bereit zur\nAnnahme von Verbindungen ist.</p>\n"},{"comment":"<p>Falsch, man <mark>kann</mark> mit <code>connect()</code>\n<mark>keine</mark> Verbindung <em>annehmen</em>, dazu benutzt man\n<code>accept()</code>. In dem Fall <mark>muss</mark> aber zuvor\n<code>bind()</code> und <code>listen()</code> verwenden.</p>\n","option":"<p>Nach der Erzeugung eines Sockets mittels <code>socket()</code>\n<mark>kann</mark> ohne weitere System- oder Funktionsaufrufe sofort eine\nVerbindung von einem Client durch einen Aufruf von\n<code>connect()</code> angenommen werden.</p>\n","correct":false},{"option":"<p>Der Server richtet an einem Socket mittels <code>listen()</code> eine\nWarteschlange f&#xFC;r ankommende Verbindungen ein und <mark>kann</mark>\ndanach mit <code>accept()</code> eine konkrete Verbindung annehmen.\n<code>accept()</code> blockiert so lange die Warteschlange leer ist.</p>\n","correct":true}],"source":"2016-06","id":"I6qGgy5m9vJwUbpuVUzDxA","question":"<p>Welche Aussage zum Aufbau einer Kommunikationsverbindung zwischen\neinem Client und Server &#xFC;ber eine Socket-Schnittstelle ist richtig?</p>\n","multiple":false},{"question":"<p>Wozu dient der Maschinenbefehl <em>cas</em> (compare-and-swap)?</p>\n","id":"+UqhvNHtVlOHMO/+QY6W2g","source":"2016-06","options":[{"option":"<p>Um bei Monoprozessorsystemen Interrupts zu sperren.</p>\n","correct":false,"comment":"<p>Nein, das w&#xE4;re auf x86 ein Befehl wie <code>cli</code>.</p>\n"},{"option":"<p>Um auf einem Multiprozessorsystem einfache Modifikationen an\nVariablen ohne Sperren implementieren zu k&#xF6;nnen.</p>\n","correct":true,"comment":"<p>Ja, es ersetzt einen Wert atomar und transaktional, wenn der Wert\nsich <mark>nicht</mark> ver&#xE4;ndert hat.</p>\n"},{"comment":"<p>Nein, passives Warten braucht einen Scheduler, was man\n<mark>nicht</mark> direkt mit cas bekommt.</p>\n","correct":false,"option":"<p>Um bei der Implementierung von Schlossvariablen (Locks) aktives\nWarten zu vermeiden</p>\n"},{"option":"<p>Um in einem System mit Seitennummerierung (Paging) Speicherseiten in\ndie Auslagerungspartition (swap area) schreiben zu k&#xF6;nnen.</p>\n","correct":false,"comment":"<p>Nein, das wird <mark>nicht</mark> mit einem Maschinenbefehl\numgesetzt, sondern braucht eine MMU.</p>\n"}],"multiple":false},{"id":"IW/+74W7Lvin1zR+HjaAVw","source":"2016-06","options":[{"comment":"<p>Nein, <em>First In, First Out</em> wird die &#xE4;lteste Seite\nausgelagert.</p>\n","option":"<p>Bei der Seitenersetzungsstrategie FIFO wird <mark>immer</mark> die\nzuletzt eingelagerte Seite ersetzt.</p>\n","correct":false},{"comment":"<p>Nein, der Deskriptor <mark>muss</mark> dahingehend angepasst werden,\num anzudeuten dass die Seite wieder pr&#xE4;sent ist.</p>\n","correct":false,"option":"<p>Beim Auslagern einer Speicherseite <mark>muss</mark> der zugeh&#xF6;rige\nSeitendeskriptor angepasst werden, beim Einlagern einer Seite ist das\njedoch <mark>nicht</mark> n&#xF6;tig.</p>\n"},{"comment":"<p>Ja, <em>Least Recently Used</em> wird die &#xE4;lteste unbenutzte Seite\nausgelagert.</p>\n","correct":true,"option":"<p>Bei der Seitenersetzungsstrategie LRU wird die Seite ersetzt, welche\nam l&#xE4;ngsten <mark>nicht</mark> mehr referenziert wurde.</p>\n"},{"comment":"<p>Doch, wenn die neuste Seite (<em>First In</em>) <mark>immer</mark>\nausgelagert wird (<em>First Out</em>), dann werden bei hoher Last\n<mark>immer</mark> die gleichen Seiten ein- und ausgelagert, was man\nunter <q>Seitenflattern</q> versteht.</p>\n","option":"<p>Beim Einsatz der Seitenersetzungsstrategie FIFO <mark>kann</mark> es\n<mark>nicht</mark> zu Seitenflattern kommen.</p>\n","correct":false}],"question":"<p>Welche Aussage zu Seitenersetzungsstrategien ist richtig?</p>\n","multiple":false},{"options":[{"correct":false,"option":"<p>Weil kritische Abschnitte <mark>immer</mark> nur kurz belegt sein\nd&#xFC;rfen.</p>\n","comment":"<p>F&#xFC;r die Performance eines Programms ist das sicher vorteilhaft,\njedoch hat das nichts mit der Frage zu tun.</p>\n"},{"comment":"<p>Nein, gegenseitiger Ausschluss w&#xE4;re sonst auch gegeben.</p>\n","option":"<p>Weil sonst die Monitordaten inkonsistent sind.</p>\n","correct":false},{"correct":true,"option":"<p>Weil ein anderer Thread die Blockierungsbedingung nur aufheben kann,\nwenn er den Monitor vorher betreten kann.</p>\n","comment":"<p>Ja, vergleiche z. B. blockierende Warteschlange. W&#xFC;rde ein\nkonsumierender Thread <mark>nicht</mark> den Monitor freigeben, so\nk&#xF6;nnte kein produzierender Thread ein Element einf&#xFC;gen.</p>\n"},{"option":"<p>Weil der Thread sonst aktiv warten w&#xFC;rde.</p>\n","correct":false,"comment":"<p>Nein, der Thread wartet passiv auf den Monitor.</p>\n"}],"source":"2023-02","id":"KcjojiHQwz/i8703iDEQog","question":"<p>Beim Blockieren in einem Monitor <mark>muss</mark> der Monitor\nfreigegeben werden. Warum?</p>\n","multiple":false},{"source":"2023-02","id":"BLTYDfprvdekT5HscQnVwA","options":[{"comment":"<p>Nein, P und V k&#xF6;nnen von beliebigen, auch unterschiedlichen, Threads\naus aufgerufen werden.</p>\n","option":"<p>Die V-Operation <mark>kann</mark> auf einem Semaphor nur von dem\nThread aufgerufen werden, der zuvor auch die P-Operation aufgerufen\nhat.</p>\n","correct":false},{"comment":"<p>Ja, eine Semaphore mit initialem Wert von 1 (bin&#xE4;re Semaphore)\nimplementiert <em>mutual exclusion</em>, wenn P und V <mark>immer</mark>\npaarweise nacheinander aufgerufen werden.</p>\n","option":"<p>Durch den Einsatz von Semaphoren <mark>kann</mark> ein\nwechselseitiger Ausschluss erzielt werden.</p>\n","correct":true},{"comment":"<p>Nein, das w&#xFC;rde bedeuten, dass man damit nur\nSynchronisationsmechanismen implementieren kann, bei denen jeder Zugriff\nund <mark>nicht</mark> nur Entnahmezugriffe auf das Betriebsmittel dem\nwechselseitigen Ausschluss unterliegt. (vgl. [10.1 S.14]) Jedoch l&#xE4;sst\nsich z. B. eine blockierende Warteschlange mit nichtblockierender\nEntnahme implementieren, bei welcher die Semaphore nur Konsumenten bei\neiner leeren Warteschlange blockiert.</p>\n","option":"<p>Ein Semaphor <mark>kann</mark> ausschlie&#xDF;lich f&#xFC;r mehrseitige\nSynchronisation (<em>multilateral synchronisation</em>) verwendet\nwerden.</p>\n","correct":false},{"option":"<p>Einseitige Synchronisation (<em>unilateral synchronisation</em>)\nerfordert <mark>immer</mark> Betriebssystemunterst&#xFC;tzung.</p>\n","correct":false,"comment":"<p>Nein, diese <mark>kann</mark> zum Beispiel ohne Betriebssystemaufrufe\ndurch ein <em>spin lock</em> realisiert werden.</p>\n"}],"question":"<p>Welche Aussage zum Thema Synchronisation ist richtig?</p>\n","multiple":false},{"source":"2023-02","id":"aLyp8JCxeIhg9fx8FGeO6Q","options":[{"comment":"<p>Nein. Programme, die eine dynamische Bibliothek einbinden m&#xFC;ssen\n(zumindest in der Theorie) nur neugestartet werden, nachdem diese\nausgetauscht wurde, wonach sie durch den dynamischen Binder neu gebunden\nwerden.</p>\n","option":"<p>&#xC4;nderungen am Code einer dynamischen Bibliothek (z. B. Bugfixes)\nerfordern <mark>immer</mark> das erneute Binden aller Programme, die\ndiese Bibliothek benutzen.</p>\n","correct":false},{"comment":"<p>Nein, das passiert hier bereits beim Binden.</p>\n","correct":false,"option":"<p>Beim statischen Binden werden <mark>alle</mark> Adressen zum\nLadezeitpunkt aufgel&#xF6;st.</p>\n"},{"comment":"<p>Ja, beim Laden werden die Adressen der verwendeten Symbole durch den\n<em>dynamic linker</em> aufgel&#xF6;st. Zur Laufzeit k&#xF6;nnen jedoch noch\nBibliotheken nachgeladen werden (<code>dlopen(3)</code>).</p>\n","correct":true,"option":"<p>Beim dynamischen Binden erfolgt die Adressaufl&#xF6;sung beim Laden des\nProgramms oder zur Laufzeit.</p>\n"},{"correct":false,"option":"<p>Statisch gebundene Programme k&#xF6;nnen zum Ladezeitpunkt an beliebige\nvirtuelle Speicheradressen platziert werden.</p>\n","comment":"<p>Nein. Das kann, <mark>muss</mark> aber <mark>nicht</mark> so sein.\nDynamische Bibliotheken m&#xFC;ssen hingegen\n<em>position-independent-code</em> enthalten, um in den Adressbereich\ndes Zielprogramms geladen werden zu k&#xF6;nnen.</p>\n"}],"multiple":false,"question":"<p>Welche der folgenden Aussagen zu statischem bzw. dynamischem Binden\nist richtig?</p>\n"},{"question":"<p>Sie kennen den Translation-Lookaside-Buffer (TLB). Welche Aussage ist\nrichtig?</p>\n","multiple":false,"id":"43yVsM1Hxgxth9NA2u3JnQ","source":"2023-02","options":[{"correct":true,"option":"<p>Ver&#xE4;ndert sich die Speicherabbildung von logischen auf physikalische\nAdressen aufgrund einer Adressraumumschaltung, so werden auch die Daten\nim TLB ung&#xFC;ltig.</p>\n","comment":"<p>Ja, weil die zwischengespeicherten Seitenaddressen <mark>nicht</mark>\nmehr mit dem neuem logischem Addressraum zusammenh&#xE4;ngen w&#xFC;rden.</p>\n"},{"option":"<p>Der TLB verk&#xFC;rzt die Zugriffszeit auf den physikalischen Speicher da\nein Teil des m&#xF6;glichen Speichers in einem schnellen Pufferspeicher\nvorgehalten wird.</p>\n","correct":false,"comment":"<p>Nein, im TLB werden nur die Addressen der Seiten gespeichert, um das\nNachschlagen in der MMU zu vermeiden, und <mark>nicht</mark> den\nSpeicher selbst.</p>\n"},{"comment":"<p>Nein, der TLB hat nichts mit den Daten per se zu tun, sondern\nbeschleundigt nur den Zugriff auf h&#xE4;ufig benutzte Seiten.</p>\n","option":"<p>Der TLB puffert Daten bei der Ein-/Ausgabebehandlung und beschleunigt\ndiese damit.</p>\n","correct":false},{"comment":"<p>Nein, ist kein Eintrag im TLB zu finden, wird die Adresse von der MMU\naufgel&#xF6;st.</p>\n","option":"<p>Wird eine Speicherabbildung im TLB <mark>nicht</mark> gefunden, wird\nder auf den Speicher zugreifende Prozess mit einer Schutzraumverletzung\n(Segmentation Fault) abgebrochen.</p>\n","correct":false}]},{"id":"Y/FPA0AlWc58uf0C/WAA3g","source":"2023-02","options":[{"option":"<p>Mittels <code>fork()</code> erzeugte Kindprozesse k&#xF6;nnen in einem\nMultiprozessor-System nur auf dem Prozessor ausgef&#xFC;hrt werden, auf dem\nauch der Elternprozess ausgef&#xFC;hrt wird.</p>\n","correct":false,"comment":"<p>Nein, es ist dem Scheduler ganz &#xFC;berlassen zu entscheiden, auf\nwelchen Prozessoren ein Prozess laufen soll. Ein Prozess\n<mark>muss</mark> auch <mark>nicht</mark> ganz auf einem Kern oder nur\nauf einem Kern laufen</p>\n"},{"comment":"<p>Ja, das steht auch so in der Man-Page. Die Annahme ist hier, dass\nkein Fehler aufgetreten ist.</p>\n","option":"<p>Der Aufruf von <code>fork()</code> gibt im Elternprozess die\nProzess-ID des Kindprozesses zur&#xFC;ck, im Kindprozess hingegen den Wert\n0.</p>\n","correct":true},{"option":"<p>Threads, die mittels <code>pthread_create()</code> erzeugt wurden,\nbesitzen jeweils einen eigenen Adressraum.</p>\n","correct":false,"comment":"<p>Nein, Kind-Threads (im Kontext von der Pthread Bibliothek.) teilen\nden Addressraum mit dem Eltern-Thread. Prozesse haben eigene\nAddressr&#xE4;ume.</p>\n"},{"option":"<p>Die Ver&#xE4;nderung von Variablen und Datenstrukturen in einem mittels\n<code>fork()</code> erzeugten Kindprozess beeinflusst auch die\nDatenstrukturen im Elternprozess.</p>\n","correct":false,"comment":"<p>Nein, allgemein nicht, au&#xDF;er der Benutzer richtet dieses spezifisch\nein (Siehe <code>shm_open(3)</code>), was aber ohne weiteres\n<mark>nicht</mark> der Fall ist.</p>\n"}],"multiple":false,"question":"<p>Welche Aussage zu Prozessen und Threads ist richtig?</p>\n"},{"source":"2023-02","id":"hOMYpVIZCBJUWU5VujGfPg","options":[{"comment":"<p>Nein, ein Stack-Frame liegt im Stack Segment, und der Programmcode\nliegt im Text-Segment.</p>\n","option":"<p>Der Speicherbereich, in dem der Programmcode einer Funktion abgelegt\nist.</p>\n","correct":false},{"comment":"<p>Nein, es gibt keinen gesonderten Namen f&#xFC;r Fehlerhaften Zugriff auf\nden Stack-Namen.</p>\n","option":"<p>Ein Fehler, der bei unberechtigten Zugriffen auf den Stack-Speicher\nentsteht.</p>\n","correct":false},{"comment":"<p>Ja, ein Stack-Frame wird beim betreten einer Funktion angelegt f&#xFC;r\n<mark>alle</mark> Metadaten und Daten welche zur Ausf&#xFC;hrung ben&#xF6;tigt\nwerden und aufger&#xE4;umt sobald die Funktion verlassen wird.</p>\n","option":"<p>Ein Bereich des Speichers, in dem u.a. lokale automatic-Variablen\neiner Funktion abgelegt sind.</p>\n","correct":true},{"option":"<p>Ein spezieller Registersatz des Prozessors zur Bearbeitung von\nFunktionen.</p>\n","correct":false,"comment":"<p>Nein, es ist kein Registersatz.</p>\n"}],"question":"<p>Was ist ein Stack-Frame?</p>\n","multiple":false},{"question":"<p>Welche der folgenden Informationen wird typischerweise in dem\nSeitendeskriptor einer Seite eines virtuellen Adressraums gehalten?</p>\n","multiple":false,"options":[{"comment":"<p>Ja, so setzt das Betriebsystem bspw. um, dass ein Text Segment\nausf&#xFC;hrbar aber <mark>nicht</mark> schreibbar ist.</p>\n","option":"<p>Die Zugriffsrechte auf die jeweilige Seite (z. B. lesen, schreiben,\nausf&#xFC;hren).</p>\n","correct":true},{"comment":"<p>Nein, das Seiten existieren unabh&#xE4;ngig von Prozessen und m&#xFC;ssten per\nse <mark>nicht</mark> daf&#xFC;r benutzt werden, um logische Speicherr&#xE4;ume\nauf Betriebsystemen mit unabh&#xE4;ngigen Prozessen umzusetzen.</p>\n","correct":false,"option":"<p>Die Identifikation des Prozesses, dem die Seite zugeordnet ist.</p>\n"},{"comment":"<p>Nein, dieses wird <mark>muss</mark> man sich <mark>nicht</mark> in\ndem Seitendeskriptor merken, weil es nur wichtig ist, dass die Seite\nsich gem&#xE4;&#xDF; dem Verst&#xE4;ndnis von diesen Segmenten verh&#xE4;lt (lesbar,\nausf&#xFC;bar, &#x2026;).</p>\n","correct":false,"option":"<p>Die Zuordnung zu einem Segment (Text, Daten, &#x2026;).</p>\n"},{"option":"<p>Die Position der Seite im virtuellen Adressraum.</p>\n","correct":false,"comment":"<p>Nein, diese Zuordnung findet <mark>nicht</mark> im Seitendeskriptor\nstatt, sondern im Betriebsystem.</p>\n"}],"id":"4YXlVEmvVbDQ2CugzepUKg","source":"2023-02"},{"id":"A5W1dVG4Bo5iGCkKJC7hrQ","options":[{"correct":false,"option":"<p>Bei kooperativem Scheduling sind Prozessumschaltungen unm&#xF6;glich, wenn\nein Prozess in einer Endlosschleife l&#xE4;uft. Selbst wenn er bei\n<mark>jedem</mark> Schleifendurchlauf einen Systemaufruf macht.</p>\n","comment":"<p>Nein, laufender Prozess gibt CPU mit Systemaufruf ab.</p>\n"},{"correct":false,"comment":"<p>Nein, mit dem Begriff <q>online</q> ist <mark>nicht</mark> gemeint,\ndass die Schedulingverfahren mit einem Netzwerk interagieren, sondern\neine Klasse von Algorithmen, welche ihre Daten zur Ausf&#xFC;hrungszeit\nerhalten, im Gegensatz zu <q>offline</q> Algorithmen, welche von Anfang\nan <mark>alle</mark> Daten zur Verf&#xFC;gung haben.</p>\n","option":"<p>Online-Schedulingverfahren sind f&#xFC;r den Einsatz in Rechnern ohne\nNetzwerkschnittstelle ungeeignet.</p>\n"},{"comment":"<p>Ja, spezifisch Timer-Interrupts werden dazu benutzt um selbst\nnicht-kooperative Programme <em>unterbrechen</em> zu k&#xF6;nnen. Wenn diese\nAnkommen, welches die Ausf&#xFC;hrung zum Betriebsystem, und das\nBetriebsystem <mark>kann</mark> den Scheduler ansto&#xDF;en, damit dieser\nbeliebige Prozesse ein- und auslagern kann.</p>\n","option":"<p>Verdr&#xE4;ngende Schedulingverfahren k&#xF6;nnen nur mit Hilfe von\nUnterbrechungen realisiert werden.</p>\n","correct":true},{"correct":false,"comment":"<p>Nein, es ist je nach Anwendung m&#xF6;glich diese zu vorhersagen\n(beispielsweise im Embedded-Kontext), wo die Verfahren dann durchaus\nrelevant sein k&#xF6;nnen. Die zielt darauf hinaus zu verleiten, nur &#xFC;ber\nDialog-Betrieb zu denken.</p>\n","option":"<p>Deterministische Schedulingverfahren sind nur in der Theorie\nrelevant, da die genaue L&#xE4;nge der CPU-St&#xF6;&#xDF;e <mark>nie</mark>\nvorhergesagt werden kann.</p>\n"}],"multiple":false,"source":"2021-07","question":"<p>Welche der folgenden Aussagen &#xFC;ber Schedulingverfahren ist\nrichtig?</p>\n"},{"question":"<p>Welche der folgenden Aussagen zum Thema Prozesse und Threads ist\nrichtig?</p>\n","source":"2022-07","multiple":false,"options":[{"correct":true,"comment":"<p>Ja, dieses ist der Fall f&#xFC;r schwer- und leichtgewichtige Prozesse,\naber <mark>nicht</mark> mehr f&#xFC;r federgewichtige, wo die\nSchedulingstrategie durch einen Scheduler im User-Space umgesetzt\nwird.</p>\n","option":"<p>Bei schwergewichtigen Prozessen ist die Schedulingstrategie durch das\nBetriebssystem vorgegeben.</p>\n"},{"correct":false,"option":"<p>Jeder federgewichtige Prozess (User-Thread) und jeder\nleichtgewichtige Prozess (Kern-Thread) hat seinen eigenen, gesch&#xFC;tzten\nAdressraum.</p>\n","comment":"<p>Nein, teilen sich einen Adressraum. Dieses w&#xE4;re bei schwergewichtigen\nProzessen der Fall.</p>\n"},{"option":"<p>Bei Blockade eines schwergewichtigen Prozesses werden\n<mark>alle</mark> anderen schwergewichtigen Prozesse, die das selbe\nProgamm ausf&#xFC;hren, ebenfalls blockiert.</p>\n","comment":"<p>Nein, schwergewichtige Prozesse sind unabh&#xE4;ngig voneinander, d.h. sie\nhaben einen eigenen Ausf&#xFC;hrungsfaden. Bei federgewichtigen Prozessen\nw&#xFC;rde das Problem bestehen (beschr&#xE4;nkt auf den Kontext von einem\nProzess).</p>\n","correct":false},{"correct":false,"option":"<p>Unabh&#xE4;ngig von leichtgewichtigen Prozessen (Kernel-Threads) k&#xF6;nnen\nfedergewichtige Prozesse (User-Threads) Multiprozessoren ausnutzen.</p>\n","comment":"<p>Nein, federgewichtige Prozesse (engl. oft <q><a\nhref=\"https://de.wikipedia.org/wiki/User-Thread\">user threads</a></q>)\nk&#xF6;nnen h&#xF6;chstens so viele Kerne ausnutzen, wie es leichtgewichtige\nProzesse gibt, insofern der Scheduler auch darauf ausgelegt ist die\nfedergewichtigen Prozesse zwischen Kernen bzw. leichtgewichtigen\nProzessen hin und her zu schalten.</p>\n"}],"id":"Pyqefcdjim3K+iYMaPsWOg"},{"question":"<p>Welche der folgenden Aussagen zum Thema RAID ist richtig?</p>\n","source":"2022-07","multiple":false,"options":[{"option":"<p>Bei RAID 5 werden <mark>alle</mark> im Verbund beteiligten Platten\ngleichm&#xE4;&#xDF;ig beansprucht.</p>\n","comment":"<p>Ja, da die Parit&#xE4;tsbits auf <mark>alle</mark> Platten aufgeteilt\nsind.</p>\n","correct":true},{"correct":false,"comment":"<p>Nein, wenn eine Platte ausf&#xE4;llt, f&#xE4;llt das System aus.</p>\n","option":"<p>Bei RAID 0 k&#xF6;nnen nach Ausfall einer der beteiligten Platten die\nDaten durch die Information der anderen rekonstruiert werden.</p>\n"},{"correct":false,"option":"<p>Der Lesedurchsatz eines RAID-Systems mit mehreren Platten ist\nprinzipbedingt geringer als der Lesedurchsatz einer einzelnen\nPlatte.</p>\n","comment":"<p>Nein, weil mehr als eine Platte gleichzeitig angefragt werden\n<mark>kann</mark> um Daten zu liefern, und man auf all diese Anfragen\ngleichzeitig warten kann, was schneller ist als wenn diese Anfragen\nsequenziell abgearbeitet werden m&#xFC;ssten.</p>\n"},{"comment":"<p>Nein, die Parit&#xE4;tsplatte bei RAID 4 wird mehr beansprucht als die\nanderen Platten.</p>\n","option":"<p>Bei RAID 4 werden <mark>alle</mark> im Verbund beteiligten Platten\ngleichm&#xE4;&#xDF;ig beansprucht.</p>\n","correct":false}],"id":"4+RKsRhT8uf3MBDDmWGmew"},{"id":"qUiHMx50rlZO96bmh3W6xQ","options":[{"correct":false,"comment":"<p>Nein, wie in der <em>Hacking &#xDC;bung</em> gezeigt wird, ist es m&#xF6;glich\n&#xFC;ber den Speicher eines Arrays hinweg zu lesen und zu schreiben, was mit\ndem richtigem Wissen ausgenutzt werden kann. C als Sprache gibt\n<mark>nicht</mark> vor, welches verhalten richtig ist (<em>Undefined\nBehaviour</em>), und k&#xF6;nnte prinzipiell zur Laufzeit oder insofern\nm&#xF6;glich statisch vorhersagen ob es zu einem solchem Fehler kommt, und\ndas dann entsprechend Behandeln (wie im Fall von anderen Sprachen mit\nh&#xF6;here Typsicherheit: Java, Ada, Rust, &#x2026;).</p>\n<p>Ein Fehler wie ein Segmentation-Fault h&#xE4;ngt mit der\nSpeichervirtualisierung, und <mark>nicht</mark> mit dem Sprach-Konzept\neines Arrays zusammen, und <mark>muss</mark> daher <mark>nicht</mark>\nauftreten, wenn der Speicher hinter dem Array verf&#xFC;gbar ist, auch wenn\nder Inhalt aus sprachlicher Sicht <mark>nicht</mark> definiert ist.</p>\n","option":"<p>Ein Puffer&#xFC;berlauf eines lokalen Arrays wird <mark>immer</mark> zu\neinem Segmentation Fault f&#xFC;hren und <mark>kann</mark> somit\n<mark>keine</mark> sicherheitskritischen Auswirkungen haben.</p>\n"},{"correct":false,"comment":"<p>Doch, aber diese sind nur <mark>nicht</mark> sichtbar (au&#xDF;er im Fall\nvon Lokalen Funktionen), und m&#xFC;ssten als Speicherreferenzen &#xFC;bergeben\nwerden. Alternativ k&#xF6;nnte man mit Wissen &#xFC;ber die ABI die Adresse von\nVariablen aus einem anderem Stack Frame im gleichem Thread berechnen.\nAber inh&#xE4;rent gibt es allgemein hierzu <mark>keine</mark> Einschr&#xE4;nkung\nmittels Speicherschutzmechanismen.</p>\n","option":"<p>Es ist <mark>nicht</mark> m&#xF6;glich auf lokale\n<q>automatic</q>-Variablen zuzugreifen, die sich im Stack-Frame einer\nanderen Funktion befinden.</p>\n"},{"comment":"<p>Nein, das ist nur dann m&#xF6;glich wenn die Funktionen endrekursiv sind,\nund der &#xDC;bersetzer in der Lage ist diese zu entrekursivieren (<em>Tail\nCall Optimisation</em>). Allgemein ben&#xF6;tigen Rekursive Funktionen den\nSpeicher der mit <mark>jedem</mark> Aufruf angelegt wird, um ihr\nErgebnis zu bestimmen, bspw. eine naive Implementierung der\nFakult&#xE4;tsfunktion</p>\n<pre><code>unsigned fact(unsigned n)\n{\n  if (n &lt;= 1) {\n    return 1;\n  }\n  return n * fact(n-1);\n}</code></pre>\n<p>Speichert sich auf dem Stack <mark>alle</mark> Werte von\n<code>n</code> bis <code>1</code>, und multipliziert diese am Ende\nzusammen beim Abwickeln des Aufrufbaums. W&#xFC;rde der Stack-Frame\nwiederbenutzt werden, w&#xFC;rde jeder Aufruf die Speicherstelle\n&#xFC;berschreiben wo der Wert von <code>n</code> aus <mark>jedem</mark>\nvorherigem Aufruf auch gespeichert w&#xE4;re, und das Endergebnis w&#xE4;re damit\nverf&#xE4;lscht (in dem Fall w&#xE4;re es <code>n</code> quadriert).</p>\n","option":"<p>Bei rekursiven Funktionsaufrufen <mark>kann</mark> der Speicher des\nStack-Frames in <mark>jedem</mark> Fall wiederverwendet werden, weil die\ngleiche Funktion aufgerufen wird.</p>\n","correct":false},{"correct":true,"option":"<p>Wenn in einem UNIX-Prozess mehrere Threads parallel laufen, ben&#xF6;tigt\njeder von ihnen einen eigenen Stack.</p>\n","comment":"<p>Ja. Wenn die Anzahl der Threads <mark>nicht</mark> statisch bekannt\nist (wie in C mit Pthreads im Allgemeinem der Fall ist), dann wird der\nSpeicher f&#xFC;r jeden Thread dynamisch auf der Halde angelegt.</p>\n"}],"multiple":false,"source":"2022-07","question":"<p>F&#xFC;r lokale Variablen, Aufrufparameter usw. einer Funktion wird bei\nvielen Prozessoren ein Stack-Frame angelegt. Welche Aussage ist\nrichtig?</p>\n"},{"id":"9TpHQht3XcPj2eSx01cK8A","options":[{"option":"<p>Ein Dateideskriptor ist eine Verwaltungsstruktur, die auf der\nFestplatte gespeichert ist und Informationen &#xFC;ber Gr&#xF6;&#xDF;e, Zugriffsrechte,\n&#xC4;nderungsdatum usw. einer Datei enth&#xE4;lt.</p>\n","comment":"<p>Nein, mit dieser Aussage ist die Inode Abstraktion gemeint. Au&#xDF;erdem\ngeht es <mark>nicht</mark> um die Speicherung eines Deskriptors bei der\nProzess-Lokalit&#xE4;t, sondern dass die Interpretation des Wertes von einem\nDeskriptors vom Betriebsystem bei Systemaufrufen get&#xE4;tigt wird, indem\ndieser &#xFC;berpr&#xFC;ft welcher Prozess den Systemaufruf abgesetzt hat.</p>\n","correct":false},{"correct":true,"comment":"<p>Ja, ist auch sinnvoll, wenn man will, dass Prozesse die Standard Ein-\nund Ausgabe vererben, was die Grundlage von einer Shell bildet.</p>\n<p>Dieses <mark>kann</mark> zu Nebenl&#xE4;ufigkeitsfehlern f&#xFC;hren! Nimmt man\nBeispielsweise dieses Programm, welches in zwei Prozessen ausgef&#xFC;hrt\nwird:</p>\n<pre><code>\nint main()\n{\n     /* disable output buffering: */\n     setvbuf(stdout, NULL, _IONBF, 0);\n\n     /* child writes &quot;a\\n&quot;, parent writes &quot;b\\n&quot; */\n     char *line = 0 == fork() ? &quot;a&quot; : &quot;b&quot;;\n\n     for (;;) puts(line);\n     return 0;\n}</code></pre>\n<p>und l&#xE4;sst es eine Sekunde lang laufen,</p>\n<pre><code>$ timeout 0.1 ./a.out &gt; out\n$ uniq -c out | sort | uniq\n      1 \n      1 a\n      1 ab\n      1 b\n      1 ba\n      2 a\n      2 b\n      3 b\n      4 a\n      4 b\n     63 b\n      7 a</code></pre>\n<p>sieht man, dass die Ausgabe irregul&#xE4;r ist, und davon abh&#xE4;ngt wie der\nScheduler die Prozesse ein und ausgelagert hat. Wenn man mit dem\nSystemaufruf <code>nice(2)</code> die Priorit&#xE4;t eines Prozesses\nver&#xE4;ndert, dann &#xE4;ndert sich entsprechend auch die Ausgabe. Hier bspw.\nhat man nach dem <code>fork(2)</code> die Priorit&#xE4;t vom Eltern-Prozess\n(<code>\"b\\n\"</code>) erh&#xF6;rt:</p>\n<pre><code>$ timeout 0.1 ./a.out &gt; out\n$ uniq -c out | sort | uniq | sort -nr\n    189 b\n     50 a\n     44 a\n     34 b\n     31 b\n     27 b\n     20 b\n     16 b\n     13 b\n     11 b\n     10 b\n      5 b\n      5 a\n      4 b\n      4 a\n      3 b\n      3 a\n      2 b\n      2 a\n      1 ba\n      1 b\n      1 ab\n      1 a\n      1 </code></pre>\n","option":"<p>Nach dem Aufruf von fork(2) teilen sich die Prozesse die den\ngemeinsamen Dateideskriptoren zu Grunde liegenden\nKernel-Datenstrukturen.</p>\n"},{"comment":"<p>Ja, definiert von <code>FD_CLOEXEC</code>.</p>\n","option":"<p>Ist das Flag FD_CLOEXEC eines Dateideskriptors gesetzt, dann wird\ndieser Dateideskriptor geschlossen, sobald der Prozess eine Funktion der\nexec-Familie aufruft.</p>\n","correct":true},{"correct":true,"option":"<p>Ein Dateideskriptor ist eine prozesslokale Integerzahl, die der\nProzess zum Zugriff auf eine Datei benutzen kann.</p>\n","comment":"<p>Ja. Dabei ist wichtig, dass diese Zahl <mark>keine</mark> Bedeutung\nf&#xFC;r den Prozess selbst hat, sondern nur als Identifikation einer\nRessourcenzuteilung f&#xFC;r den jeweiligen Prozess dienst. Daher\n<mark>kann</mark> der Wert <mark>nicht</mark> ohne weiteres zwischen\nProzessen umher gereicht werden.</p>\n"},{"correct":false,"option":"<p>Ein Dateideskriptor ist eine Integerzahl, die &#xFC;ber gemeinsamen\nSpeicher an einen anderen Prozess &#xFC;bergeben werden <mark>kann</mark> und\nvon letzterem zum Zugriff auf eine ge&#xF6;ffnete Datei verwendet werden\nkann.</p>\n","comment":"<p>Nein, ist eine prozesslokale Integerzahl.</p>\n"},{"comment":"<p>Ja.</p>\n","option":"<p>Auch Netzwerkverbindungen werden &#xFC;ber einen Dateideskriptor\nreferenziert.</p>\n","correct":true},{"comment":"<p>Nein, weil diese sich auf die gleiche Verwaltungsstruktur im\nBetriebssystemkern beziehen.</p>\n","option":"<p>Wird ein Dateideskriptor mittels des dup(2)-Systemaufruf\nvervielf&#xE4;ltigt, k&#xF6;nnen die Zugriffsrechte auf dem resultierendem\nDeskriptor unabh&#xE4;ngig vom urspr&#xFC;nglichen ge&#xE4;ndert werden.</p>\n","correct":false},{"option":"<p>Dateideskriptoren sind Zeiger auf Betriebssystem-interne Strukturen,\ndie von den Systemaufrufen ausgewertet werden, um auf Dateien\nzuzugreifen.</p>\n","comment":"<p>Nein, obzwar ein Zeiger f&#xFC;r &#xFC;blich auch ein Integerzahl ist, verweist\nein Datei-Deskriptor <mark>nicht</mark> direkt auf eine Speicherstelle\nwelche direkt dereferenziert werden kann, wie bei einem gew&#xF6;hnlichem\nZeiger. Um auf die jeweiligen Strukturen im Betriebsystem zu verweisen,\n<mark>muss</mark> das Betriebsystem den Datei-Deskriptor interpretieren\n(oft bspw. als Index in einem Array von Zeigern auf eben die\nBetriebssystem-interne Strukturen).</p>\n","correct":false}],"multiple":true,"source":"2022-07","question":"<p>Welche der folgenden Aussagen zu UNIX/Linux-Dateideskriptoren sind\nkorrekt?</p>\n"},{"source":"2022-07","question":"<p>Welche der folgenden Aussagen zum Thema persistenter Datenspeicherung\nsind richtig?</p>\n","id":"Nw96lIXTQBMuOCnRHJnXFg","options":[{"correct":false,"option":"<p>Bei verketteter Speicherung dauert der wahlfreie Zugriff auf eine\nbestimmte Dateiposition <mark>immer</mark> gleich lang, wenn\nCachingeffekte au&#xDF;er Acht gelassen werden.</p>\n","comment":"<p>Nein, bei Zugriffen, die weiter <q>hinten</q> gespeichert sind,\nk&#xF6;nnte es l&#xE4;nger dauern.</p>\n"},{"comment":"<p>Ja.</p>\n","option":"<p>Bei verketteter Speicherung mittels FAT-Ansatz <mark>kann</mark> die\nVerkettungsinformation redundant gespeichert werden, um die\nFehleranf&#xE4;lligkeit zu reduzieren.</p>\n","correct":true},{"comment":"<p>Nein.</p>\n","option":"<p>Journaling-Dateisysteme sind immun gegen defekte Plattenbl&#xF6;cke.</p>\n","correct":false},{"comment":"<p>Doch, es <mark>kann</mark> zu Verschnitt kommen, da der Speicher in\nBl&#xF6;cke unterteilt wird. (Verschnitt: manche Speicherbl&#xF6;cke bei\nAufteilung von Daten k&#xF6;nnen nur zum Teil gef&#xFC;llt werden)</p>\n","option":"<p>Bei indizierter Speicherung <mark>kann</mark> es prinzipbedingt\n<mark>nicht</mark> zu Verschnitt kommen.</p>\n","correct":false},{"correct":true,"option":"<p>Bei kontinuierlicher Speicherung von Daten ist es unter Umst&#xE4;nden mit\nenormem Aufwand verbunden, eine bestehende Datei zu vergr&#xF6;&#xDF;ern.</p>\n","comment":"<p>Ja, dynamisches Erweitern schwierig, weil es das umherbewegen ganzer\nDateien ben&#xF6;tigen k&#xF6;nnte, welche jeweils <mark>alle</mark> wieder in\nfreien, kontinuierlichen Speicherbereichen gelegt werden m&#xFC;ssten. Das\nwird besonders dann erschwert, wenn mehre Prozesse versuchen lesend oder\nschreibend auf das Dateisystem zuzugreifen.</p>\n"},{"option":"<p>Im Vergleich zu den anderen Verfahren ist bei indizierter Speicherung\ndie Positionierzeit des Festplatten-Armes beim Zugriff auf\n<mark>alle</mark> Datenbl&#xF6;cke einer Datei minimal.</p>\n","comment":"<p>Nein. Allgemein hat die Positionierzeit nichts direkt mit dem\nDateisystem zu tun. Ein Dateisystem k&#xF6;nnte so ausgelegt sein, um gro&#xDF;e\nSpr&#xFC;nge des Festplatten-Armes zu vermeiden, bspw. bei kontinuierlicher\nSpeicherung.</p>\n","correct":false},{"correct":true,"option":"<p>Journaling-Dateisysteme garantieren, dass auch nach einem\nSystemausfall <mark>alle</mark> Metadaten wieder in einen konsistenten\nZustand gebracht werden k&#xF6;nnen.</p>\n","comment":"<p>Ja, mit Hilfe der Log-File.</p>\n"},{"option":"<p>Festplatten eignen sich besser f&#xFC;r sequentielle als f&#xFC;r wahlfreie\nZugriffsmuster.</p>\n","comment":"<p>Ja, wegen dem Lese-Schreib-Kopf, der Daten, die nebeneinander stehen,\nschneller lesen kann, als Daten, die an verschiedenen Orten gespeichert\nsind.</p>\n","correct":true}],"multiple":true}]
